<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>PyTorch-Training first Convolutional Neural Network (CNN)</title>
  <meta name='description' content='pytorch에서 KMNIST를 불러와서 이미지를 불러오고, opencv를 이용하여 간단한 시각화를 해본다.'>

  <link rel="canonical" href="/blog/cnn-pytorch">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="PyTorch-Training first Convolutional Neural Network (CNN) – woohyeon">
  <meta name="twitter:description" content="pytorch에서 KMNIST를 불러와서 이미지를 불러오고, opencv를 이용하여 간단한 시각화를 해본다.">
  <meta name="twitter:image:src" content="/images/posts/06_cnn_pytorch/thumbnail.png">

  <!-- Facebook OpenGraph -->
  <meta property="og:title" content="PyTorch-Training first Convolutional Neural Network (CNN) – woohyeon">
  <meta property="og:description" content="pytorch에서 KMNIST를 불러와서 이미지를 불러오고, opencv를 이용하여 간단한 시각화를 해본다.">
  <meta property="og:image" content="/images/posts/06_cnn_pytorch/thumbnail.png">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;900&display=swap" rel="stylesheet">

  <!-- Ionicons -->
  <link href="https://unpkg.com/ionicons@4.5.0/dist/css/ionicons.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="/assets/style.css">
</head>

<body>

    

    <!-- begin header -->
<header class="c-header">
  <div class="container">
    <div class="row">
      <div class="c-header__inner">

        <div class="logo">
          <a class="logo__link" href="/">
          
            <img class="logo__image" src="/uploads/logo-blank.png" alt="woohyeon">
          
          </a>
        </div>

        <nav class="main-nav">
          <div class="main-nav__box">

            <div class="nav__icon-close">
              <i class="ion ion-md-close"></i>
            </div>

            <div class="nav__title">Menu</div>

              <ul class="nav__list list-reset">

              
                
                <li class="nav__item">
                  <a href="/" class="nav__link">Home</a>
                </li>
                
              
                
                <li class="nav__item">
                  <a href="/projects/" class="nav__link">Projects</a>
                </li>
                
              
                
                <li class="nav__item">
                  <a href="/blog/" class="nav__link">Blog</a>
                </li>
                
              
                
                <li class="nav__item dropdown">
                  <span class="nav__link dropdown-toggle">Pages <i class="ion ion-ios-arrow-down arrow-down"></i></span>
                  <div class="dropdown-menu">
                    
                      <a href="/about/" class="nav__link">About</a>
                    
                      <a href="/elements/" class="nav__link">Elements</a>
                    
                  </div>
                </li>

                
              

            </ul>
          </div>

          <!--bookshop-live name(social-link.jekyll.html) params() context() -->
          
<div class="social">
  <ul class="social__list list-reset">
    
    <li class="social__item">
      <a class="social__link" href="https://twitter.com" target="_blank" rel="noopener" aria-label="twitter icon"><i class="ion ion-logo-twitter"></i></a>
    </li>
    
    <li class="social__item">
      <a class="social__link" href="https://github.com/woohaen88" target="_blank" rel="noopener" aria-label="github icon"><i class="ion ion-logo-github"></i></a>
    </li>
    
    <li class="social__item">
      <a class="social__link" href="https://pinterest.com" target="_blank" rel="noopener" aria-label="pinterest icon"><i class="ion ion-logo-pinterest"></i></a>
    </li>
    
    <li class="social__item">
      <a class="social__link" href="https://youtube.com" target="_blank" rel="noopener" aria-label="youtube icon"><i class="ion ion-logo-youtube"></i></a>
    </li>
    
  </ul>
</div>

          <!--bookshop-live end-->
        </nav>

        <div class="nav-button">
          <i class="nav__icon nav__icon-menu ion ion-md-menu"></i>
        </div>

      </div>
    </div>
  </div>
</header>
<!-- end header -->

    <div class="post-top">
  <div class="container">
    <div class="row">

      

        <div class="align_c">
          <img loading="lazy" src="/images/posts/06_cnn_pytorch/thumbnail.png" alt="PyTorch-Training first Convolutional Neural Network (CNN)" />
        </div>

      

      <div>
        <div class="post__info">

          
          <div class="post-tags">
            
              <a href="/tag/pytorch" class="post-tags__tag">pytorch</a>
            
              <a href="/tag/module" class="post-tags__tag">Module</a>
            
              <a href="/tag/cnn" class="post-tags__tag">CNN</a>
            
          </div>
          


          <h1 class="post__title">PyTorch-Training first Convolutional Neural Network (CNN)</h1>

          <div class="post__meta">
            <div class="post__author-image">
              <img loading="lazy" src="/uploads/profile.jpeg" alt="Kim WooHyeon" />
            </div>

            <div class="post__meta-bottom">
              <div class="post__author">Kim WooHyeon</div>
              <time class="post__date" datetime="2022-01-01T00:02:00+00:00">01 Jan 2022</time>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</div>

<!-- begin post -->
<div class="container animate">

  <article class="post">

    <div class="post__content" data-cms-content-wrapper="/site/_layouts/post.html">
      <p>이번 포스트에서는 CNN학습을 어떻게 하고, 손으로 쓴 히라가나 글씨를 분류하는 것을 목표로한다. 일반적으로 알다시피 숫자형 데이터와는 다르지만 그렇다고 해서 PyTorch에서 구현하는 모델링을 하고 분류하는 방법자체가 많이 달라지지 않는다. 여전히 우리는 이러한 단계를 따른다.</p>

<ol>
  <li>모델 아키텍쳐 정의</li>
  <li>데이터 로드(클라우드, 혹은 디스크)</li>
  <li>epochs와 batches의 반복문을 실행한다.</li>
  <li>손실함수를 계산</li>
  <li>미분계수를 0으로 만들고, 역전파를 실행 그리고 나서 모델 파라미터를 업데이트한다.</li>
</ol>

<p>데이터셋을 쉽게 다루게 해주는 DataLoader를 로드한다. 이 DataLoader는 PyTorch를 사용하는데 있어서 아주 중요한 skill이다.</p>

<h2 id="1-training-convolutional-neural-networkcnn">1. Training Convolutional Neural Network(CNN)</h2>

<p>CNN을 구성하기 위해서는 필수 라이브러리가 필요하다. 바로 torch와 torchvision이다. 그리고 데이터분할을 손쉽게 다루는 scikit-learn와 이미지 그래픽을 위한 opencv또한 설치하도록 하자.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>pip <span class="nb">install </span>torch torchvision
<span class="nv">$ </span>pip <span class="nb">install </span>opencv-contrib-python
<span class="nv">$ </span>pip <span class="nb">install </span>scikit-learn
<span class="nv">$ </span>pip <span class="nb">install </span>imutils
</code></pre></div></div>

<p><br /></p>

<h3 id="the-kmnist-dataset">The KMNIST dataset</h3>

<figure style="text-align: center">
<img src="/images/posts/06_cnn_pytorch/kmnist_dataset.png" width="100%" />
	<span style="font-size: 0.8em; color:gray;"><figcaption align="center">
		Figure 1: The KMNIST dataset
	</figcaption></span>
</figure>

<p>KMNIST는 Kuzushiji-MNIST dataset의 줄임말이다. KMNIST dataset은 기존의 MNIST와 마찬가지로 70,000개의 이미지와 각각 상응하는 라벨이 있다.(60,000개의 훈련 이미지와 10,000개의 라벨 이미지)</p>

<p>KMNIST에는 10개의 클래스가 있고, 균등하게 분배되어 있다. 우리는 CNN을 이용해서 이 것을 60,000개의 이미지를 10개로 올바르게 분류하는게 목표다.</p>

<p>프로젝트의 구조는 다음과 같다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">--dirsfirst</span>
<span class="nb">.</span>
├── output
│   ├── model.pth
│   └── plot.png
├── ururuMllib
│   ├── __init__.py
│   └── lenet.py
├── predict.py
└── train.py
2 directories, 6 files
</code></pre></div></div>

<p>가장 먼저 살펴볼 script는 다음과 같다.</p>

<ol>
  <li>lenet.py : 유명한 LeNet architecture</li>
  <li>train.py : KMNIST를 훈련하는 script</li>
  <li>predict.py : train model을 로드하고, 스크린에 결과를 보여준다.</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">output</code> 디렉터리에는 <code class="language-plaintext highlighter-rouge">plot.png</code>(training/validation loss and accuracy)와 <code class="language-plaintext highlighter-rouge">model.pth</code>가 만들어진다.</p>

<h2 id="2-implementing-a-convolutional-neural-networkcnn">2. Implementing a Convolutional Neural Network(CNN)</h2>

<figure style="text-align: center">
<img src="/images/posts/06_cnn_pytorch/Implementing_a_convnet.png" width="100%" />
	<span style="font-size: 0.8em; color:gray;"><figcaption align="center">
		Figure 2: The LeNet architecture
	</figcaption></span>
</figure>

<p>Lenet 아키텍쳐는 다음과 같은 Layer 구조를 따른다.</p>

<blockquote class="shadow-grey">
  <p>(CONV =&gt; RELU =&gt; POOL) * 2 =&gt; FC =&gt; RELU =&gt; FC =&gt; SOFTMAX</p>
</blockquote>

<p>CNN을 구현해보자. 첫번째로 먼저 필요한 라이브러리를 import 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import the necessary packages
</span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Conv2d</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">MaxPool2d</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">ReLU</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">LogSoftmax</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">flatten</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
</code></pre></div></div>

<ul>
  <li><span class="shadow-grey">Module</span>: <span class="shadow-grey">Sequential</span>을 사용하기보다는 <span class="shadow-grey">Module</span> 의 서브클래스를 불러와서 사용한다.</li>
  <li><span class="shadow-grey">Conv2d</span>: PyTorch의 CNN Layer</li>
  <li><span class="shadow-grey">Linear</span>: Fully connected Layer</li>
  <li><span class="shadow-grey">MaxPool2d</span>: 2D max-pooling을 적용</li>
  <li><span class="shadow-grey">ReLU</span>: ReLU 활성화함수</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LeNet</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numChannels</span><span class="p">,</span> <span class="n">classes</span><span class="p">):</span>
		<span class="c1"># call the parent constructor
</span>		<span class="nb">super</span><span class="p">(</span><span class="n">LeNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

		<span class="c1"># initialize first set of CONV =&gt; RELU =&gt; POOL layers
</span>		<span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">numChannels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
			<span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">relu1</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">maxpool1</span> <span class="o">=</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

		<span class="c1"># initialize second set of CONV =&gt; RELU =&gt; POOL layers
</span>		<span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
			<span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">relu2</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">maxpool2</span> <span class="o">=</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

		<span class="c1"># initialize first (and only) set of FC =&gt; RELU layers
</span>		<span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">relu3</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()</span>

		<span class="c1"># initialize our softmax classifier
</span>		<span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">logSoftmax</span> <span class="o">=</span> <span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>이 코드블럭은 <span class="shadow-grey">LeNet</span> 클래스를 정의한다. 이렇게 <span class="shadow-grey">Module</span>을 상속해서 우리는 여러가지 이점을 얻을 수 있다.</p>

<ul>
  <li>변수 재활용</li>
  <li>사용자 정의 함수나 subnetwork/components를 쉽게 만들 수 있다.</li>
  <li>사용자 정의 함수로 <span class="shadow-grey">forward</span>를 만들 수 있다.</li>
</ul>

<p><strong><em>이중 가장 좋은 점은 우리가 올바르게 모델 아키텍쳐를 정의하기만 하면 파이토치는 자동적으로 자동 미분과 역전파를 수행한다.</em></strong></p>

<p><span class="shadow-grey">LeNet</span>클래스는 2가지 변수를 받는다.</p>

<ol>
  <li><span class="shadow-grey">numChannels</span>: input이미지의 채널수(1: grayscale, 3: RGB)</li>
  <li><span class="shadow-grey">classes</span>: 중복이 되지 않는 데이터셋의 고유 클래스</li>
</ol>

<p>위 코드는 <span class="shadow-grey">CONV =&gt; RELU =&gt; POOL</span> 레이어를 초기화한다. 첫 번재 CONV ㄹ이어는 총 5x5로 이루어진 20개의 필터를 학습한다. 그리고 나서 이미지차원을 줄이기 위해 ReLU 활성화함수를 적용하고 그 후에는 2x2 max-pooling 레이어와 2x2 stride를 적용한다.</p>

<p>그리고나서는 <span class="shadow-grey">CONV =&gt; RELU =&gt; POOL</span> 레이어를 또 한번 반복하는데 이때는 나머지는 그대로 두고 레이어 수가 50개로 증가한다.</p>

<p>그 다음 스텝으로 우리는 완전 연결 레이어를 추가한다. 이 때 input은 800, output은 500으로 한다.</p>

<p>마지막에는 클래스 함수에서 확률을 얻기 위해<span class="shadow-grey">LogSoftmax</span>를 적용한다.</p>

<p>이 시점에서 짚고 넘어갈 일은 초기화된 변수라는 것을 이해하는 것이 중요하다.이러한 변수는 본질적으로 <span class="shadow-grey">place holder</span>이다. PyTorch는 네트워크 아키텍처가 무엇인지 전혀 알지 못한다. 단지 일부 변수가 LeNet 클래스 정의 내에 존재한다는 것뿐이다.</p>

<p>네트워크 아키텍처 자체를 구축하려면(즉, 어떤 레이어가 다른 레이어에 입력되는지) Module 클래스의 forward 메서드를 재정의해야 한다.</p>

<p><span class="shadow-grey">forward</span> 함수는 다음과 같은 목적을 가지고 있다.</p>

<ol>
  <li>클래스의 생성자(예: __init__)에 정의된 변수에서 레이어/서브네트워크를 함께 연결한다.</li>
  <li>네트워크 아키텍처 자체를 정의한다.</li>
  <li>이를 통해 모델의 순방향 전달이 수행되어 결과적으로 출력 예측이 가능하다.</li>
  <li>그리고 PyTorch의 autograd 모듈 덕분에 자동 미분을 수행하고 모델 가중치를 업데이트할 수 있다.</li>
</ol>

<p><span class="shadow-grey">forward</span>는 코드로 구현하면 다음과 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
		<span class="c1"># pass the input through our first set of CONV =&gt; RELU =&gt;
</span>		<span class="c1"># POOL layers
</span>		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxpool1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

		<span class="c1"># pass the output from the previous layer through the second
</span>		<span class="c1"># set of CONV =&gt; RELU =&gt; POOL layers
</span>		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxpool2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

		<span class="c1"># flatten the output from the previous layer and pass it
</span>		<span class="c1"># through our only set of FC =&gt; RELU layers
</span>		<span class="n">x</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

		<span class="c1"># pass the output to our softmax classifier to get our output
</span>		<span class="c1"># predictions
</span>		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">logSoftmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

		<span class="c1"># return the output predictions
</span>		<span class="k">return</span> <span class="n">output</span>
</code></pre></div></div>

<p><span class="shadow-grey">forward</span>함수는 한개의 파라미터 <span class="shadow-grey">x</span>를 받아 들인다. 그리고 이 것은 network의 input데이터이다. 그리고 나서 <span class="shadow-grey">conv1</span>, <span class="shadow-grey">relu1</span>, <span class="shadow-grey">maxpool1</span>레이어를첫번째 등장하는 <span class="shadow-grey">CONV =&gt; RELU =&gt; POOL</span> 레이어에 연결한다.</p>

<p><span class="shadow-grey">CONV =&gt; RELU =&gt; POOL</span> 레이어는 다차원 텐서다. 완전연결레이어에 연결하기 위해서 <span class="shadow-grey">flatten</span>메서드를 사용해야한다.</p>

<p>이렇게 하기 위해서 우리는 <span class="shadow-grey">fc1</span>와 <span class="shadow-grey">relu3</span>레이어를 연결해야한다. 다음에는 <span class="shadow-grey">fc2</span>와 <span class="shadow-grey">logSoftmax</span>를 연결한다. <span class="shadow-grey">output</span>은 호출함수를 리턴한다.</p>

<h3 id="creating-our-cnn-training-script-with-pytorch">Creating our CNN training script with PyTorch</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># USAGE
# python train.py --model output/model.pth --plot output/plot.png
</span>
<span class="c1"># set the matplotlib backend so figures can be saved in the background
</span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"Agg"</span><span class="p">)</span>

<span class="c1"># import the necessary packages
</span><span class="kn">from</span> <span class="nn">ururuMLlib.lenet</span> <span class="kn">import</span> <span class="n">LeNet</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">KMNIST</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>
</code></pre></div></div>

<p><span class="shadow-grey">matplotlib</span>를 import하고 background engine을 “Agg”로 바꾼다.</p>

<p>command line arguments는 다음과 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># construct the argument parser and parse the arguments
</span><span class="n">ap</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">ap</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-m"</span><span class="p">,</span> <span class="s">"--model"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">help</span><span class="o">=</span><span class="s">"path to output trained model"</span><span class="p">)</span>
<span class="n">ap</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-p"</span><span class="p">,</span> <span class="s">"--plot"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">help</span><span class="o">=</span><span class="s">"path to output loss/accuracy plot"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ap</span><span class="p">.</span><span class="n">parse_args</span><span class="p">())</span>
</code></pre></div></div>

<p>여기에서 우리는 2개의 arguments를 파싱한다.</p>

<ol>
  <li><span class="shadow-grey">–model</span> : 모델이 저장될 경로</li>
  <li><span class="shadow-grey">–plot</span> : training history plot이 저장될 경로</li>
</ol>

<p>모델을 학습하기 위한 파라미터를 정의한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define training hyperparameters
</span><span class="n">INIT_LR</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># define the train and val splits
</span><span class="n">TRAIN_SPLIT</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">VAL_SPLIT</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">TRAIN_SPLIT</span>

<span class="c1"># set the device we will be using to train the model
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
</code></pre></div></div>

<p>학습률, batch_size, epochf를 정의하고, train과 validation을 (4 : 1)로 분류한다. 데이터셋을 다운 받자. 코드는 다음과 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load the KMNIST dataset
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] loading the KMNIST dataset..."</span><span class="p">)</span>
<span class="n">trainData</span> <span class="o">=</span> <span class="n">KMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"data"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">testData</span> <span class="o">=</span> <span class="n">KMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"data"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="c1"># calculate the train/validation split
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] generating the train/validation split..."</span><span class="p">)</span>
<span class="n">numTrainSamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span> <span class="o">*</span> <span class="n">TRAIN_SPLIT</span><span class="p">)</span>
<span class="n">numValSamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span> <span class="o">*</span> <span class="n">VAL_SPLIT</span><span class="p">)</span>
<span class="p">(</span><span class="n">trainData</span><span class="p">,</span> <span class="n">valData</span><span class="p">)</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">trainData</span><span class="p">,</span>
	<span class="p">[</span><span class="n">numTrainSamples</span><span class="p">,</span> <span class="n">numValSamples</span><span class="p">],</span>
	<span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">Generator</span><span class="p">().</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">))</span>

<span class="c1"># initialize the train, validation, and test data loaders
</span><span class="n">trainDataLoader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">trainData</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">valDataLoader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valData</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">testDataLoader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">testData</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="c1"># calculate steps per epoch for training and validation set
</span><span class="n">trainSteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainDataLoader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
<span class="n">valSteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valDataLoader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
</code></pre></div></div>

<p><span class="shadow-grey">DataLoader</span> object는 훈련에서는 <span class="shadow-grey">shuffle=True</span>, 테스트에서는 <span class="shadow-grey">shuffle=False</span>로 설정한다.</p>

<p>이제 LeNet을 초기화 하자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># initialize the LeNet model
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] initializing the LeNet model..."</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">(</span>
	<span class="n">numChannels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
	<span class="n">classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">trainData</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">classes</span><span class="p">)).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># initialize our optimizer and loss function
</span><span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">INIT_LR</span><span class="p">)</span>
<span class="n">lossFn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="c1"># initialize a dictionary to store training history
</span><span class="n">H</span> <span class="o">=</span> <span class="p">{</span>
	<span class="s">"train_loss"</span><span class="p">:</span> <span class="p">[],</span>
	<span class="s">"train_acc"</span><span class="p">:</span> <span class="p">[],</span>
	<span class="s">"val_loss"</span><span class="p">:</span> <span class="p">[],</span>
	<span class="s">"val_acc"</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="c1"># measure how long training is going to take
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] training the network..."</span><span class="p">)</span>
<span class="n">startTime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
</code></pre></div></div>

<p>위 코드는 우리의 <span class="shadow-grey">model</span>을ㄹ 초기화한다. KMNIST dataset이 grayscale이기 때문에 우리는 <span class="shadow-grey">numChannels=1</span>로 설정한다. 그리고 우리는 <span class="shadow-grey">datasest.classes</span>의 <span class="shadow-grey">classes</span>를 설정한다.</p>

<p>optimizer와 loss function을 초기화한다. 우리는 <span class="shadow-grey">Adam optimizer</span>와 <span class="shadow-grey">negative log-likelihood</span>를 사용한다. 그리고 이 것을 <span class="shadow-grey">nn.NLLoss</span>와 <span class="shadow-grey">LogSoftmax</span>와 연결한다.</p>

<p>이제 모델 training을 해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># loop over our epochs
</span><span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="p">)):</span>
	<span class="c1"># set the model in training mode
</span>	<span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

	<span class="c1"># initialize the total training and validation loss
</span>	<span class="n">totalTrainLoss</span> <span class="o">=</span> <span class="mi">0</span>
	<span class="n">totalValLoss</span> <span class="o">=</span> <span class="mi">0</span>

	<span class="c1"># initialize the number of correct predictions in the training
</span>	<span class="c1"># and validation step
</span>	<span class="n">trainCorrect</span> <span class="o">=</span> <span class="mi">0</span>
	<span class="n">valCorrect</span> <span class="o">=</span> <span class="mi">0</span>

	<span class="c1"># loop over the training set
</span>	<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">trainDataLoader</span><span class="p">:</span>
		<span class="c1"># send the input to the device
</span>		<span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

		<span class="c1"># perform a forward pass and calculate the training loss
</span>		<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">loss</span> <span class="o">=</span> <span class="n">lossFn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

		<span class="c1"># zero out the gradients, perform the backpropagation step,
</span>		<span class="c1"># and update the weights
</span>		<span class="n">opt</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
		<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
		<span class="n">opt</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

		<span class="c1"># add the loss to the total training loss so far and
</span>		<span class="c1"># calculate the number of correct predictions
</span>		<span class="n">totalTrainLoss</span> <span class="o">+=</span> <span class="n">loss</span>
		<span class="n">trainCorrect</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">).</span><span class="nb">type</span><span class="p">(</span>
			<span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<p>이제 우리는 다음과 같은 절차를 따른다.</p>

<ol>
  <li>model mode를 <span class="shadow-grey blue">train()</span> mode로 변경한다.</li>
  <li>우리의 training loss와 validation loss를 현재 epoch에서 초기화한다.</li>
  <li>현재 epoch에서 올바른 학습과 검증예측에대한 수를 초기화한다.</li>
</ol>

<p>이게 완료되었으면 다음 스텝으로 넘어간다.</p>

<ol>
  <li>gradient를 0으로 만든다.</li>
  <li>역전파를 수행한다.</li>
  <li>model weight를 업데이트한다.</li>
</ol>

<p><strong><em>위 단계를 꼭 기억하자!</em></strong> 위 스텝을 정확히 지키지 않으면 심각한 오류를 초래한다.</p>

<p>이제 우리의 모델을 검증데이터셋에서 평가한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># switch off autograd for evaluation
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># set the model in evaluation mode
</span>    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

    <span class="c1"># loop over the validation set
</span>    <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">valDataLoader</span><span class="p">:</span>
        <span class="c1"># send the input to the device
</span>        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1"># make the predictions and calculate the validation loss
</span>        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">totalValLoss</span> <span class="o">+=</span> <span class="n">lossFn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># calculate the number of correct predictions
</span>        <span class="n">valCorrect</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">).</span><span class="nb">type</span><span class="p">(</span>
            <span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<p>검증데이터셋에서 PyTorch 모델을 평가할 때는 다음을 명시하자.</p>

<ol>
  <li><span class="shadow-grey blue">torch.no_grad()</span>: 자동미분을 끈다.</li>
  <li>model를 평가모드로 바꾼다. <span class="shadow-grey blue">model.eval()</span></li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate the average training and validation loss
</span><span class="n">avgTrainLoss</span> <span class="o">=</span> <span class="n">totalTrainLoss</span> <span class="o">/</span> <span class="n">trainSteps</span>
<span class="n">avgValLoss</span> <span class="o">=</span> <span class="n">totalValLoss</span> <span class="o">/</span> <span class="n">valSteps</span>

<span class="c1"># calculate the training and validation accuracy
</span><span class="n">trainCorrect</span> <span class="o">=</span> <span class="n">trainCorrect</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainDataLoader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">valCorrect</span> <span class="o">=</span> <span class="n">valCorrect</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">valDataLoader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># update our training history
</span><span class="n">H</span><span class="p">[</span><span class="s">"train_loss"</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">avgTrainLoss</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">H</span><span class="p">[</span><span class="s">"train_acc"</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">trainCorrect</span><span class="p">)</span>
<span class="n">H</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">avgValLoss</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">H</span><span class="p">[</span><span class="s">"val_acc"</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">valCorrect</span><span class="p">)</span>

<span class="c1"># print the model training and validation information
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] EPOCH: {}/{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train loss: {:.6f}, Train accuracy: {:.4f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
    <span class="n">avgTrainLoss</span><span class="p">,</span> <span class="n">trainCorrect</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Val loss: {:.6f}, Val accuracy: {:.4f}</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
    <span class="n">avgValLoss</span><span class="p">,</span> <span class="n">valCorrect</span><span class="p">))</span>
</code></pre></div></div>

<p>위 코드블럭은 training과 validation loss의 평균을 계산한다. 훈련은 완료되었다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># finish measuring how long training took
</span><span class="n">endTime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"[INFO] total time taken to train the model: {:.2f}s"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
	<span class="n">endTime</span> <span class="o">-</span> <span class="n">startTime</span><span class="p">))</span>

<span class="c1"># we can now evaluate the network on the test set
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] evaluating network..."</span><span class="p">)</span>

<span class="c1"># turn off autograd for testing evaluation
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
	<span class="c1"># set the model in evaluation mode
</span>	<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

	<span class="c1"># initialize a list to store our predictions
</span>	<span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>

	<span class="c1"># loop over the test set
</span>	<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">testDataLoader</span><span class="p">:</span>
		<span class="c1"># send the input to the device
</span>		<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

		<span class="c1"># make the predictions and add them to the list
</span>		<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		<span class="n">preds</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>

<span class="c1"># generate a classification report
</span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">testData</span><span class="p">.</span><span class="n">targets</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span>
	<span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="n">target_names</span><span class="o">=</span><span class="n">testData</span><span class="p">.</span><span class="n">classes</span><span class="p">))</span>
</code></pre></div></div>

<p>이제 훈련 타이머를 멈추고 훈련 시간을 보여준다. 그리고 그런 다음 <span class="shadow-grey blue">torch.no_grad()</span>컨텍스트를 설정하고 model을 <span class="shadow-grey blue">eval()</span>로 변경한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the training loss and accuracy
</span><span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"ggplot"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="s">"train_loss"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"train_loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"val_loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="s">"train_acc"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"train_acc"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="s">"val_acc"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"val_acc"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Training Loss and Accuracy on Dataset"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Epoch #"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Loss/Accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower left"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">"plot"</span><span class="p">])</span>

<span class="c1"># serialize the model to disk
</span><span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="s">"model"</span><span class="p">])</span>
</code></pre></div></div>

<p>훈련 기록에 대한 matplotlib 그림을 생성한다.</p>

<p>그런 다음 PyTorch 모델 가중치를 디스크에 저장하기 위해 <span class="shadow-grey">torch.save</span>를 호출하여 디스크에서 로드하고 별도의 Python 스크립트에서 예측할 수 있다.</p>

<p>전체적으로 이 스크립트를 검토하면 PyTorch가 훈련 루프에 대해 얼마나 더 많은 제어를 제공하는지 알 수 있다.</p>

<p>훈련 루프를 완전히 제어하고 사용자 지정 절차를 구현해야 하는 경우에 좋다.</p>

<h3 id="training-our-cnn-with-pytorch">Training our CNN with PyTorch</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>INFO] loading the KMNIST dataset...
<span class="o">[</span>INFO] generating the train/validation split...
<span class="o">[</span>INFO] initializing the LeNet model...
<span class="o">[</span>INFO] training the network...
<span class="o">[</span>INFO] EPOCH: 1/10
Train loss: 0.367026, Train accuracy: 0.8862
Val loss: 0.162807, Val accuracy: 0.9512

<span class="o">[</span>INFO] EPOCH: 2/10
Train loss: 0.100468, Train accuracy: 0.9694
Val loss: 0.107167, Val accuracy: 0.9687

<span class="o">[</span>INFO] EPOCH: 3/10
Train loss: 0.060439, Train accuracy: 0.9814
Val loss: 0.072758, Val accuracy: 0.9791

<span class="o">[</span>INFO] EPOCH: 4/10
Train loss: 0.038513, Train accuracy: 0.9881
Val loss: 0.069339, Val accuracy: 0.9810

<span class="o">[</span>INFO] EPOCH: 5/10
Train loss: 0.025257, Train accuracy: 0.9922
Val loss: 0.088133, Val accuracy: 0.9760

<span class="o">[</span>INFO] EPOCH: 6/10
Train loss: 0.020032, Train accuracy: 0.9935
Val loss: 0.086066, Val accuracy: 0.9787

<span class="o">[</span>INFO] EPOCH: 7/10
Train loss: 0.016911, Train accuracy: 0.9946
Val loss: 0.093041, Val accuracy: 0.9776

<span class="o">[</span>INFO] EPOCH: 8/10
Train loss: 0.013512, Train accuracy: 0.9958
Val loss: 0.086559, Val accuracy: 0.9789

<span class="o">[</span>INFO] EPOCH: 9/10
Train loss: 0.012416, Train accuracy: 0.9961
Val loss: 0.104030, Val accuracy: 0.9773

<span class="o">[</span>INFO] EPOCH: 10/10
Train loss: 0.010962, Train accuracy: 0.9966
Val loss: 0.094252, Val accuracy: 0.9801

<span class="o">[</span>INFO] total <span class="nb">time </span>taken to train the model: 294.22s
<span class="o">[</span>INFO] evaluating network...
              precision    recall  f1-score   support

           o       0.92      0.96      0.94      1000
          ki       0.96      0.94      0.95      1000
          su       0.95      0.88      0.91      1000
         tsu       0.97      0.97      0.97      1000
          na       0.96      0.92      0.94      1000
          ha       0.94      0.93      0.93      1000
          ma       0.91      0.97      0.94      1000
          ya       0.93      0.97      0.95      1000
          re       0.98      0.98      0.98      1000
          wo       0.96      0.96      0.96      1000

    accuracy                           0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000
</code></pre></div></div>

<figure style="text-align: center">
<img src="/images/posts/06_cnn_pytorch/plot.png" width="100%" />
	<span style="font-size: 0.8em; color:gray;"><figcaption align="center">
		Figure 3: Plotting our training history with PyTorch
	</figcaption></span>
</figure>

<p>CPU에서는 ≈160초 정도 걸리고 GPU에서는 ≈82초 걸린다.</p>

<p>epoch의 마지막에서 우리는 99.67%의 정확도를 얻었다. 그리고 테스트셋에서는 98.01%의 결과를 얻었다.</p>

<p>우리의 얕은 모델 구조(그러나 PyTorch에서 CNN을 사용하기에는 VGG나 ResNet과 같은 모델을 사용하면 더 높은 정확도를 얻을 수 있지만 이런 모델은 더 복잡하다)에서 테스트셋이 정확도가 ≈95% 정도 도달하게 되면 꽤 좋은 결과다.</p>

<p>그러나, 위 그림에서 보듯이 우리의 훈련 그래프는 꽤 smooth하다. 그리고 과대적합이 일어났는지를 입증해야 한다</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">ls </span>output/
model.pth	plot.png
</code></pre></div></div>

<p><span class="shadow-grey">model.pth</span>파일은 우리가 훈련한 모델이고 disk에 저장된다. 그리고 예측할 때는 이 모델을 불러와서 사용한다.</p>

<h2 id="implementing-our-pytorch-prediction-script">Implementing our PyTorch prediction script</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set the numpy seed for better reproducibility
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># import the necessary packages
</span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Subset</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">KMNIST</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">imutils</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">cv2</span>
</code></pre></div></div>

<p>필요한 라이브러리를 로드하고 코드의 재사용성을 위해 seed를 설정한다.</p>

<ul>
  <li><span class="shadow-grey">DataLoader</span> : 우리의 KMNIST test 데이터를 사용한다.</li>
  <li><span class="shadow-grey">Subset</span> : testing data</li>
  <li><span class="shadow-grey">ToTensor</span> : PyTorch tensor로 변환한다.</li>
  <li><span class="shadow-grey">KMNIST</span> : The Kuzushiji-MNIST dataset</li>
  <li><span class="shadow-grey">cv2</span> : display를 위한 라이브러리</li>
</ul>

<p>command line arguments를 parsing한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># construct the argument parser and parse the arguments
</span><span class="n">ap</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">ap</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-m"</span><span class="p">,</span> <span class="s">"--model"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">help</span><span class="o">=</span><span class="s">"path to the trained PyTorch model"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ap</span><span class="p">.</span><span class="n">parse_args</span><span class="p">())</span>
</code></pre></div></div>

<p>여기서는 우리는 1개의 argument만 사용한다. <span class="shadow-grey">–model</span> : 우리가 훈련한 모델 객체이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set the device we will be using to test the model
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>

<span class="c1"># load the KMNIST dataset and randomly grab 10 data points
</span><span class="k">print</span><span class="p">(</span><span class="s">"[INFO] loading the KMNIST test dataset..."</span><span class="p">)</span>
<span class="n">testData</span> <span class="o">=</span> <span class="n">KMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"data"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">testData</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">testData</span> <span class="o">=</span> <span class="n">Subset</span><span class="p">(</span><span class="n">testData</span><span class="p">,</span> <span class="n">idxs</span><span class="p">)</span>

<span class="c1"># initialize the test data loader
</span><span class="n">testDataLoader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">testData</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># load the model and set it to evaluation mode
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">"model"</span><span class="p">]).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<p>KMNIST 데이터 세트에서 테스트 데이터를 로드한다. 우리는 Subset 클래스를 사용하여 이 데이터 세트의 총 10개의 이미지를 무작위로 샘플링한다.</p>

<p>모델을 통해 테스트 데이터의 하위 집합을 전달하기 위해 DataLoader가 생성한다.</p>

<p>그런 다음 디스크에서 PyTorch 모델을 로드하여 위세서 선언한 <span class="shadow-grey">devicec</span>로 전달한다. 마지막으로 모델은 평가 모드로 전환한다.</p>

<p>이제 테스트 세트의 샘플에 대해 예측해 보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># switch off autograd
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
	<span class="c1"># loop over the test set
</span>	<span class="k">for</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">testDataLoader</span><span class="p">:</span>
		<span class="c1"># grab the original image and ground truth label
</span>		<span class="n">origImage</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">squeeze</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
		<span class="n">gtLabel</span> <span class="o">=</span> <span class="n">testData</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">classes</span><span class="p">[</span><span class="n">label</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]]</span>

		<span class="c1"># send the input to the device and make predictions on it
</span>		<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
		<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

		<span class="c1"># find the class label index with the largest corresponding
</span>		<span class="c1"># probability
</span>		<span class="n">idx</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">predLabel</span> <span class="o">=</span> <span class="n">testData</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">classes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</code></pre></div></div>

<p>그래디언트 추적을 끄고 테스트 세트의 하위 집합에 있는 모든 이미지를 반복한다.</p>

<p>그리고 각 이미지에 대해 다음을 수행한다.</p>

<ol>
  <li>현재 이미지를 가져와 NumPy 배열로 변환(나중에 OpenCV로 그릴 수 있도록)</li>
  <li>실측 클래스 레이블을 추출</li>
  <li><span class="shadow-grey">image</span>를 적절한 <span class="shadow-grey">device</span>로 보냄</li>
  <li>훈련된 LeNet 모델을 사용하여 현재 <span class="shadow-grey">image</span>를 예측</li>
  <li>예측 확률이 가장 높은 클래스 레이블을 추출</li>
</ol>

<p>남은 것은 약간의 시각화정도이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>		<span class="c1"># convert the image from grayscale to RGB (so we can draw on
</span>		<span class="c1"># it) and resize it (so we can more easily see it on our
</span>		<span class="c1"># screen)
</span>		<span class="n">origImage</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">origImage</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
		<span class="n">origImage</span> <span class="o">=</span> <span class="n">imutils</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">origImage</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
		<span class="c1"># draw the predicted class label on it
</span>		<span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">gtLabel</span> <span class="o">==</span> <span class="n">predLabel</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
		<span class="n">cv2</span><span class="p">.</span><span class="n">putText</span><span class="p">(</span><span class="n">origImage</span><span class="p">,</span> <span class="n">gtLabel</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
			<span class="n">cv2</span><span class="p">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
		<span class="c1"># display the result in terminal and show the input image
</span>		<span class="k">print</span><span class="p">(</span><span class="s">"[INFO] ground truth label: {}, predicted label: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
			<span class="n">gtLabel</span><span class="p">,</span> <span class="n">predLabel</span><span class="p">))</span>
		<span class="n">cv2</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"image"</span><span class="p">,</span> <span class="n">origImage</span><span class="p">)</span>
		<span class="n">cv2</span><span class="p">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>KMNIST 데이터 세트의 각 이미지는 단일 채널 회색조 이미지입니다. 그러나 OpenCV의 <span class="shadow-grey">cv2.putText</span> 함수를 사용하여 <span class="shadow-grey">image</span>에 예측된 클래스 레이블과 정답 레이블을 그려보자.</p>

<p>회색조 이미지에 RGB 색상을 그리려면 먼저 회색조 이미지를 깊이별로 총 3번 쌓아서 회색조 이미지의 RGB 표현을 만들어야 한다.</p>

<p>또한 화면에서 더 쉽게 볼 수 있도록 <span class="shadow-grey">origImage</span>의 크기를 조정한다.(기본적으로 KMNIST 이미지는 28×28 픽셀에 불과하므로 특히 고해상도 모니터에서 보기 어려울 수 있음).</p>

<p>여기에서 텍스트 <span class="shadow-grey">color</span>을 결정하고 출력 이미지에 레이블을 그린다.</p>

<p>화면에 출력 <span class="shadow-grey">origImage</span>를 표시하여 스크립트를 마무리한다.</p>

<h3 id="making-predictions-with-our-trained-pytorch-model">Making predictions with our trained PyTorch model</h3>

<p>이제 훈련된 PyTorch 모델을 사용하여 예측할 준비가 되었다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>INFO] loading the KMNIST <span class="nb">test </span>dataset...
<span class="o">[</span>INFO] ground truth label: ki, predicted label: ki
<span class="o">[</span>INFO] ground truth label: ki, predicted label: ki
<span class="o">[</span>INFO] ground truth label: ki, predicted label: ki
<span class="o">[</span>INFO] ground truth label: ha, predicted label: ha
<span class="o">[</span>INFO] ground truth label: tsu, predicted label: tsu
<span class="o">[</span>INFO] ground truth label: ya, predicted label: ya
<span class="o">[</span>INFO] ground truth label: tsu, predicted label: tsu
<span class="o">[</span>INFO] ground truth label: na, predicted label: na
<span class="o">[</span>INFO] ground truth label: ki, predicted label: ki
<span class="o">[</span>INFO] ground truth label: tsu, predicted label: tsu
</code></pre></div></div>

<figure style="text-align: center">
<img src="/images/posts/06_cnn_pytorch/predict_handwritten_characters.png" width="100%" />
	<span style="font-size: 0.8em; color:gray;"><figcaption align="center">
		Figure 4: Making predictions on handwritten characters using PyTorch and our trained CNN
	</figcaption></span>
</figure>

<p>출력에서 알 수 있듯이 PyTorch 모델을 사용하여 각 히라가나 문자를 성공적으로 인식할 수 있다.</p>

    </div>

    <div class="post__share">
  <div class="share__head">
    <div class="share__title">Share this Post</div>
  </div>
  <ul class="share__list list-reset">
    <li class="share__item">
      <a class="share__link share__twitter"
        href="https://twitter.com/intent/tweet?text=PyTorch-Training%20first%20Convolutional%20Neural%20Network%20(CNN)&url=/blog/cnn-pytorch"
        onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
        title="Share on Twitter" rel="nofollow"><i class="ion ion-logo-twitter"></i></a>
    </li>
    <li class="share__item">
      <a class="share__link share__facebook"
        href="https://www.facebook.com/sharer/sharer.php?u=/blog/cnn-pytorch"
        onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
        title="Share on Facebook" rel="nofollow"><i class="ion ion-logo-facebook"></i></a>
    </li>
    <li class="share__item">
      <a class="share__link share__pinterest"
        href="http://pinterest.com/pin/create/button/?url=/blog/cnn-pytorch&amp;media=/images/posts/06_cnn_pytorch/thumbnail.png&amp;description=PyTorch-Training%20first%20Convolutional%20Neural%20Network%20(CNN)"
        onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
        title="Share on Pinterest" rel="nofollow"><i class="ion ion-logo-pinterest"></i></a>
    </li>
    <li class="share__item">
      <a class="share__link share__linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&url=/blog/cnn-pytorch&title=PyTorch-Training%20first%20Convolutional%20Neural%20Network%20(CNN)&summary=pytorch%EC%97%90%EC%84%9C%20KMNIST%EB%A5%BC%20%EB%B6%88%EB%9F%AC%EC%99%80%EC%84%9C%20%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%A5%BC%20%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B3%A0,%20opencv%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC%20%EA%B0%84%EB%8B%A8%ED%95%9C%20%EC%8B%9C%EA%B0%81%ED%99%94%EB%A5%BC%20%ED%95%B4%EB%B3%B8%EB%8B%A4.&source=Woohyeon"
        onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
        title="Share on LinkedIn" rel="nofollow"><i class="ion ion-logo-linkedin"></i></a>
    </li>
  </ul>
</div>

  </article>
</div>
<!-- end post -->

<div class="container">
  <div class="row">
    <div class="col col-10 col-d-12 push-d-0 push-1">
      <div class="post__navigation animate">
  
  <a class="post__prev" href="/blog/intro-to-pytorch">
    <div class="prev__image">
      <img loading="lazy" src="/images/posts/03_modulization/thumbnail.png" alt="PyTorch-Training first Convolutional Neural Network (CNN)">
    </div>
    <div class="prev__box">
      <span class="post__nav post__nav__prev">Prev post</span>
      <h2 class="post__nav__title">Intro to PyTorch-Training your first neural network using PyTorch</h2>
    </div>
  </a>
  

  
</div>
    </div>
  </div>
</div>







<!-- begin related posts -->
<div class="container">
  <section class="related-posts is-related animate">
    <div class="row">
      <div class="col col-12">
        <div class="container__inner">
          <div class="section__info">
            <div class="section__head">
              <h2 class="section__title">You may also like</h2>
              <a class="section__link" href="/blog">
                
                
                  
                    <a href="/tags#pytorch" class="section__link related-tag">See all<span> pytorch</span> <i class="ion ion-md-arrow-forward"></i></a>
                  
                
                  
                
                  
                
              
              </a>
            </div>
          </div>
          <div class="row">

          
            
            
      
            
      
            
            
            
            
      
            
      
            

              <div class="article col col-4 col-d-6 col-t-12">
                <div class="article__inner">
              
                  
                  <div class="image-wrap">
                    <a class="article__image" href="/blog/intro-to-pytorch">
                      <img loading="lazy" src="/images/posts/03_modulization/thumbnail.png" alt="Intro to PyTorch-Training your first neural network using PyTorch">
                    </a>
                  </div>
                  
              
                  <div class="article__content">
              
                    
                    <div class="article-tags__box">
                      
                      <a href="/tag/pytorch" class="article__tag">pytorch</a>
                      
                      <a href="/tag/module" class="article__tag">Module</a>
                      
                    </div>
                    
              
                    <h2 class="article__title">
                      <a href="/blog/intro-to-pytorch">Intro to PyTorch-Training your first neural network using PyTorch</a>
                    </h2>
              
                    <p class="article__excerpt">
                      객체 지향 프로그래밍에서 자체 신경망 계층을 만들어서 재사용하거나 더 복잡한 신경망을 만드는 방법
                    </p>
              
                    <div class="article__meta">
                      <div class="article__author-image">
                        <img loading="lazy" src="/uploads/profile.jpeg" alt="Kim WooHyeon">
                      </div>
                      <div class="article-info">
                        <div class="article__author-name">Kim WooHyeon</div>
                        <span class="article__date"><time datetime="2021-12-31T00:00:00+00:00">31 Dec 2021</time></span>
                      </div>
                    </div>
              
                  </div>
                </div>
              </div>

            
                
              
            
            
            
      
            
      
            

              <div class="article col col-4 col-d-6 col-t-12">
                <div class="article__inner">
              
                  
                  <div class="image-wrap">
                    <a class="article__image" href="/blog/image-handling-convolution">
                      <img loading="lazy" src="/images/posts/04_image_handling/thumbnail.png" alt="이미지 처리와 합성곱 신경망">
                    </a>
                  </div>
                  
              
                  <div class="article__content">
              
                    
                    <div class="article-tags__box">
                      
                      <a href="/tag/pytorch" class="article__tag">pytorch</a>
                      
                      <a href="/tag/module" class="article__tag">Module</a>
                      
                    </div>
                    
              
                    <h2 class="article__title">
                      <a href="/blog/image-handling-convolution">이미지 처리와 합성곱 신경망</a>
                    </h2>
              
                    <p class="article__excerpt">
                      작성
                    </p>
              
                    <div class="article__meta">
                      <div class="article__author-image">
                        <img loading="lazy" src="/uploads/profile.jpeg" alt="Kim WooHyeon">
                      </div>
                      <div class="article-info">
                        <div class="article__author-name">Kim WooHyeon</div>
                        <span class="article__date"><time datetime="2021-12-29T00:00:00+00:00">29 Dec 2021</time></span>
                      </div>
                    </div>
              
                  </div>
                </div>
              </div>

            
                
              
            
            
            
      
            
      
            

              <div class="article col col-4 col-d-6 col-t-12">
                <div class="article__inner">
              
                  
                  <div class="image-wrap">
                    <a class="article__image" href="/blog/modulization-from-nn">
                      <img loading="lazy" src="/images/posts/03_modulization/thumbnail.png" alt="신경망의 모듈화">
                    </a>
                  </div>
                  
              
                  <div class="article__content">
              
                    
                    <div class="article-tags__box">
                      
                      <a href="/tag/pytorch" class="article__tag">pytorch</a>
                      
                      <a href="/tag/module" class="article__tag">Module</a>
                      
                    </div>
                    
              
                    <h2 class="article__title">
                      <a href="/blog/modulization-from-nn">신경망의 모듈화</a>
                    </h2>
              
                    <p class="article__excerpt">
                      객체 지향 프로그래밍에서 자체 신경망 계층을 만들어서 재사용하거나 더 복잡한 신경망을 만드는 방법
                    </p>
              
                    <div class="article__meta">
                      <div class="article__author-image">
                        <img loading="lazy" src="/uploads/profile.jpeg" alt="Kim WooHyeon">
                      </div>
                      <div class="article-info">
                        <div class="article__author-name">Kim WooHyeon</div>
                        <span class="article__date"><time datetime="2021-12-28T00:00:00+00:00">28 Dec 2021</time></span>
                      </div>
                    </div>
              
                  </div>
                </div>
              </div>

            
                
                  
          </div>
        </div>
      </div>
    </div>
  </section>
</div>
<!-- end related posts -->






    <!-- 
        Bookshop components are accessed using the bookshop tag, 
        using the same syntax as the standard Jekyll include tag.
    -->
    <!--bookshop-live name(page.jekyll.html) params(content_blocks=page.content_blocks page_theme=page.page_theme) context() -->
          
          <!--bookshop-live end-->

    <div class="top" title="Top"><i class="ion ion-ios-arrow-up"></i></div>

    <!-- begin footer -->
<footer class="footer">
  <div class="container">
    <div class="row">
      <div class="col col-12">

        <!--bookshop-live name(social-link.jekyll.html) params() context() -->
          
<div class="social">
  <ul class="social__list list-reset">
    
    <li class="social__item">
      <a class="social__link" href="https://twitter.com" target="_blank" rel="noopener" aria-label="twitter icon"><i class="ion ion-logo-twitter"></i></a>
    </li>
    
    <li class="social__item">
      <a class="social__link" href="https://github.com/woohaen88" target="_blank" rel="noopener" aria-label="github icon"><i class="ion ion-logo-github"></i></a>
    </li>
    
    <li class="social__item">
      <a class="social__link" href="https://pinterest.com" target="_blank" rel="noopener" aria-label="pinterest icon"><i class="ion ion-logo-pinterest"></i></a>
    </li>
    
    <li class="social__item">
      <a class="social__link" href="https://youtube.com" target="_blank" rel="noopener" aria-label="youtube icon"><i class="ion ion-logo-youtube"></i></a>
    </li>
    
  </ul>
</div>

          <!--bookshop-live end-->

        <ul class="footer_nav list-reset">
          
          <li class="footer_nav__item">
            <a href="/" class="footer_nav__link">Home</a>
          </li>
          
          <li class="footer_nav__item">
            <a href="/projects/" class="footer_nav__link">Projects</a>
          </li>
          
          <li class="footer_nav__item">
            <a href="/elements/" class="footer_nav__link">Elements</a>
          </li>
          
          <li class="footer_nav__item">
            <a href="/about/" class="footer_nav__link">About</a>
          </li>
          
          <li class="footer_nav__item">
            <a href="/blog/" class="footer_nav__link">Blog</a>
          </li>
          
        </ul>

        <div class="copyright"><p>2021 &copy; <a href="/">Vonge</a>. Template by <a href="https://cloudcannon.com/">CloudCannon</a>. and Modified ururu</p></div>

      </div>
    </div>
  </div>
</footer>
<!-- end footer -->

    <!--
        load the live component for CloudCannon live previews.
    -->
    <script>
(function(){
  const bookshopLiveSetup = (CloudCannon) => {
    CloudCannon.enableEvents();

    const head = document.querySelector('head');
    const script = document.createElement('script');
    script.src = `/_cloudcannon/bookshop-live.js`;
    script.onload = function() {
      window.bookshopLive = new window.BookshopLive({
        remoteGlobals: ['/_cloudcannon/bookshop-site-data.json']
      });
      const updateBookshopLive = async () => {
        const frontMatter = await CloudCannon.value();
        const options = window.bookshopLiveOptions || {};
        await window.bookshopLive.update({page: frontMatter}, options);
        CloudCannon?.refreshInterface?.();
      }
      document.addEventListener('cloudcannon:update', updateBookshopLive);
      updateBookshopLive();
    }
    head.appendChild(script);
  }

  document.addEventListener('cloudcannon:load', function (e) {
    bookshopLiveSetup(e.detail.CloudCannon);
  });
})();
</script>

    <script src="/js/scripts.js"></script>
    <script src="/js/common.js"></script>
</body>
</html>