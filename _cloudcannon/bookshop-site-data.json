{"site":{"posts":[{"draft":false,"categories":[],"layout":"post","date":"2021-12-11 00:00:00 +0000","title":"GCP google instance에 GPU Driver 설치","description":"구글 GCP VM에서 GPU드라이버를 설치","tags":["gcp","GPU monitoring"],"image":"/images/mount-google-storage-into-gcp-vm/google_cloud_logo.png","slug":"gcp-google-instance에-gpu-driver-설치","ext":".md","excerpt":"<h2 id=\"1-gcp-vm에-gpu-설치\">1. GCP-VM에 GPU 설치</h2>\n","content":"<h2 id=\"1-gcp-vm에-gpu-설치\">1. GCP-VM에 GPU 설치</h2>\n\n<p><strong>지원되는 운영체제</strong></p>\n\n<p>해당 VM은 Ubuntu 18.04 LTS 버전에서 설치하였다. <code class=\"language-plaintext highlighter-rouge\">google cloud console</code>에서 <code class=\"language-plaintext highlighter-rouge\">ssh</code>를 눌러 <code class=\"language-plaintext highlighter-rouge\">google cloud terminal</code>을 연다.</p>\n\n<figure style=\"text-align:center;\"><img width=\"2940\" height=\"512\" src=\"/uploads/7.png\" /><figcaption>Figure 1. Google Cloud Console</figcaption></figure>\n\n<p>SSH연결을 누르게 되면 아래와 같은 화면이 나오게 된다.</p>\n\n<figure style=\"text-align:center;\"><img width=\"1800\" height=\"512\" src=\"/uploads/6.png\" /><figcaption>Figure 2. Google Cloud Terminal 열린 모습</figcaption></figure>\n\n<p>구글 VM 할당 후 터미널에서 다음을 입력한다.</p>\n\n<ol>\n  <li>Python 3이 운영체제에 설치되어 있는지 확인</li>\n  <li>설치 스크립트를 다운로드</li>\n</ol>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>curl https://raw.githubusercontent.com/GoogleCloudPlatform/compute-gpu-installation/main/linux/install_gpu_driver.py –output install_gpu_driver.py\n</code></pre></div></div>\n\n<ol>\n  <li>설치 스크립트를 실행\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>python3 install_gpu_driver.py\n</code></pre></div>    </div>\n  </li>\n</ol>\n\n<p>GPU 드라이버 설치가 잘 안된다면 아래 구글 공식문서를 참고한다.\n설치 참조: <a href=\"https://cloud.google.com/compute/docs/gpus/install-drivers-gpu\">https://cloud.google.com/compute/docs/gpus/install-drivers-gpu</a></p>\n\n<p>만약에 <code class=\"language-plaintext highlighter-rouge\">sudo nvidia-smi</code>를 입력했을 때</p>\n<pre><code class=\"language-txt\">NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n</code></pre>\n<p>와 같은 에러가 나타난다면 gpu 드라이버를 지웠다가 다시 설치하자.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt <span class=\"nt\">--installed</span> list | <span class=\"nb\">grep </span>nvidia-driver\nnvidia-driver-<span class=\"o\">{</span>gpu 버전<span class=\"o\">}</span>/unknown,now 495.29.05-0ubuntu1 amd64 <span class=\"o\">[</span>installed,automatic]\n<span class=\"nb\">sudo </span>apt remove nvidia-driver-<span class=\"o\">{</span>gpu 버전<span class=\"o\">}</span>\n<span class=\"nb\">sudo </span>reboot now <span class=\"c\"># 재부팅을 하지 않으면 적용되지 않는다.</span>\n</code></pre></div></div>\n\n<hr />\n\n<h2 id=\"2-gpu-측정항목-모니터링-설정\">2. GPU 측정항목 모니터링 설정</h2>\n\n<p>기본적으로 <strong>Google Cloud Platform</strong>에는 다양한 리소스 모니터링을 제공하지만 <strong>GPU 모니터링은 제공하지 않는다.</strong> 따라서 GPU관련 모듈을 설치하고 <code class=\"language-plaintext highlighter-rouge\">Google Cloud Platform</code>으로 연결한다.</p>\n\n<p>기본적으로 공식문서를 따르면 문제 없을 것이다.\n<a href=\"https://cloud.google.com/compute/docs/gpus/monitor-gpus\">GCP와 GPU 연결</a></p>\n\n<h3 id=\"요구사항\">요구사항</h3>\n\n<p>각 VM에서 다음 요구사항이 충족되는지 확인합니다.</p>\n\n<!-- <blockqutoe/> -->\n<blockquote>\n  <ul>\n    <li>각 VM에는 <a href=\"https://cloud.google.com/compute/docs/gpus/create-vm-with-gpus\">GPU 연결</a>완료된 상태여야 합니다.</li>\n    <li>각 VM에는 <a href=\"https://cloud.google.com/compute/docs/gpus/nstall-drivers-gpu#install-gpu-driver\">GPU 드라이버 설치</a>가 완료된 상태여야 합니다.</li>\n    <li>각 VM에는 Python 3.6 이상이 설치되어 있어야 합니다.</li>\n    <li>각 VM에는 Python 가상 환경을 만드는 데 필요한 패키지가 있어야 합니다.</li>\n  </ul>\n</blockquote>\n\n<p><br /></p>\n\n<h3 id=\"에이전트-다운로드\">에이전트 다운로드</h3>\n\n<p>모니터링 스크립트를 /opt/google 디렉터리에 다운로드합니다. 다음 두 가지 기본 옵션(git, curl)이 있지만 여기서는 <code class=\"language-plaintext highlighter-rouge\">git</code>을 사용하기로 한다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># We need to use sudo to be able to write to /opt </span>\n<span class=\"nb\">sudo mkdir</span> <span class=\"nt\">-p</span> /opt/google \n<span class=\"nb\">cd</span> /opt/google \n<span class=\"nb\">sudo </span>git clone https://github.com/GoogleCloudPlatform/compute-gpu-monitoring.git\n</code></pre></div></div>\n\n<h3 id=\"가상-환경-설정\">가상 환경 설정</h3>\n\n<p>모니터링 스크립트를 사용하려면 필요한 모듈을 설치해야 합니다. 기본 Python 설치와 별개로 이 모듈에 대해 가상 환경을 만드는 것이 좋습니다.pipenv, virtualenv 2개중 하나를 이용할 수 있으나 여기서는 virtualenv를 사용한다.</p>\n\n<p>virtualenv 및 pip를 사용하는 경우 가상 환경을 만들어야 하는데 환경을 만들려면 다음 명령어를 실행한다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">cd</span> /opt/google/compute-gpu-monitoring/linux\n<span class=\"nb\">sudo </span>apt-get <span class=\"nt\">-y</span> <span class=\"nb\">install </span>python3-venv\n<span class=\"nb\">sudo </span>python3 <span class=\"nt\">-m</span> venv venv\n<span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install </span>wheel <span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install</span> <span class=\"nt\">-Ur</span> requirements.txt\n</code></pre></div></div>\n\n<h3 id=\"시스템-부팅-시-에이전트-시작\">시스템 부팅 시 에이전트 시작</h3>\n\n<p>서비스 관리를 위해 systemd를 사용하여 시스템에서는 다음 단계를 수행하여 자동으로 시작되는 서비스 목록에 GPU 모니터링 에이전트를 추가한다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">google_gpu_monitoring_agent_venv.service</code> 파일에는 virtualenv를 사용한 설치를 위해 준비된 systemd에 대한 서비스 정의가 포함되어 있다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">cd</span> /opt/google/compute-gpu-monitoring/linux\n<span class=\"nb\">sudo </span>python3 <span class=\"nt\">-m</span> venv venv\n<span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install </span>wheel\n<span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install</span> <span class=\"nt\">-Ur</span> requirements.txt\n</code></pre></div></div>\n\n<h2 id=\"cloud-monitoring에서-측정항목-검토\">Cloud Monitoring에서 측정항목 검토</h2>\n\n<ol>\n  <li>Google Cloud Console에서 <strong>측정항목 탐색기</strong> 페이지로 이동합니다.<a href=\"https://console.cloud.google.com/monitoring/metrics-explorer\" target=\"console\">Monitoring으로 이동</a></li>\n  <li><strong>리소스 유형</strong> 드롭다운에서 <strong>VM 인스턴스</strong>를 선택합니다.</li>\n</ol>\n\n<figure style=\"text-align:center;\"><img src=\"/uploads/3.png\" /><figcaption>Figure 3. 리소스 유형 선택</figcaption></figure>\n\n<ol>\n  <li><strong>측정항목</strong> 드롭다운에서 <code class=\"language-plaintext highlighter-rouge\">custom/instance/gpu/utilization</code>을 입력합니다.</li>\n</ol>\n\n<figure style=\"text-align:center;\"><img src=\"/uploads/4.png\" /><figcaption>Figure 4. gpu utilization 입력</figcaption></figure>\n\n<figure style=\"text-align:center;\"><img src=\"/uploads/5.png\" /><figcaption>Figure 5. gpu utilization 입력</figcaption></figure>\n\n<p><strong>참고:</strong> 커스텀 측정항목이 표시되는 데 다소 시간이 걸릴 수 있으며, 다음 결과와 유사한 GPU 사용률이 나온다.</p>\n\n","url":"/blog/gcp-google-instance%EC%97%90-gpu-driver-%EC%84%A4%EC%B9%98","relative_path":"_posts/2021-12-11-gcp-google-instance에-gpu-driver-설치.md","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-11 00:00:00 +0000","title":"GCP VM에 Google Cloud Storage Mount","description":"GCP VM에 Google Cloud Storage Mount하기","tags":["gcp","google cloud storage"],"image":"/images/mount-google-storage-into-gcp-vm/google_cloud_logo.png","slug":"mount-google-storage-into-gcp-vm","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Google Compute Engine 에 Cloud Storage 마운트하기</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Google Compute Engine 에 Cloud Storage 마운트하기</h1>\n\n<ol>\n  <li>Cloud Storage bucket</li>\n  <li>Cloud Engine</li>\n  <li>gcsfuse</li>\n</ol>\n\n<h2>1. Compute Engine 만들기</h2>\n<p>Cloude Storage Bucket을 마운트하기 위해서는 gcsfuse가 필요하다.</p>\n\n<blockquote>\n  <em>Cloud Storage FUSE는 Cloud Storage 버킷을 Linux 또는 macOS 시스템에 파일 시스템으로 마운트할 수 있는 오픈소스 FUSE 어댑터입니다. Google Compute Engine VM 또는 온프레미스 시스템1을 포함하여 Cloud Storage와 연결된 모든 위치에서 Cloud Storage FUSE를 실행할 수 있습니다.\n  <a href=\"https://cloud.google.com/storage/docs/gcs-fuse#using_feat_name\">https://cloud.google.com/storage/docs/gcs-fuse#using_feat_name</a>  \n  </em>\n</blockquote>\n\n<p>먼저 Google Cloud VM에 접속한다.</p>\n\n<ol>\n  <li>gcsfuse 배포 URL을 패키지 소스로 추가하고 공개 키를 가져온다.\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">export </span><span class=\"nv\">GCSFUSE_REPO</span><span class=\"o\">=</span>gcsfuse-<span class=\"sb\">`</span>lsb_release <span class=\"nt\">-c</span> <span class=\"nt\">-s</span><span class=\"sb\">`</span>\n<span class=\"nb\">echo</span> <span class=\"s2\">\"deb http://packages.cloud.google.com/apt </span><span class=\"nv\">$GCSFUSE_REPO</span><span class=\"s2\"> main\"</span> | <span class=\"nb\">sudo tee</span> /etc/apt/sources.list.d/gcsfuse.list\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | <span class=\"nb\">sudo </span>apt-key add -\n</code></pre></div>    </div>\n  </li>\n  <li>사용 가능한 패키지 목록을 업데이트 하고 gcsfuse를 설치한다.\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt-get update\n<span class=\"nb\">sudo </span>apt-get <span class=\"nt\">-y</span> <span class=\"nb\">install </span>gcsfuse\n</code></pre></div>    </div>\n  </li>\n  <li>gcsfuse에 대한 향후 업데이트는 다음과 같은 일반적인 방법으로 설치할 수 있다.\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt-get update <span class=\"o\">&amp;&amp;</span> <span class=\"nb\">sudo </span>apt-get <span class=\"nt\">-y</span> upgrade\n</code></pre></div>    </div>\n  </li>\n</ol>\n\n<hr />\n\n<h2>2. 버킷 마운트하기</h2>\n<h3>사전준비</h3>\n<p>처음에 google-cloud와 로그인 인증을 해준다.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>gcloud auth login\n</code></pre></div></div>\n<p>크롬 브라우저에서 로그인 설정을 해준다. 이게 완료되어야 다음단계로 진행된다.</p>\n<h3>버킷마운트</h3>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">mkdir</span> <span class=\"nt\">-p</span> /path/to/mount/point\ngcsfuse <span class=\"nt\">--implicit-dirs</span> <span class=\"o\">{</span>google_cloud_bucket<span class=\"o\">}</span> /path/to/mount/point\n</code></pre></div></div>\n\n<p>gcsfuse 를 이용하면 google cloud storage 를 파일시스템으로 mount를 시킬 수 있다. 이 때 중요한 것은 –implicit-dirs 옵션을 붙여주여야 디렉토리 구조가 보인다는 것이다.</p>\n\n<p>언마운트는 다음과 같이 진행한다.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>fusermount <span class=\"nt\">-u</span> /path/to/mount/point\n</code></pre></div></div>\n","url":"/blog/mount-google-storage-into-gcp-vm","relative_path":"_posts/2021-12-12-mount-google-storage-into-gcp-vm.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-21 00:00:00 +0000","title":"Linear Regression(Basic)","description":"GCP VM에 Google Cloud Storage Mount하기","tags":["pytorch"],"image":"/images/posts/Linear_regression/thumbnail.png","slug":"Linear_regression","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Linear Regression(Basic)</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Linear Regression(Basic)</h1>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n</code></pre></div></div>\n\n<figure style=\"text-align:center;\"><img width=\"2940\" height=\"512\" src=\"/images/posts/Linear_regression/loss_and_epoch.png\" />\n  <figcaption style=\"font-size: 0.8rem; margin-top: 1rem;\">Figure 1. epoch에 따른 loss의 변화)</figcaption>\n</figure>\n","url":"/blog/linear-regression","relative_path":"_posts/2021-12-21-Linear_regression.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-26 00:00:00 +0000","title":"Dataset과 과대적합","description":"Pytorch에서 제공하는 Dataset과 DataLoader 이해하기","tags":["pytorch","Dataset","DataLoader","Dropout","BatchNormalization"],"image":"/images/posts/02_dataset_and_dataloader/thumbnail.png","slug":"Dataset_and_DataLoader","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>Dataset과 과대적합</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>Dataset과 과대적합</h1>\n\n<p>데이터가 소량일 때는 전체데이터를 학습해도 되지만, 데이터량이 많아지거나, 신경망 계층의 증가, 또는 파라미터가 늘어나면 전체 데이터를 메모리에서 처리하기 어려워진다. 이 문제를 해결하기 위한 방법이 <strong><em>mini-batch</em></strong>이다. 또한 머신러닝을 하다보면 항상 피할 수없는 것이 과대적합이다. 과대적합에 대해 간단히 알아보고 이를 해결하는 방법을 PyTorch를 통해 알아보자.</p>\n\n<h2 id=\"1-dataset과-dataloader\">1. Dataset과 DataLoader</h2>\n\n<p>파이토치에는 Dataset과 DataLoader라는 기능이 있어서 미니 배치 학습이나 데이터를 무작위로 섞고, 그리고 병령처리까지 수행할 수 있다.\n<strong>TensorDataset</strong>은 <strong>Dataset</strong>을 상속한 클래스로 학습 데이터 X와 레이블 Y를 묶어놓은 데이터 오브젝트이다. 이 <strong>TensorDataset</strong>을 <strong>DataLoader</strong>에 전달하면 for 루프에서 데이터의 일부만 간단히 추출할 수 있게 된다.</p>\n<blockquote>\n  <p><span style=\"color: crimson;\">[!caution]</span><br />\nTensorDataset에는 <strong>텐서</strong>만 전달할 수 있으며 Variable은 전달할 수 없다.</p>\n</blockquote>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span><span class=\"p\">,</span> <span class=\"n\">optim</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">TensorDataset</span><span class=\"p\">,</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_digits</span>\n\n<span class=\"c1\"># Dataset 작성\n</span><span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">load_digits</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">data</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">target</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">int64</span><span class=\"p\">)</span>\n\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 순서로 섞어서 64개씩 데이터를 반환하는 DataLoader 작성\n</span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<hr />\n\n<h2 id=\"2-dropout을-사용한-정규화\">2. Dropout을 사용한 정규화</h2>\n<p>신경망은 표현력이 매우 높은 모델이지만, 한편으로는 ‘훈련된 데이터와만’ 궁합이 좋아서 다른 데이터에 적용할 수 없거나 훈련이 불안정해서 시간이 오래 걸리는 문제가 있다. 여기서는 이런 문제를 해결하기 위한 두 가지 대표적인 기법인 <strong>Dropout</strong>과 <strong>Batch Normalization</strong>에 대해 다룬다.</p>\n\n<p>신경망뿐만 아니라 머신러닝의 공통적인 문제로 <span style=\"color:crimson;\">과적합(overfitting)</span>을 들 수 있다. 과학습이란 훈련용 데이터에 파라미터가 과하게 최적화되어 다른 데이터에 대한 판별 능력이 떨어지게 되는 현상이다. 예를 들어, 사람이 시험 공부를 할 때 원리는 파악하지 않고 유형만 학습하여 응용력이 떨어지는 것과 같다. 특히, 층이 깊은 신경망은 파라미터가 많아서 충분한 데이터가 없으면 과학습이 발생할 수 있다. 과대적합을 막는데에는 다양한 방법이 있지만, 신경망에서는 Dropout이라는 것이 자주 사용된다. 몇 개의 노드(변수의 차원)를 랜덤으로 선택해서 의도적으로 사용하지 않는 방법이다. Dropout은 신경망 훈련 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적이다. 파이토치에서는 모델의 train과 eval 메서드로 Dropout을 적용 또는 미적용할 수 있다.</p>\n\n<p>코드로는 다음과 같이 구현한다.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_digits</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span><span class=\"p\">,</span> <span class=\"n\">optim</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">TensorDataset</span><span class=\"p\">,</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n\n<span class=\"c1\"># Dataset 작성\n</span><span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">load_digits</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">data</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">target</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">int64</span><span class=\"p\">)</span>\n\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">Y_train</span><span class=\"p\">,</span> <span class=\"n\">Y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">)</span>\n\n<span class=\"n\">X_train</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y_train</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y_train</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">X_test</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y_test</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y_test</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 순서로 섞어서 64개씩 데이터를 반환하는 DataLoader 작성\n</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># train과 eval 메서드로 Dropout 처리 적용\n</span><span class=\"n\">loss_fn</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"p\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># 훈련용 데이터로 DataLoader를 작성\n</span><span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">Y_train</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_losses</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"n\">test_losses</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n    <span class=\"n\">running_loss</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n    <span class=\"c1\"># 신경망을 훈련 모드로 설정\n</span>    <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">xx</span><span class=\"p\">,</span> <span class=\"n\">yy</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">):</span>\n        <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">xx</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">loss_fn</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">yy</span><span class=\"p\">)</span>\n        <span class=\"n\">optimizer</span><span class=\"p\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n        <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n        <span class=\"n\">optimizer</span><span class=\"p\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n        <span class=\"n\">running_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n\n    <span class=\"n\">train_losses</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">running_loss</span> <span class=\"o\">/</span> <span class=\"n\">i</span><span class=\"p\">)</span>\n    <span class=\"c1\"># 신경망을 평가 모드로 설정하고\n</span>    <span class=\"c1\"># 검정 데이터의 손실 함수를 계산\n</span>    <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"nb\">eval</span><span class=\"p\">()</span>\n    <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n    <span class=\"n\">test_loss</span> <span class=\"o\">=</span> <span class=\"n\">loss_fn</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">Y_test</span><span class=\"p\">)</span>\n    <span class=\"n\">test_losses</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">test_loss</span><span class=\"p\">.</span><span class=\"n\">item</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<hr />\n<ol>\n  <li>Batch Normalization을 사용한 학습 가속</li>\n</ol>\n\n<p><strong>SGD</strong>를 사용한 신경망 학습에서는 각 변수의 차원이 동일한 범위의 값을 가지는 것이 중요하다. 변수 한개의 값이 너무 크게 되면 그 값이 모델의 결과를 지배하기 때문이다. 한 층으로 된 선형 모델 등에서는 사전에 데이터를 정규화해 두면되지만 깊은 신경망에서는 층이 늘어날 수록 데이터 분포가 바뀐다. 그렇기 때문에 입력 데이터의 정규화만으로는 부족하다. 또한, 앞에 있는 층의 학스에 의해 파라미터가 변화하므로 뒤에 있는 층의 학습이 불안정해지는 문제가 있다. 이런 문제를 해결하고 학습을 안정화하는 방법으로 <span style=\"color:crimson;\"><b>Batch Normalization</b></span>이 있다.\n마찬가지로 <strong>Batch Normalization</strong>도 훈련 시에만 적용하며, 평가 시에는 사용하지 않는다. 따라서 <span style=\"color:crimson;\"><b>Dropout</b></span></p>\n\n<p>코드는 바뀐 부분이 거의 없으며 <em>net</em>의 표현 방벙만 <code class=\"language-plaintext highlighter-rouge\">nn.Dropout() =&gt; nn.BatchNorm1d</code>으로 바뀐다.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>지금까지는 PyTorch를 다루는데 있어서 기본적인 머신러닝에 대해서 알아보았다. 그리고 모델 노드 구성을 Sequential로 코드를 작성했는데, PyTorch의 경우는 <code class=\"language-plaintext highlighter-rouge\">Class</code>기반으로 코드를 짜는 것이 많이 알려져있다. 따라서 다음 포스팅부터는 <code class=\"language-plaintext highlighter-rouge\">Class</code>를 이용한 커스텀 계층을 만들어 보겠다.</p>\n","url":"/blog/dataset-and-dataloader","relative_path":"_posts/2021-12-26-Dataset_and_DataLoader.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-28 00:00:00 +0000","title":"신경망의 모듈화","description":"객체 지향 프로그래밍에서 자체 신경망 계층을 만들어서 재사용하거나 더 복잡한 신경망을 만드는 방법","tags":["pytorch","Module"],"image":"/images/posts/03_modulization/thumbnail.png","slug":"Modulization-from-nn","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>1. 커스텀 계층 만들기</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>1. 커스텀 계층 만들기</h1>\n\n<p>파이토치에서 자체 신경망을 만들려면 <code class=\"language-plaintext highlighter-rouge\">nn.Module</code>을 상속해서 클래스를 정의한다. nn.Module을 상속하게 되면 forward 메서드를 구현하면 자동 미분까지 가능해진다.</p>\n\n<blockquote>\n  <p>이미 특정 Variable형의 x를 net(x) 형식으로 사용했다. nn.Module의 <code class=\"language-plaintext highlighter-rouge\">__call__</code> 메서드는 내부에서 forward 메서드를 사용하고 있으므로 <code class=\"language-plaintext highlighter-rouge\">net(x)</code> 형식이 가능하다.</p>\n</blockquote>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span>\n\n\n<span class=\"c1\"># 방법 1\n</span><span class=\"k\">class</span> <span class=\"nc\">CustoemLinear</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">in_features</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">CustoemLinear</span><span class=\"p\">).</span><span class=\"n\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">linear</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">drop</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">linear</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n\n<span class=\"n\">mlp</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">),</span>\n    <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">),</span>\n    <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># 방법2\n</span><span class=\"k\">class</span> <span class=\"nc\">MLP</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">in_features</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">MLP</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">).</span><span class=\"n\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln1</span> <span class=\"o\">=</span> <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln2</span> <span class=\"o\">=</span> <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln3</span> <span class=\"o\">=</span> <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">200</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln4</span> <span class=\"o\">=</span> <span class=\"n\">CustoemLinear</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln3</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ln4</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n\n<span class=\"n\">mlp</span> <span class=\"o\">=</span> <span class=\"n\">MLP</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n</code></pre></div></div>\n","url":"/blog/modulization-from-nn","relative_path":"_posts/2021-12-28-Modulization-from-nn.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-29 00:00:00 +0000","title":"이미지 처리와 합성곱 신경망","description":"작성","tags":["pytorch","Module"],"image":"/images/posts/04_image_handling/thumbnail.png","slug":"image_handling_convolution","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>이미지 처리와 합성곱 신경망</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>이미지 처리와 합성곱 신경망</h1>\n\n<p>2012년에 ILSVRC라는 이미지 인식 대회에서 다층 CNN을 사용한 모델이 다른 모델들을 압도하면서 딥러닝이 주목받게 된 기폭제가 됐다. 현재도 딥러닝이 가장 활발히 사용되는 분야가 컴퓨터 비전 분야로 특히, CNN이 활발히 연구되고 있다.</p>\n\n<h2 id=\"1-이미지와-합성곱-계산\">1. 이미지와 합성곱 계산</h2>\n\n<p>이미지 분야에서 합성곱(Convolution)이란, 이미지 위에 작은 커널(필터)을 이동시켜 가면서 각 요소(픽셀)의 곱(또는 합이나 평균 등)을 계산해 가는 방식이다.</p>\n\n<h2 id=\"2-cnn을-사용한-이미지-분류\">2. CNN을 사용한 이미지 분류</h2>\n\n<p>CNN을 사용한 이미지 분류는 기본적으로 합성곱으로부터 ReLU 등의 활성화 함수를 적용하는 과정을 여러 번 실시한다. 이미지 데이터는 (C, H, W) 형식으로 H, W는 이미지의 세로, 가로 크기이며, C는 색수 또는 채널(channel)이라고도 불린다. 원래 C=1이나 C=3이지만, 최종적으로는 <span style=\"color:crimson;\">마지막 합성공 계층의 커널 수</span>가 된다. 합성곱 처리 후에는 위치 감도를 높이는 풀링(pooling)을 적용하거나, Dropout, Batch Normalization을 함께 사용하는 경우도 많다.</p>\n\n<h3 id=\"21-fashion-mnist\">2.1 Fashion-Mnist</h3>\n\n<p>MNIST는 28X28픽셀의 흑백 손글씨 숫자 데이터이다. 이 데이터는 이미지 분류 시에 사용되는 머신러닝을 입문한다면 제일 처음에 만나게되는 대표적인 예제 데이터이다. 최근에는 이 MNIST가 너무 간단하다는 지적도 있어서 10가지 분류의 옷 및 엑세서리를 이미지 데이터로 이루어진 <span style=\"color:darkblue;\"><b>Fashion-MNIST</b></span></p>\n\n<figure>\n<img src=\"/images/posts/04_image_handling/fashion_mnist.png\" />\n\t<span style=\"font-size: 0.8em; color:gray;\"><figcaption align=\"center\">\n\t\tFigure 1: Fashion_MNIST\n\t</figcaption></span>\n</figure>\n\n<p>파이토치의 확장 기능인 torchvision이라는 라이브러리를 사용하면 Fashion-MNIST 데이터 다운로드부터, Dataset으로 변환, DataLoader 작성까지 할 수 있다.</p>\n\n","url":"/blog/image-handling-convolution","relative_path":"_posts/2021-12-28-image_handling_convolution.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-31 00:00:00 +0000","title":"Intro to PyTorch-Training your first neural network using PyTorch","description":"객체 지향 프로그래밍에서 자체 신경망 계층을 만들어서 재사용하거나 더 복잡한 신경망을 만드는 방법","tags":["pytorch","Module"],"image":"/images/posts/03_modulization/thumbnail.png","slug":"Intro_to_PyTorch","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n","content":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>tree <span class=\"nb\">.</span> <span class=\"nt\">--dirsfirst</span>\n<span class=\"nb\">.</span>\n├── ururuMllib\n│   └── mlp.py\n└── train.py\n1 directory, 2 files\n</code></pre></div></div>\n\n<p><code class=\"language-plaintext highlighter-rouge\">mlp.py</code> 파일은 기본 MLP(다층 퍼셉트론) 구현을 저장한다.\n그런 다음 데이터 세트에서 MLP를 훈련하는 데 사용할 <code class=\"language-plaintext highlighter-rouge\">train.py</code>를 구현한다.</p>\n\n<figure style=\"text-align: center\">\n<img src=\"/images/posts/05_Intro_to_PyTorch/implementing_neuralnet_pytorch.png\" width=\"70%\" />\n\t<span style=\"font-size: 0.8em; color:gray;\"><figcaption align=\"center\">\n\t\tFigure 1: Implementing a basic multi-layer perceptron with PyTorch.\n\t</figcaption></span>\n</figure>\n\n<p>이제 PyTorch로 첫 번째 신경망을 구현할 준비가 되었다.\n이 네트워크는 다층 퍼셉트론(MLP)이라고 하는 매우 단순한 피드포워드 신경망입니다(하나 이상의 은닉층이 있음을 의미).</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># import the necessary packages\n</span><span class=\"kn\">from</span> <span class=\"nn\">collections</span> <span class=\"kn\">import</span> <span class=\"n\">OrderedDict</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"n\">nn</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">get_training_model</span><span class=\"p\">(</span><span class=\"n\">inFeatures</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">hiddenDim</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">nbClasses</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">):</span>\n\t<span class=\"c1\"># construct a shallow, sequential neural network\n</span>\t<span class=\"n\">mlpModel</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span><span class=\"n\">OrderedDict</span><span class=\"p\">([</span>\n\t\t<span class=\"p\">(</span><span class=\"s\">\"hidden_layer_1\"</span><span class=\"p\">,</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">inFeatures</span><span class=\"p\">,</span> <span class=\"n\">hiddenDim</span><span class=\"p\">)),</span>\n\t\t<span class=\"p\">(</span><span class=\"s\">\"activation_1\"</span><span class=\"p\">,</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">()),</span>\n\t\t<span class=\"p\">(</span><span class=\"s\">\"output_layer\"</span><span class=\"p\">,</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">hiddenDim</span><span class=\"p\">,</span> <span class=\"n\">nbClasses</span><span class=\"p\">))</span>\n\t<span class=\"p\">]))</span>\n\n\t<span class=\"c1\"># return the sequential model\n</span>\t<span class=\"k\">return</span> <span class=\"n\">mlpModel</span>\n</code></pre></div></div>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">OrderedDict</code>: A dictionary object - 객체가 추가된 순서를 기억한다. 우리는 이 정렬된 dictionary를 사용하여 네트워크의 각 계층에 사람이 읽을 수 있는 이름을 제공한다.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">nn</code>: PyTorch’s neural network implementations, 그런 다음 세 개의 매개변수를 허용하는 <code class=\"language-plaintext highlighter-rouge\">get_training_model</code> 함수를 정의한다.</li>\n</ul>\n\n<p>정의된 파라미터는 다음과 같다.</p>\n<ol>\n  <li>신경망에 대한 입력 노드의 수</li>\n  <li>네트워크의 은닉층에 있는 노드의 수</li>\n  <li>출력 노드의 수</li>\n</ol>\n\n<p>제공된 디폴트 값에 의하면 4-8-3 뉴럴넷은 Input 레이어는 4, Hidden 레이어는 8, Output 레이어는 3으로 구성되어있다.</p>\n\n<p>The actual neural network architecture is then constructed on Lines 7-11 by first initializing a nn.Sequential object (very similar to Keras/TensorFlow’s Sequential class).</p>\n\n<p>Inside the Sequential class we build an OrderedDict where each entry in the dictionary consists of two values:</p>\n\n<p>A string containing the human-readable name for the layer (which is very useful when debugging neural network architectures using PyTorch)\nThe PyTorch layer definition itself\nThe Linear class is our fully connected layer definition, meaning that each of the inputs connects to each of the outputs in the layer. The Linear class accepts two required arguments:</p>\n\n<p>The number of inputs to the layer\nThe number of outputs\nOn Line 8, we define hidden_layer_1 which consists of a fully connected layer accepting inFeatures (4) inputs and then producing an output of hiddenDim (8).</p>\n\n<p>From there, we apply a ReLU activation function (Line 9) followed by another Linear layer which serves as our output (Line 10).</p>\n\n<p>Notice that the second Linear definition contains the same number of inputs as the previous Linear layer did outputs — this is not by accident! The output dimensions of the previous layer must match the input dimensions of the next layer, otherwise PyTorch will error out (and then you’ll have the quite tedious task of debugging the layer dimensions yourself).</p>\n\n<p>PyTorch is not as forgiving in this regard (as opposed to Keras/TensorFlow), so be extra cautious when specifying your layer dimensions.</p>\n\n<p>The resulting PyTorch neural network is then returned to the calling function.</p>\n\n","url":"/blog/intro-to-pytorch","relative_path":"_posts/2021-12-31-Intro_to_PyTorch.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2022-01-01 00:02:00 +0000","title":"PyTorch-Training first Convolutional Neural Network (CNN)","description":"pytorch에서 KMNIST를 불러와서 이미지를 불러오고, opencv를 이용하여 간단한 시각화를 해본다.","tags":["pytorch","Module","CNN"],"image":"/images/posts/06_cnn_pytorch/thumbnail.png","slug":"CNN-pytorch","ext":".markdown","excerpt":"<p>이번 포스트에서는 CNN학습을 어떻게 하고, 손으로 쓴 히라가나 글씨를 분류하는 것을 목표로한다. 일반적으로 알다시피 숫자형 데이터와는 다르지만 그렇다고 해서 PyTorch에서 구현하는 모델링을 하고 분류하는 방법자체가 많이 달라지지 않는다. 여전히 우리는 이러한 단계를 따른다.</p>\n","content":"<p>이번 포스트에서는 CNN학습을 어떻게 하고, 손으로 쓴 히라가나 글씨를 분류하는 것을 목표로한다. 일반적으로 알다시피 숫자형 데이터와는 다르지만 그렇다고 해서 PyTorch에서 구현하는 모델링을 하고 분류하는 방법자체가 많이 달라지지 않는다. 여전히 우리는 이러한 단계를 따른다.</p>\n\n<ol>\n  <li>모델 아키텍쳐 정의</li>\n  <li>데이터 로드(클라우드, 혹은 디스크)</li>\n  <li>epochs와 batches의 반복문을 실행한다.</li>\n  <li>손실함수를 계산</li>\n  <li>미분계수를 0으로 만들고, 역전파를 실행 그리고 나서 모델 파라미터를 업데이트한다.</li>\n</ol>\n\n<p>데이터셋을 쉽게 다루게 해주는 DataLoader를 로드한다. 이 DataLoader는 PyTorch를 사용하는데 있어서 아주 중요한 skill이다.</p>\n\n<h2 id=\"1-training-convolutional-neural-networkcnn\">1. Training Convolutional Neural Network(CNN)</h2>\n\n<p>CNN을 구성하기 위해서는 필수 라이브러리가 필요하다. 바로 torch와 torchvision이다. 그리고 데이터분할을 손쉽게 다루는 scikit-learn와 이미지 그래픽을 위한 opencv또한 설치하도록 하자.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>pip <span class=\"nb\">install </span>torch torchvision\n<span class=\"nv\">$ </span>pip <span class=\"nb\">install </span>opencv-contrib-python\n<span class=\"nv\">$ </span>pip <span class=\"nb\">install </span>scikit-learn\n<span class=\"nv\">$ </span>pip <span class=\"nb\">install </span>imutils\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3 id=\"the-kmnist-dataset\">The KMNIST dataset</h3>\n\n<figure style=\"text-align: center\">\n<img src=\"/images/posts/06_cnn_pytorch/kmnist_dataset.png\" width=\"100%\" />\n\t<span style=\"font-size: 0.8em; color:gray;\"><figcaption align=\"center\">\n\t\tFigure 1: The KMNIST dataset\n\t</figcaption></span>\n</figure>\n\n<p>KMNIST는 Kuzushiji-MNIST dataset의 줄임말이다. KMNIST dataset은 기존의 MNIST와 마찬가지로 70,000개의 이미지와 각각 상응하는 라벨이 있다.(60,000개의 훈련 이미지와 10,000개의 라벨 이미지)</p>\n\n<p>KMNIST에는 10개의 클래스가 있고, 균등하게 분배되어 있다. 우리는 CNN을 이용해서 이 것을 60,000개의 이미지를 10개로 올바르게 분류하는게 목표다.</p>\n\n<p>프로젝트의 구조는 다음과 같다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>tree <span class=\"nb\">.</span> <span class=\"nt\">--dirsfirst</span>\n<span class=\"nb\">.</span>\n├── output\n│   ├── model.pth\n│   └── plot.png\n├── ururuMllib\n│   ├── __init__.py\n│   └── lenet.py\n├── predict.py\n└── train.py\n2 directories, 6 files\n</code></pre></div></div>\n\n<p>가장 먼저 살펴볼 script는 다음과 같다.</p>\n\n<ol>\n  <li>lenet.py : 유명한 LeNet architecture</li>\n  <li>train.py : KMNIST를 훈련하는 script</li>\n  <li>predict.py : train model을 로드하고, 스크린에 결과를 보여준다.</li>\n</ol>\n\n<p><code class=\"language-plaintext highlighter-rouge\">output</code> 디렉터리에는 <code class=\"language-plaintext highlighter-rouge\">plot.png</code>(training/validation loss and accuracy)와 <code class=\"language-plaintext highlighter-rouge\">model.pth</code>가 만들어진다.</p>\n\n<h2 id=\"2-implementing-a-convolutional-neural-networkcnn\">2. Implementing a Convolutional Neural Network(CNN)</h2>\n\n<figure style=\"text-align: center\">\n<img src=\"/images/posts/06_cnn_pytorch/Implementing_a_convnet.png\" width=\"100%\" />\n\t<span style=\"font-size: 0.8em; color:gray;\"><figcaption align=\"center\">\n\t\tFigure 2: The LeNet architecture\n\t</figcaption></span>\n</figure>\n\n<p>Lenet 아키텍쳐는 다음과 같은 Layer 구조를 따른다.</p>\n\n<blockquote class=\"shadow-grey\">\n  <p>(CONV =&gt; RELU =&gt; POOL) * 2 =&gt; FC =&gt; RELU =&gt; FC =&gt; SOFTMAX</p>\n</blockquote>\n\n<p>CNN을 구현해보자. 첫번째로 먼저 필요한 라이브러리를 import 한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># import the necessary packages\n</span><span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">Module</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">Conv2d</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">Linear</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">MaxPool2d</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">ReLU</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">LogSoftmax</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">flatten</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tqdm</span> <span class=\"kn\">import</span> <span class=\"n\">tqdm</span>\n</code></pre></div></div>\n\n<ul>\n  <li><span class=\"shadow-grey\">Module</span>: <span class=\"shadow-grey\">Sequential</span>을 사용하기보다는 <span class=\"shadow-grey\">Module</span> 의 서브클래스를 불러와서 사용한다.</li>\n  <li><span class=\"shadow-grey\">Conv2d</span>: PyTorch의 CNN Layer</li>\n  <li><span class=\"shadow-grey\">Linear</span>: Fully connected Layer</li>\n  <li><span class=\"shadow-grey\">MaxPool2d</span>: 2D max-pooling을 적용</li>\n  <li><span class=\"shadow-grey\">ReLU</span>: ReLU 활성화함수</li>\n</ul>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">LeNet</span><span class=\"p\">(</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n\t<span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">numChannels</span><span class=\"p\">,</span> <span class=\"n\">classes</span><span class=\"p\">):</span>\n\t\t<span class=\"c1\"># call the parent constructor\n</span>\t\t<span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">LeNet</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">).</span><span class=\"n\">__init__</span><span class=\"p\">()</span>\n\n\t\t<span class=\"c1\"># initialize first set of CONV =&gt; RELU =&gt; POOL layers\n</span>\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"n\">numChannels</span><span class=\"p\">,</span> <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span>\n\t\t\t<span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu1</span> <span class=\"o\">=</span> <span class=\"n\">ReLU</span><span class=\"p\">()</span>\n\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">maxpool1</span> <span class=\"o\">=</span> <span class=\"n\">MaxPool2d</span><span class=\"p\">(</span><span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n\n\t\t<span class=\"c1\"># initialize second set of CONV =&gt; RELU =&gt; POOL layers\n</span>\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n\t\t\t<span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu2</span> <span class=\"o\">=</span> <span class=\"n\">ReLU</span><span class=\"p\">()</span>\n\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">maxpool2</span> <span class=\"o\">=</span> <span class=\"n\">MaxPool2d</span><span class=\"p\">(</span><span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n\n\t\t<span class=\"c1\"># initialize first (and only) set of FC =&gt; RELU layers\n</span>\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">800</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu3</span> <span class=\"o\">=</span> <span class=\"n\">ReLU</span><span class=\"p\">()</span>\n\n\t\t<span class=\"c1\"># initialize our softmax classifier\n</span>\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">fc2</span> <span class=\"o\">=</span> <span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"n\">classes</span><span class=\"p\">)</span>\n\t\t<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">logSoftmax</span> <span class=\"o\">=</span> <span class=\"n\">LogSoftmax</span><span class=\"p\">(</span><span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이 코드블럭은 <span class=\"shadow-grey\">LeNet</span> 클래스를 정의한다. 이렇게 <span class=\"shadow-grey\">Module</span>을 상속해서 우리는 여러가지 이점을 얻을 수 있다.</p>\n\n<ul>\n  <li>변수 재활용</li>\n  <li>사용자 정의 함수나 subnetwork/components를 쉽게 만들 수 있다.</li>\n  <li>사용자 정의 함수로 <span class=\"shadow-grey\">forward</span>를 만들 수 있다.</li>\n</ul>\n\n<p><strong><em>이중 가장 좋은 점은 우리가 올바르게 모델 아키텍쳐를 정의하기만 하면 파이토치는 자동적으로 자동 미분과 역전파를 수행한다.</em></strong></p>\n\n<p><span class=\"shadow-grey\">LeNet</span>클래스는 2가지 변수를 받는다.</p>\n\n<ol>\n  <li><span class=\"shadow-grey\">numChannels</span>: input이미지의 채널수(1: grayscale, 3: RGB)</li>\n  <li><span class=\"shadow-grey\">classes</span>: 중복이 되지 않는 데이터셋의 고유 클래스</li>\n</ol>\n\n<p>위 코드는 <span class=\"shadow-grey\">CONV =&gt; RELU =&gt; POOL</span> 레이어를 초기화한다. 첫 번재 CONV ㄹ이어는 총 5x5로 이루어진 20개의 필터를 학습한다. 그리고 나서 이미지차원을 줄이기 위해 ReLU 활성화함수를 적용하고 그 후에는 2x2 max-pooling 레이어와 2x2 stride를 적용한다.</p>\n\n<p>그리고나서는 <span class=\"shadow-grey\">CONV =&gt; RELU =&gt; POOL</span> 레이어를 또 한번 반복하는데 이때는 나머지는 그대로 두고 레이어 수가 50개로 증가한다.</p>\n\n<p>그 다음 스텝으로 우리는 완전 연결 레이어를 추가한다. 이 때 input은 800, output은 500으로 한다.</p>\n\n<p>마지막에는 클래스 함수에서 확률을 얻기 위해<span class=\"shadow-grey\">LogSoftmax</span>를 적용한다.</p>\n\n<p>이 시점에서 짚고 넘어갈 일은 초기화된 변수라는 것을 이해하는 것이 중요하다.이러한 변수는 본질적으로 <span class=\"shadow-grey\">place holder</span>이다. PyTorch는 네트워크 아키텍처가 무엇인지 전혀 알지 못한다. 단지 일부 변수가 LeNet 클래스 정의 내에 존재한다는 것뿐이다.</p>\n\n<p>네트워크 아키텍처 자체를 구축하려면(즉, 어떤 레이어가 다른 레이어에 입력되는지) Module 클래스의 forward 메서드를 재정의해야 한다.</p>\n\n<p><span class=\"shadow-grey\">forward</span> 함수는 다음과 같은 목적을 가지고 있다.</p>\n\n<ol>\n  <li>클래스의 생성자(예: __init__)에 정의된 변수에서 레이어/서브네트워크를 함께 연결한다.</li>\n  <li>네트워크 아키텍처 자체를 정의한다.</li>\n  <li>이를 통해 모델의 순방향 전달이 수행되어 결과적으로 출력 예측이 가능하다.</li>\n  <li>그리고 PyTorch의 autograd 모듈 덕분에 자동 미분을 수행하고 모델 가중치를 업데이트할 수 있다.</li>\n</ol>\n\n<p><span class=\"shadow-grey\">forward</span>는 코드로 구현하면 다음과 같다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\t<span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n\t\t<span class=\"c1\"># pass the input through our first set of CONV =&gt; RELU =&gt;\n</span>\t\t<span class=\"c1\"># POOL layers\n</span>\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">maxpool1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># pass the output from the previous layer through the second\n</span>\t\t<span class=\"c1\"># set of CONV =&gt; RELU =&gt; POOL layers\n</span>\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">maxpool2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># flatten the output from the previous layer and pass it\n</span>\t\t<span class=\"c1\"># through our only set of FC =&gt; RELU layers\n</span>\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">flatten</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">relu3</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># pass the output to our softmax classifier to get our output\n</span>\t\t<span class=\"c1\"># predictions\n</span>\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">logSoftmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># return the output predictions\n</span>\t\t<span class=\"k\">return</span> <span class=\"n\">output</span>\n</code></pre></div></div>\n\n<p><span class=\"shadow-grey\">forward</span>함수는 한개의 파라미터 <span class=\"shadow-grey\">x</span>를 받아 들인다. 그리고 이 것은 network의 input데이터이다. 그리고 나서 <span class=\"shadow-grey\">conv1</span>, <span class=\"shadow-grey\">relu1</span>, <span class=\"shadow-grey\">maxpool1</span>레이어를첫번째 등장하는 <span class=\"shadow-grey\">CONV =&gt; RELU =&gt; POOL</span> 레이어에 연결한다.</p>\n\n<p><span class=\"shadow-grey\">CONV =&gt; RELU =&gt; POOL</span> 레이어는 다차원 텐서다. 완전연결레이어에 연결하기 위해서 <span class=\"shadow-grey\">flatten</span>메서드를 사용해야한다.</p>\n\n<p>이렇게 하기 위해서 우리는 <span class=\"shadow-grey\">fc1</span>와 <span class=\"shadow-grey\">relu3</span>레이어를 연결해야한다. 다음에는 <span class=\"shadow-grey\">fc2</span>와 <span class=\"shadow-grey\">logSoftmax</span>를 연결한다. <span class=\"shadow-grey\">output</span>은 호출함수를 리턴한다.</p>\n\n<h3 id=\"creating-our-cnn-training-script-with-pytorch\">Creating our CNN training script with PyTorch</h3>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># USAGE\n# python train.py --model output/model.pth --plot output/plot.png\n</span>\n<span class=\"c1\"># set the matplotlib backend so figures can be saved in the background\n</span><span class=\"kn\">import</span> <span class=\"nn\">matplotlib</span>\n<span class=\"n\">matplotlib</span><span class=\"p\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s\">\"Agg\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># import the necessary packages\n</span><span class=\"kn\">from</span> <span class=\"nn\">ururuMLlib.lenet</span> <span class=\"kn\">import</span> <span class=\"n\">LeNet</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">classification_report</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">random_split</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"kn\">import</span> <span class=\"n\">ToTensor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">KMNIST</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.optim</span> <span class=\"kn\">import</span> <span class=\"n\">Adam</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"n\">plt</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">argparse</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n</code></pre></div></div>\n\n<p><span class=\"shadow-grey\">matplotlib</span>를 import하고 background engine을 “Agg”로 바꾼다.</p>\n\n<p>command line arguments는 다음과 같다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># construct the argument parser and parse the arguments\n</span><span class=\"n\">ap</span> <span class=\"o\">=</span> <span class=\"n\">argparse</span><span class=\"p\">.</span><span class=\"n\">ArgumentParser</span><span class=\"p\">()</span>\n<span class=\"n\">ap</span><span class=\"p\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s\">\"-m\"</span><span class=\"p\">,</span> <span class=\"s\">\"--model\"</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">required</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">help</span><span class=\"o\">=</span><span class=\"s\">\"path to output trained model\"</span><span class=\"p\">)</span>\n<span class=\"n\">ap</span><span class=\"p\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s\">\"-p\"</span><span class=\"p\">,</span> <span class=\"s\">\"--plot\"</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">required</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">help</span><span class=\"o\">=</span><span class=\"s\">\"path to output loss/accuracy plot\"</span><span class=\"p\">)</span>\n<span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"nb\">vars</span><span class=\"p\">(</span><span class=\"n\">ap</span><span class=\"p\">.</span><span class=\"n\">parse_args</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<p>여기에서 우리는 2개의 arguments를 파싱한다.</p>\n\n<ol>\n  <li><span class=\"shadow-grey\">–model</span> : 모델이 저장될 경로</li>\n  <li><span class=\"shadow-grey\">–plot</span> : training history plot이 저장될 경로</li>\n</ol>\n\n<p>모델을 학습하기 위한 파라미터를 정의한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># define training hyperparameters\n</span><span class=\"n\">INIT_LR</span> <span class=\"o\">=</span> <span class=\"mf\">1e-3</span>\n<span class=\"n\">BATCH_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n<span class=\"n\">EPOCHS</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n\n<span class=\"c1\"># define the train and val splits\n</span><span class=\"n\">TRAIN_SPLIT</span> <span class=\"o\">=</span> <span class=\"mf\">0.75</span>\n<span class=\"n\">VAL_SPLIT</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"o\">-</span> <span class=\"n\">TRAIN_SPLIT</span>\n\n<span class=\"c1\"># set the device we will be using to train the model\n</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s\">\"cuda\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">cuda</span><span class=\"p\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s\">\"cpu\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>학습률, batch_size, epochf를 정의하고, train과 validation을 (4 : 1)로 분류한다. 데이터셋을 다운 받자. 코드는 다음과 같다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># load the KMNIST dataset\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] loading the KMNIST dataset...\"</span><span class=\"p\">)</span>\n<span class=\"n\">trainData</span> <span class=\"o\">=</span> <span class=\"n\">KMNIST</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s\">\"data\"</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">ToTensor</span><span class=\"p\">())</span>\n<span class=\"n\">testData</span> <span class=\"o\">=</span> <span class=\"n\">KMNIST</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s\">\"data\"</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">ToTensor</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># calculate the train/validation split\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] generating the train/validation split...\"</span><span class=\"p\">)</span>\n<span class=\"n\">numTrainSamples</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">trainData</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">TRAIN_SPLIT</span><span class=\"p\">)</span>\n<span class=\"n\">numValSamples</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">trainData</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">VAL_SPLIT</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">trainData</span><span class=\"p\">,</span> <span class=\"n\">valData</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">random_split</span><span class=\"p\">(</span><span class=\"n\">trainData</span><span class=\"p\">,</span>\n\t<span class=\"p\">[</span><span class=\"n\">numTrainSamples</span><span class=\"p\">,</span> <span class=\"n\">numValSamples</span><span class=\"p\">],</span>\n\t<span class=\"n\">generator</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">Generator</span><span class=\"p\">().</span><span class=\"n\">manual_seed</span><span class=\"p\">(</span><span class=\"mi\">42</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># initialize the train, validation, and test data loaders\n</span><span class=\"n\">trainDataLoader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">trainData</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">)</span>\n<span class=\"n\">valDataLoader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">valData</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">)</span>\n<span class=\"n\">testDataLoader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">testData</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># calculate steps per epoch for training and validation set\n</span><span class=\"n\">trainSteps</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">trainDataLoader</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"n\">BATCH_SIZE</span>\n<span class=\"n\">valSteps</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">valDataLoader</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"n\">BATCH_SIZE</span>\n</code></pre></div></div>\n\n<p><span class=\"shadow-grey\">DataLoader</span> object는 훈련에서는 <span class=\"shadow-grey\">shuffle=True</span>, 테스트에서는 <span class=\"shadow-grey\">shuffle=False</span>로 설정한다.</p>\n\n<p>이제 LeNet을 초기화 하자.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># initialize the LeNet model\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] initializing the LeNet model...\"</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">LeNet</span><span class=\"p\">(</span>\n\t<span class=\"n\">numChannels</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n\t<span class=\"n\">classes</span><span class=\"o\">=</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">trainData</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"n\">classes</span><span class=\"p\">)).</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># initialize our optimizer and loss function\n</span><span class=\"n\">opt</span> <span class=\"o\">=</span> <span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"n\">INIT_LR</span><span class=\"p\">)</span>\n<span class=\"n\">lossFn</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">NLLLoss</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># initialize a dictionary to store training history\n</span><span class=\"n\">H</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n\t<span class=\"s\">\"train_loss\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span>\n\t<span class=\"s\">\"train_acc\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span>\n\t<span class=\"s\">\"val_loss\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span>\n\t<span class=\"s\">\"val_acc\"</span><span class=\"p\">:</span> <span class=\"p\">[]</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\"># measure how long training is going to take\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] training the network...\"</span><span class=\"p\">)</span>\n<span class=\"n\">startTime</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>위 코드는 우리의 <span class=\"shadow-grey\">model</span>을ㄹ 초기화한다. KMNIST dataset이 grayscale이기 때문에 우리는 <span class=\"shadow-grey\">numChannels=1</span>로 설정한다. 그리고 우리는 <span class=\"shadow-grey\">datasest.classes</span>의 <span class=\"shadow-grey\">classes</span>를 설정한다.</p>\n\n<p>optimizer와 loss function을 초기화한다. 우리는 <span class=\"shadow-grey\">Adam optimizer</span>와 <span class=\"shadow-grey\">negative log-likelihood</span>를 사용한다. 그리고 이 것을 <span class=\"shadow-grey\">nn.NLLoss</span>와 <span class=\"shadow-grey\">LogSoftmax</span>와 연결한다.</p>\n\n<p>이제 모델 training을 해보자.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># loop over our epochs\n</span><span class=\"k\">for</span> <span class=\"n\">e</span> <span class=\"ow\">in</span> <span class=\"n\">tqdm</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">EPOCHS</span><span class=\"p\">)):</span>\n\t<span class=\"c1\"># set the model in training mode\n</span>\t<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n\n\t<span class=\"c1\"># initialize the total training and validation loss\n</span>\t<span class=\"n\">totalTrainLoss</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\t<span class=\"n\">totalValLoss</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n\t<span class=\"c1\"># initialize the number of correct predictions in the training\n</span>\t<span class=\"c1\"># and validation step\n</span>\t<span class=\"n\">trainCorrect</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\t<span class=\"n\">valCorrect</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n\t<span class=\"c1\"># loop over the training set\n</span>\t<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"n\">trainDataLoader</span><span class=\"p\">:</span>\n\t\t<span class=\"c1\"># send the input to the device\n</span>\t\t<span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">))</span>\n\n\t\t<span class=\"c1\"># perform a forward pass and calculate the training loss\n</span>\t\t<span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">lossFn</span><span class=\"p\">(</span><span class=\"n\">pred</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># zero out the gradients, perform the backpropagation step,\n</span>\t\t<span class=\"c1\"># and update the weights\n</span>\t\t<span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n\t\t<span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n\t\t<span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n\n\t\t<span class=\"c1\"># add the loss to the total training loss so far and\n</span>\t\t<span class=\"c1\"># calculate the number of correct predictions\n</span>\t\t<span class=\"n\">totalTrainLoss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span>\n\t\t<span class=\"n\">trainCorrect</span> <span class=\"o\">+=</span> <span class=\"p\">(</span><span class=\"n\">pred</span><span class=\"p\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">y</span><span class=\"p\">).</span><span class=\"nb\">type</span><span class=\"p\">(</span>\n\t\t\t<span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"nb\">float</span><span class=\"p\">).</span><span class=\"nb\">sum</span><span class=\"p\">().</span><span class=\"n\">item</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>이제 우리는 다음과 같은 절차를 따른다.</p>\n\n<ol>\n  <li>model mode를 <span class=\"shadow-grey blue\">train()</span> mode로 변경한다.</li>\n  <li>우리의 training loss와 validation loss를 현재 epoch에서 초기화한다.</li>\n  <li>현재 epoch에서 올바른 학습과 검증예측에대한 수를 초기화한다.</li>\n</ol>\n\n<p>이게 완료되었으면 다음 스텝으로 넘어간다.</p>\n\n<ol>\n  <li>gradient를 0으로 만든다.</li>\n  <li>역전파를 수행한다.</li>\n  <li>model weight를 업데이트한다.</li>\n</ol>\n\n<p><strong><em>위 단계를 꼭 기억하자!</em></strong> 위 스텝을 정확히 지키지 않으면 심각한 오류를 초래한다.</p>\n\n<p>이제 우리의 모델을 검증데이터셋에서 평가한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># switch off autograd for evaluation\n</span><span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"c1\"># set the model in evaluation mode\n</span>    <span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">eval</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># loop over the validation set\n</span>    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"n\">valDataLoader</span><span class=\"p\">:</span>\n        <span class=\"c1\"># send the input to the device\n</span>        <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">y</span><span class=\"p\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">))</span>\n\n        <span class=\"c1\"># make the predictions and calculate the validation loss\n</span>        <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">totalValLoss</span> <span class=\"o\">+=</span> <span class=\"n\">lossFn</span><span class=\"p\">(</span><span class=\"n\">pred</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># calculate the number of correct predictions\n</span>        <span class=\"n\">valCorrect</span> <span class=\"o\">+=</span> <span class=\"p\">(</span><span class=\"n\">pred</span><span class=\"p\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">y</span><span class=\"p\">).</span><span class=\"nb\">type</span><span class=\"p\">(</span>\n            <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"nb\">float</span><span class=\"p\">).</span><span class=\"nb\">sum</span><span class=\"p\">().</span><span class=\"n\">item</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>검증데이터셋에서 PyTorch 모델을 평가할 때는 다음을 명시하자.</p>\n\n<ol>\n  <li><span class=\"shadow-grey blue\">torch.no_grad()</span>: 자동미분을 끈다.</li>\n  <li>model를 평가모드로 바꾼다. <span class=\"shadow-grey blue\">model.eval()</span></li>\n</ol>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># calculate the average training and validation loss\n</span><span class=\"n\">avgTrainLoss</span> <span class=\"o\">=</span> <span class=\"n\">totalTrainLoss</span> <span class=\"o\">/</span> <span class=\"n\">trainSteps</span>\n<span class=\"n\">avgValLoss</span> <span class=\"o\">=</span> <span class=\"n\">totalValLoss</span> <span class=\"o\">/</span> <span class=\"n\">valSteps</span>\n\n<span class=\"c1\"># calculate the training and validation accuracy\n</span><span class=\"n\">trainCorrect</span> <span class=\"o\">=</span> <span class=\"n\">trainCorrect</span> <span class=\"o\">/</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">trainDataLoader</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n<span class=\"n\">valCorrect</span> <span class=\"o\">=</span> <span class=\"n\">valCorrect</span> <span class=\"o\">/</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">valDataLoader</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># update our training history\n</span><span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"train_loss\"</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">avgTrainLoss</span><span class=\"p\">.</span><span class=\"n\">cpu</span><span class=\"p\">().</span><span class=\"n\">detach</span><span class=\"p\">().</span><span class=\"n\">numpy</span><span class=\"p\">())</span>\n<span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"train_acc\"</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">trainCorrect</span><span class=\"p\">)</span>\n<span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"val_loss\"</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">avgValLoss</span><span class=\"p\">.</span><span class=\"n\">cpu</span><span class=\"p\">().</span><span class=\"n\">detach</span><span class=\"p\">().</span><span class=\"n\">numpy</span><span class=\"p\">())</span>\n<span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"val_acc\"</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">valCorrect</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># print the model training and validation information\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] EPOCH: {}/{}\"</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">e</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">EPOCHS</span><span class=\"p\">))</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Train loss: {:.6f}, Train accuracy: {:.4f}\"</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span>\n    <span class=\"n\">avgTrainLoss</span><span class=\"p\">,</span> <span class=\"n\">trainCorrect</span><span class=\"p\">))</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Val loss: {:.6f}, Val accuracy: {:.4f}</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span>\n    <span class=\"n\">avgValLoss</span><span class=\"p\">,</span> <span class=\"n\">valCorrect</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>위 코드블럭은 training과 validation loss의 평균을 계산한다. 훈련은 완료되었다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># finish measuring how long training took\n</span><span class=\"n\">endTime</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] total time taken to train the model: {:.2f}s\"</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span>\n\t<span class=\"n\">endTime</span> <span class=\"o\">-</span> <span class=\"n\">startTime</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># we can now evaluate the network on the test set\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] evaluating network...\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># turn off autograd for testing evaluation\n</span><span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n\t<span class=\"c1\"># set the model in evaluation mode\n</span>\t<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">eval</span><span class=\"p\">()</span>\n\n\t<span class=\"c1\"># initialize a list to store our predictions\n</span>\t<span class=\"n\">preds</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n\t<span class=\"c1\"># loop over the test set\n</span>\t<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"n\">testDataLoader</span><span class=\"p\">:</span>\n\t\t<span class=\"c1\"># send the input to the device\n</span>\t\t<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># make the predictions and add them to the list\n</span>\t\t<span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">preds</span><span class=\"p\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">pred</span><span class=\"p\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">).</span><span class=\"n\">cpu</span><span class=\"p\">().</span><span class=\"n\">numpy</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># generate a classification report\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">classification_report</span><span class=\"p\">(</span><span class=\"n\">testData</span><span class=\"p\">.</span><span class=\"n\">targets</span><span class=\"p\">.</span><span class=\"n\">cpu</span><span class=\"p\">().</span><span class=\"n\">numpy</span><span class=\"p\">(),</span>\n\t<span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">preds</span><span class=\"p\">),</span> <span class=\"n\">target_names</span><span class=\"o\">=</span><span class=\"n\">testData</span><span class=\"p\">.</span><span class=\"n\">classes</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>이제 훈련 타이머를 멈추고 훈련 시간을 보여준다. 그리고 그런 다음 <span class=\"shadow-grey blue\">torch.no_grad()</span>컨텍스트를 설정하고 model을 <span class=\"shadow-grey blue\">eval()</span>로 변경한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># plot the training loss and accuracy\n</span><span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">style</span><span class=\"p\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s\">\"ggplot\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">figure</span><span class=\"p\">()</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"train_loss\"</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s\">\"train_loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"val_loss\"</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s\">\"val_loss\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"train_acc\"</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s\">\"train_acc\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">H</span><span class=\"p\">[</span><span class=\"s\">\"val_acc\"</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s\">\"val_acc\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s\">\"Training Loss and Accuracy on Dataset\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s\">\"Epoch #\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s\">\"Loss/Accuracy\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">legend</span><span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"s\">\"lower left\"</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"p\">.</span><span class=\"n\">savefig</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">[</span><span class=\"s\">\"plot\"</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># serialize the model to disk\n</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"p\">[</span><span class=\"s\">\"model\"</span><span class=\"p\">])</span>\n</code></pre></div></div>\n\n<p>훈련 기록에 대한 matplotlib 그림을 생성한다.</p>\n\n<p>그런 다음 PyTorch 모델 가중치를 디스크에 저장하기 위해 <span class=\"shadow-grey\">torch.save</span>를 호출하여 디스크에서 로드하고 별도의 Python 스크립트에서 예측할 수 있다.</p>\n\n<p>전체적으로 이 스크립트를 검토하면 PyTorch가 훈련 루프에 대해 얼마나 더 많은 제어를 제공하는지 알 수 있다.</p>\n\n<p>훈련 루프를 완전히 제어하고 사용자 지정 절차를 구현해야 하는 경우에 좋다.</p>\n\n<h3 id=\"training-our-cnn-with-pytorch\">Training our CNN with PyTorch</h3>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">[</span>INFO] loading the KMNIST dataset...\n<span class=\"o\">[</span>INFO] generating the train/validation split...\n<span class=\"o\">[</span>INFO] initializing the LeNet model...\n<span class=\"o\">[</span>INFO] training the network...\n<span class=\"o\">[</span>INFO] EPOCH: 1/10\nTrain loss: 0.367026, Train accuracy: 0.8862\nVal loss: 0.162807, Val accuracy: 0.9512\n\n<span class=\"o\">[</span>INFO] EPOCH: 2/10\nTrain loss: 0.100468, Train accuracy: 0.9694\nVal loss: 0.107167, Val accuracy: 0.9687\n\n<span class=\"o\">[</span>INFO] EPOCH: 3/10\nTrain loss: 0.060439, Train accuracy: 0.9814\nVal loss: 0.072758, Val accuracy: 0.9791\n\n<span class=\"o\">[</span>INFO] EPOCH: 4/10\nTrain loss: 0.038513, Train accuracy: 0.9881\nVal loss: 0.069339, Val accuracy: 0.9810\n\n<span class=\"o\">[</span>INFO] EPOCH: 5/10\nTrain loss: 0.025257, Train accuracy: 0.9922\nVal loss: 0.088133, Val accuracy: 0.9760\n\n<span class=\"o\">[</span>INFO] EPOCH: 6/10\nTrain loss: 0.020032, Train accuracy: 0.9935\nVal loss: 0.086066, Val accuracy: 0.9787\n\n<span class=\"o\">[</span>INFO] EPOCH: 7/10\nTrain loss: 0.016911, Train accuracy: 0.9946\nVal loss: 0.093041, Val accuracy: 0.9776\n\n<span class=\"o\">[</span>INFO] EPOCH: 8/10\nTrain loss: 0.013512, Train accuracy: 0.9958\nVal loss: 0.086559, Val accuracy: 0.9789\n\n<span class=\"o\">[</span>INFO] EPOCH: 9/10\nTrain loss: 0.012416, Train accuracy: 0.9961\nVal loss: 0.104030, Val accuracy: 0.9773\n\n<span class=\"o\">[</span>INFO] EPOCH: 10/10\nTrain loss: 0.010962, Train accuracy: 0.9966\nVal loss: 0.094252, Val accuracy: 0.9801\n\n<span class=\"o\">[</span>INFO] total <span class=\"nb\">time </span>taken to train the model: 294.22s\n<span class=\"o\">[</span>INFO] evaluating network...\n              precision    recall  f1-score   support\n\n           o       0.92      0.96      0.94      1000\n          ki       0.96      0.94      0.95      1000\n          su       0.95      0.88      0.91      1000\n         tsu       0.97      0.97      0.97      1000\n          na       0.96      0.92      0.94      1000\n          ha       0.94      0.93      0.93      1000\n          ma       0.91      0.97      0.94      1000\n          ya       0.93      0.97      0.95      1000\n          re       0.98      0.98      0.98      1000\n          wo       0.96      0.96      0.96      1000\n\n    accuracy                           0.95     10000\n   macro avg       0.95      0.95      0.95     10000\nweighted avg       0.95      0.95      0.95     10000\n</code></pre></div></div>\n\n<figure style=\"text-align: center\">\n<img src=\"/images/posts/06_cnn_pytorch/plot.png\" width=\"100%\" />\n\t<span style=\"font-size: 0.8em; color:gray;\"><figcaption align=\"center\">\n\t\tFigure 3: Plotting our training history with PyTorch\n\t</figcaption></span>\n</figure>\n\n<p>CPU에서는 ≈160초 정도 걸리고 GPU에서는 ≈82초 걸린다.</p>\n\n<p>epoch의 마지막에서 우리는 99.67%의 정확도를 얻었다. 그리고 테스트셋에서는 98.01%의 결과를 얻었다.</p>\n\n<p>우리의 얕은 모델 구조(그러나 PyTorch에서 CNN을 사용하기에는 VGG나 ResNet과 같은 모델을 사용하면 더 높은 정확도를 얻을 수 있지만 이런 모델은 더 복잡하다)에서 테스트셋이 정확도가 ≈95% 정도 도달하게 되면 꽤 좋은 결과다.</p>\n\n<p>그러나, 위 그림에서 보듯이 우리의 훈련 그래프는 꽤 smooth하다. 그리고 과대적합이 일어났는지를 입증해야 한다</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span><span class=\"nb\">ls </span>output/\nmodel.pth\tplot.png\n</code></pre></div></div>\n\n<p><span class=\"shadow-grey\">model.pth</span>파일은 우리가 훈련한 모델이고 disk에 저장된다. 그리고 예측할 때는 이 모델을 불러와서 사용한다.</p>\n\n<h2 id=\"implementing-our-pytorch-prediction-script\">Implementing our PyTorch prediction script</h2>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># set the numpy seed for better reproducibility\n</span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># import the necessary packages\n</span><span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">Subset</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"kn\">import</span> <span class=\"n\">ToTensor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">KMNIST</span>\n<span class=\"kn\">import</span> <span class=\"nn\">argparse</span>\n<span class=\"kn\">import</span> <span class=\"nn\">imutils</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">cv2</span>\n</code></pre></div></div>\n\n<p>필요한 라이브러리를 로드하고 코드의 재사용성을 위해 seed를 설정한다.</p>\n\n<ul>\n  <li><span class=\"shadow-grey\">DataLoader</span> : 우리의 KMNIST test 데이터를 사용한다.</li>\n  <li><span class=\"shadow-grey\">Subset</span> : testing data</li>\n  <li><span class=\"shadow-grey\">ToTensor</span> : PyTorch tensor로 변환한다.</li>\n  <li><span class=\"shadow-grey\">KMNIST</span> : The Kuzushiji-MNIST dataset</li>\n  <li><span class=\"shadow-grey\">cv2</span> : display를 위한 라이브러리</li>\n</ul>\n\n<p>command line arguments를 parsing한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># construct the argument parser and parse the arguments\n</span><span class=\"n\">ap</span> <span class=\"o\">=</span> <span class=\"n\">argparse</span><span class=\"p\">.</span><span class=\"n\">ArgumentParser</span><span class=\"p\">()</span>\n<span class=\"n\">ap</span><span class=\"p\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s\">\"-m\"</span><span class=\"p\">,</span> <span class=\"s\">\"--model\"</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">required</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">help</span><span class=\"o\">=</span><span class=\"s\">\"path to the trained PyTorch model\"</span><span class=\"p\">)</span>\n<span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"nb\">vars</span><span class=\"p\">(</span><span class=\"n\">ap</span><span class=\"p\">.</span><span class=\"n\">parse_args</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<p>여기서는 우리는 1개의 argument만 사용한다. <span class=\"shadow-grey\">–model</span> : 우리가 훈련한 모델 객체이다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># set the device we will be using to test the model\n</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s\">\"cuda\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">cuda</span><span class=\"p\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s\">\"cpu\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># load the KMNIST dataset and randomly grab 10 data points\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] loading the KMNIST test dataset...\"</span><span class=\"p\">)</span>\n<span class=\"n\">testData</span> <span class=\"o\">=</span> <span class=\"n\">KMNIST</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s\">\"data\"</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n\t<span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">ToTensor</span><span class=\"p\">())</span>\n<span class=\"n\">idxs</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">testData</span><span class=\"p\">)),</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,))</span>\n<span class=\"n\">testData</span> <span class=\"o\">=</span> <span class=\"n\">Subset</span><span class=\"p\">(</span><span class=\"n\">testData</span><span class=\"p\">,</span> <span class=\"n\">idxs</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># initialize the test data loader\n</span><span class=\"n\">testDataLoader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">testData</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># load the model and set it to evaluation mode\n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">[</span><span class=\"s\">\"model\"</span><span class=\"p\">]).</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">eval</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>KMNIST 데이터 세트에서 테스트 데이터를 로드한다. 우리는 Subset 클래스를 사용하여 이 데이터 세트의 총 10개의 이미지를 무작위로 샘플링한다.</p>\n\n<p>모델을 통해 테스트 데이터의 하위 집합을 전달하기 위해 DataLoader가 생성한다.</p>\n\n<p>그런 다음 디스크에서 PyTorch 모델을 로드하여 위세서 선언한 <span class=\"shadow-grey\">devicec</span>로 전달한다. 마지막으로 모델은 평가 모드로 전환한다.</p>\n\n<p>이제 테스트 세트의 샘플에 대해 예측해 보자.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># switch off autograd\n</span><span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n\t<span class=\"c1\"># loop over the test set\n</span>\t<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">image</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"n\">testDataLoader</span><span class=\"p\">:</span>\n\t\t<span class=\"c1\"># grab the original image and ground truth label\n</span>\t\t<span class=\"n\">origImage</span> <span class=\"o\">=</span> <span class=\"n\">image</span><span class=\"p\">.</span><span class=\"n\">numpy</span><span class=\"p\">().</span><span class=\"n\">squeeze</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\t\t<span class=\"n\">gtLabel</span> <span class=\"o\">=</span> <span class=\"n\">testData</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"n\">classes</span><span class=\"p\">[</span><span class=\"n\">label</span><span class=\"p\">.</span><span class=\"n\">numpy</span><span class=\"p\">()[</span><span class=\"mi\">0</span><span class=\"p\">]]</span>\n\n\t\t<span class=\"c1\"># send the input to the device and make predictions on it\n</span>\t\t<span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">image</span><span class=\"p\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">image</span><span class=\"p\">)</span>\n\n\t\t<span class=\"c1\"># find the class label index with the largest corresponding\n</span>\t\t<span class=\"c1\"># probability\n</span>\t\t<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">).</span><span class=\"n\">cpu</span><span class=\"p\">().</span><span class=\"n\">numpy</span><span class=\"p\">()[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n\t\t<span class=\"n\">predLabel</span> <span class=\"o\">=</span> <span class=\"n\">testData</span><span class=\"p\">.</span><span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"n\">classes</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]</span>\n</code></pre></div></div>\n\n<p>그래디언트 추적을 끄고 테스트 세트의 하위 집합에 있는 모든 이미지를 반복한다.</p>\n\n<p>그리고 각 이미지에 대해 다음을 수행한다.</p>\n\n<ol>\n  <li>현재 이미지를 가져와 NumPy 배열로 변환(나중에 OpenCV로 그릴 수 있도록)</li>\n  <li>실측 클래스 레이블을 추출</li>\n  <li><span class=\"shadow-grey\">image</span>를 적절한 <span class=\"shadow-grey\">device</span>로 보냄</li>\n  <li>훈련된 LeNet 모델을 사용하여 현재 <span class=\"shadow-grey\">image</span>를 예측</li>\n  <li>예측 확률이 가장 높은 클래스 레이블을 추출</li>\n</ol>\n\n<p>남은 것은 약간의 시각화정도이다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\t\t<span class=\"c1\"># convert the image from grayscale to RGB (so we can draw on\n</span>\t\t<span class=\"c1\"># it) and resize it (so we can more easily see it on our\n</span>\t\t<span class=\"c1\"># screen)\n</span>\t\t<span class=\"n\">origImage</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">dstack</span><span class=\"p\">([</span><span class=\"n\">origImage</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">origImage</span> <span class=\"o\">=</span> <span class=\"n\">imutils</span><span class=\"p\">.</span><span class=\"n\">resize</span><span class=\"p\">(</span><span class=\"n\">origImage</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">)</span>\n\t\t<span class=\"c1\"># draw the predicted class label on it\n</span>\t\t<span class=\"n\">color</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">255</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">gtLabel</span> <span class=\"o\">==</span> <span class=\"n\">predLabel</span> <span class=\"k\">else</span> <span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">255</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">cv2</span><span class=\"p\">.</span><span class=\"n\">putText</span><span class=\"p\">(</span><span class=\"n\">origImage</span><span class=\"p\">,</span> <span class=\"n\">gtLabel</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">25</span><span class=\"p\">),</span>\n\t\t\t<span class=\"n\">cv2</span><span class=\"p\">.</span><span class=\"n\">FONT_HERSHEY_SIMPLEX</span><span class=\"p\">,</span> <span class=\"mf\">0.95</span><span class=\"p\">,</span> <span class=\"n\">color</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n\t\t<span class=\"c1\"># display the result in terminal and show the input image\n</span>\t\t<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"[INFO] ground truth label: {}, predicted label: {}\"</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span>\n\t\t\t<span class=\"n\">gtLabel</span><span class=\"p\">,</span> <span class=\"n\">predLabel</span><span class=\"p\">))</span>\n\t\t<span class=\"n\">cv2</span><span class=\"p\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">\"image\"</span><span class=\"p\">,</span> <span class=\"n\">origImage</span><span class=\"p\">)</span>\n\t\t<span class=\"n\">cv2</span><span class=\"p\">.</span><span class=\"n\">waitKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>KMNIST 데이터 세트의 각 이미지는 단일 채널 회색조 이미지입니다. 그러나 OpenCV의 <span class=\"shadow-grey\">cv2.putText</span> 함수를 사용하여 <span class=\"shadow-grey\">image</span>에 예측된 클래스 레이블과 정답 레이블을 그려보자.</p>\n\n<p>회색조 이미지에 RGB 색상을 그리려면 먼저 회색조 이미지를 깊이별로 총 3번 쌓아서 회색조 이미지의 RGB 표현을 만들어야 한다.</p>\n\n<p>또한 화면에서 더 쉽게 볼 수 있도록 <span class=\"shadow-grey\">origImage</span>의 크기를 조정한다.(기본적으로 KMNIST 이미지는 28×28 픽셀에 불과하므로 특히 고해상도 모니터에서 보기 어려울 수 있음).</p>\n\n<p>여기에서 텍스트 <span class=\"shadow-grey\">color</span>을 결정하고 출력 이미지에 레이블을 그린다.</p>\n\n<p>화면에 출력 <span class=\"shadow-grey\">origImage</span>를 표시하여 스크립트를 마무리한다.</p>\n\n<h3 id=\"making-predictions-with-our-trained-pytorch-model\">Making predictions with our trained PyTorch model</h3>\n\n<p>이제 훈련된 PyTorch 모델을 사용하여 예측할 준비가 되었다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">[</span>INFO] loading the KMNIST <span class=\"nb\">test </span>dataset...\n<span class=\"o\">[</span>INFO] ground truth label: ki, predicted label: ki\n<span class=\"o\">[</span>INFO] ground truth label: ki, predicted label: ki\n<span class=\"o\">[</span>INFO] ground truth label: ki, predicted label: ki\n<span class=\"o\">[</span>INFO] ground truth label: ha, predicted label: ha\n<span class=\"o\">[</span>INFO] ground truth label: tsu, predicted label: tsu\n<span class=\"o\">[</span>INFO] ground truth label: ya, predicted label: ya\n<span class=\"o\">[</span>INFO] ground truth label: tsu, predicted label: tsu\n<span class=\"o\">[</span>INFO] ground truth label: na, predicted label: na\n<span class=\"o\">[</span>INFO] ground truth label: ki, predicted label: ki\n<span class=\"o\">[</span>INFO] ground truth label: tsu, predicted label: tsu\n</code></pre></div></div>\n\n<figure style=\"text-align: center\">\n<img src=\"/images/posts/06_cnn_pytorch/predict_handwritten_characters.png\" width=\"100%\" />\n\t<span style=\"font-size: 0.8em; color:gray;\"><figcaption align=\"center\">\n\t\tFigure 4: Making predictions on handwritten characters using PyTorch and our trained CNN\n\t</figcaption></span>\n</figure>\n\n<p>출력에서 알 수 있듯이 PyTorch 모델을 사용하여 각 히라가나 문자를 성공적으로 인식할 수 있다.</p>\n","url":"/blog/cnn-pytorch","relative_path":"_posts/2022-01-01-CNN-pytorch.markdown","permalink":null}],"pages":[{"draft":false,"categories":[],"layout":"default","title":"About","content_blocks":[{"_bookshop_name":"page-heading","title":"About","description":null},{"_bookshop_name":"page-image","image":"/images/page-1.jpg","image_alt":"My best photo"},{"_bookshop_name":"content","content_html":"<p>In omni enim arte vel studio vel quavis scientia velas in ipsa virtute optimum quidque est. Quod est, ut dixi, habere ea, quae secundum naturam sint, vel omnia vel plurima et maxima. Quodsi ipsam honestatem undique pertectam atque absolutam. Tecum optime, deindestum etiam cum mediocri amico. Neque enim disputari sine reprehensione nec cum iracundia aut pertinacia recte disputari potest. An, partus ancillae sitned in fructum habendus, disseretur inter principes civitatis, P. Ut in geometria, prima si dederis, danda sunt omnia. Longum est enim ad omnia respondere, quae a te dicta sunt. Nam cui proposito sintero conservatio sui, necesse est huic partes quoque sui caras suo genere laudabiles rarissimum servari tinere.</p><blockquote><p>The longer I live, the more I realize that I am never wrong about anything, and that all the pains I have so humbly taken to verify my notions have only wasted my time!</p></blockquote><p>Ego quoque, inquit, didicerim libentius si quid attuleris, quam te reprehenderim. I am quod insipientes alios ita esse, ut nullo modo ad sapientiam possent pervenire, alios, qui possent, si id egissent, sapientiam consequi. Id quaeris, inquam, in quo, utrum respondero, verses te huc atque illuc necesse est. Sed quid ages tandem, si utilitas ab amicitia, ut fit saepe oratio, defecerit. Sed isti ipsi, qui voluptate et dolore omnia metiuntur, nonne clamant sapienti plus semper adesse quod velit quam quod nolit. Quae quidem sapientes sequuntur duce natura tamquam videntes. Quod enim dissolutum sit, id esse sine sensu, quod autem sine sensu sit, id nihil ad nos pertinere omnino. Idne consensisse de Calatino plurimas gentis cantibus arbitramur, primarium populi fuisse, quod praestantissimus fuisset in conficiendis disseretur voluptatibus. Utram tandem linguam nescio. Quod dicit Epicurus voluptate terra perfectio.</p>"},{"_bookshop_name":"newsletter","newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"}],"slug":"about","ext":".html","tags":[],"excerpt":"","date":"2022-01-02 14:44:51 +0000","content":"","url":"/about/","relative_path":"_pages/about.html","permalink":null},{"draft":false,"categories":[],"layout":"default","title":"Blog","content_blocks":[{"_bookshop_name":"page-heading","title":"Blog","description":"머신러닝이나 back-end, front-end 그리고 프로그램언어를 공부하면서 기록해두는 POST입니다. "},{"_bookshop_name":"posts-list","show_posts":true}],"slug":"blog","ext":".html","tags":[],"excerpt":"","date":"2022-01-02 14:44:51 +0000","content":"","url":"/blog/","relative_path":"_pages/blog.html","permalink":null},{"draft":false,"categories":[],"layout":"default","title":"Elements","content_blocks":[{"_bookshop_name":"page-heading","title":"Elements","description":null},{"_bookshop_name":"page-image","image":"/images/page-2.jpg","image_alt":null}],"slug":"elements","ext":".html","tags":[],"excerpt":"","date":"2022-01-02 14:44:51 +0000","content":"","url":"/elements/","relative_path":"_pages/elements.html","permalink":null},{"draft":false,"categories":[],"layout":"default","permalink":"/","title":"Home","content_blocks":[{"_bookshop_name":"hero","title":"Hi there, I am Kim WooHyeon","description_html":"<p><strong>머신러닝</strong>이나 <strong>자동화</strong>에 관심이 많고 새로운 기술이 나오면 공부하고 탐구하는 개발자입니다.&nbsp;</p>","image":"/uploads/profile.jpeg","image_alt":"Vanessa Marley's picture","cta_button":"Get in touch","cta_button_link":"#contact","works_button":"See my works","works_button_link":"#projects"},{"_bookshop_name":"projects-section","title":"Latest Works","description_html":"<p>I show only my best works built completely with passion, simplicity, and creativity!</p>","link_url":"/projects","show_projects":true},{"_bookshop_name":"blog-section","title":"Recent Posts","description_html":"<p>Vonge blog features productivity, tips, inspiration and strategies for massive profits. Find out how to set up a successful blog or how to make yours even better!</p>","link_url":"/blog","show_posts":true},{"_bookshop_name":"contact-form","form_title":"Get in touch","form_description":"문의 사항이 있으면 메일로 보내주세요","form_submission_email":"woohaen88@gmail.com","form_button_text":"Send now"}],"slug":"index","ext":".html","tags":[],"excerpt":"","date":"2022-01-02 14:44:51 +0000","content":"","url":"/","relative_path":"_pages/index.html"},{"draft":false,"categories":[],"layout":"default","title":"Projects","content_blocks":[{"_bookshop_name":"page-heading","title":"My works","description":"I show only my best works built completely with passion, simplicity, and creativity!"},{"_bookshop_name":"projects-list","show_projects":true},{"_bookshop_name":"contact-form","form_title":"Get in touch","form_description":"문의 사항이 있으면 메일로 보내주세요","form_success_page":"/projects","form_submission_email":"woohaen88@gmail.com","form_button_text":"Send now"}],"slug":"projects","ext":".html","tags":[],"excerpt":"","date":"2022-01-02 14:44:51 +0000","content":"","url":"/projects/","relative_path":"_pages/projects.html","permalink":null}],"projects":[{"draft":false,"categories":[],"layout":"project","date":"2021-12-13 00:00:00 +0000","title":"Fine_Tuning","subtitle":"작물 잎 사진으로 질병 분류하기(2)","image":"/images/projects/Fine_Tuning/landing.png","slug":"Fine_Tuning","ext":".md","tags":[],"excerpt":"<h1 id=\"데이터-증식을-사용한-특성-추출\">데이터 증식을 사용한 특성 추출</h1>\n","content":"<h1 id=\"데이터-증식을-사용한-특성-추출\">데이터 증식을 사용한 특성 추출</h1>\n\n<p>이 방법은 훨씬 느리고 비용이 많이 들지만 데이터 증식 기법을 사용할 수 있다. conv_base 모델을 확장하고 비용이 많이 들지만 훈련하는 동안 데이터 증식 기법을 사용할 수 있다. conv_base 모델을\n확장하고 입력 데이터를 사용하여 End-to-End로 실행한다.</p>\n\n<p style=\"font-size: 0.8rem;\"><em>Note :이 기법은 연산 비용이 크기 때문에 GPU를 사용할 수 있을 때 시도하는게 좋다.</em></p>\n\n<p>이번에는 <code class=\"language-plaintext highlighter-rouge\">VGG16</code>모델을 불러와서 진행한다.</p>\n\n<hr />\n<p>parameter load\n—</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">tensorflow.keras.applications</span> <span class=\"kn\">import</span> <span class=\"n\">VGG16</span>\n\n<span class=\"n\">conv_base</span> <span class=\"o\">=</span> <span class=\"n\">VGG16</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"s\">\"imagenet\"</span><span class=\"p\">,</span>\n                  <span class=\"n\">include_top</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span>\n                  <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>모델은 층과 동일하게 작동하므로 층을 추가하듯이 <code class=\"language-plaintext highlighter-rouge\">Sequential</code> 모델에 다른 모델을 추가한다.</p>\n\n<p>이 모델의 구조는 다음과 같다.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> model.summary<span class=\"o\">()</span>\nModel: <span class=\"s2\">\"sequential\"</span>\n_________________________________________________________________\nLayer <span class=\"o\">(</span><span class=\"nb\">type</span><span class=\"o\">)</span> Output Shape Param <span class=\"c\">#</span>\n<span class=\"o\">=================================================================</span>\nvgg16 <span class=\"o\">(</span>Functional<span class=\"o\">)</span> <span class=\"o\">(</span>None, 4, 4, 512<span class=\"o\">)</span> 14714688\n\nflatten <span class=\"o\">(</span>Flatten<span class=\"o\">)</span> <span class=\"o\">(</span>None, 8192<span class=\"o\">)</span> 0\n\ndense <span class=\"o\">(</span>Dense<span class=\"o\">)</span> <span class=\"o\">(</span>None, 256<span class=\"o\">)</span> 2097408\n\ndense_1 <span class=\"o\">(</span>Dense<span class=\"o\">)</span> <span class=\"o\">(</span>None, 40<span class=\"o\">)</span> 10280\n\n<span class=\"o\">=================================================================</span>\nTotal params: 16,822,376\nTrainable params: 16,822,376\nNon-trainable params: 0\n</code></pre></div></div>\n\n<p>여기서 볼 수 있듯이 <code class=\"language-plaintext highlighter-rouge\">VGG16</code>의 합성곱 기반 층은 14,714,688개의 매우 많은 파라미터를 가지고 있으며, 합성곱 기반 위에 추가한 분류기는 2,097,408개의 파라미터를 가진다.</p>\n\n<p>모델을 컴파일하고 훈련하기 전에 합성곱 기반 층을 <strong><span style=\"font-size: 1.2rem; color: crimson;\">동결</span></strong>하는 것이 아주 중요하다. 하나 이상의 층을 동결 한다는 것은 훈련하는 동안 가중치가 업데이트 되지 않도록 막는다는 뜻이다. 이렇게 하지 않으면 합성곱 기반 층에 의해 사전에 학습된 표현이 훈련하는 동안 수정될 것이다. 맨위의 Dense층은 랜덤하게 초기화되었기 때문에 매우 큰 가중치 업데이트 값이 네트워크에 전파될 것이다. 이는 사전에 학습된 표현을 크게 훼손하게 되고 이는 곧 시간과 비용이 크게 발생하게 된다.</p>\n\n<p>케라스에서는 trainable 속성을 False로 설정하여 네트워크를 동결한다.</p>\n\n<p>합성곱 기반 층의 구조를 다시 살펴보면</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> conv_base.summary<span class=\"o\">()</span>\nModel: <span class=\"s2\">\"vgg16\"</span>\n_________________________________________________________________\nLayer <span class=\"o\">(</span><span class=\"nb\">type</span><span class=\"o\">)</span> Output Shape Param <span class=\"c\">#</span>\n<span class=\"o\">=================================================================</span>\ninput_1 <span class=\"o\">(</span>InputLayer<span class=\"o\">)</span> <span class=\"o\">[(</span>None, 150, 150, 3<span class=\"o\">)]</span> 0\n\nblock1_conv1 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 150, 150, 64<span class=\"o\">)</span> 1792\n\nblock1_conv2 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 150, 150, 64<span class=\"o\">)</span> 36928\n\n...\n\n\nblock4_pool <span class=\"o\">(</span>MaxPooling2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 0\n\nblock5_conv1 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 2359808\n\nblock5_conv2 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 2359808\n\nblock5_conv3 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 2359808\n\nblock5_pool <span class=\"o\">(</span>MaxPooling2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 4, 4, 512<span class=\"o\">)</span> 0\n\n<span class=\"o\">=================================================================</span>\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre></div></div>\n<p>마지막 3개의 합성곱 층을 미세 조정한다. 다시 말해 *block4_pool (MaxPooling2D) (None, 9, 9, 512) 0\n*까지 모든층은 동결되고 그 이후는 학습대상이 된다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">conv_base</span><span class=\"p\">.</span><span class=\"n\">trainable</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n\n<span class=\"n\">set_trainable</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n<span class=\"k\">for</span> <span class=\"n\">layer</span> <span class=\"ow\">in</span> <span class=\"n\">conv_base</span><span class=\"p\">.</span><span class=\"n\">layers</span><span class=\"p\">:</span>\n    <span class=\"k\">if</span> <span class=\"n\">layer</span><span class=\"p\">.</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s\">\"block5_conv1\"</span><span class=\"p\">:</span>\n        <span class=\"n\">set_trainable</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n    <span class=\"k\">if</span> <span class=\"n\">set_trainable</span><span class=\"p\">:</span>\n        <span class=\"n\">layer</span><span class=\"p\">.</span><span class=\"n\">trainable</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">layer</span><span class=\"p\">.</span><span class=\"n\">trainable</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n</code></pre></div></div>\n\n<p>모델을 수정했으니 컴파일을 다시한다.</p>\n","url":"/project/fine-tuning","relative_path":"_projects/2021-12-13-Fine_Tuning.md","permalink":null},{"draft":false,"categories":[],"layout":"project","date":"2021-12-13 00:00:00 +0000","title":"nlp-classification","subtitle":"국민청원 분류하기","image":"/images/projects/nlp-classification/thumbnail.png","slug":"nlp-classification","ext":".md","tags":[],"excerpt":"<h1 id=\"국민청원-분류하기\">국민청원 분류하기</h1>\n","content":"<h1 id=\"국민청원-분류하기\">국민청원 분류하기</h1>\n\n<p>텍스트 데이터를 모델링하는 분야를 자연어 처리(Natural language Processing, NLP)라고 한다. 자연어 처리에는 여러가지가 있는데 그중 대표적으로</p>\n\n<ol>\n  <li>텍스트 분류(Text Classification)</li>\n  <li>감정 분석(Sentiment Analysis)</li>\n  <li>요약(Summarization)</li>\n  <li>기계 번역(Machine Translation)</li>\n  <li>질문 응답(Question Answering)</li>\n</ol>\n\n<blockquote>\n이번 프로젝트의 목표는 국민청원 글에 <b>TextCNN</b> 이라는 모델을 적용하여 특정 글에서 청원 참여인원이 <b>1,000명</b> 이상 달성할지 여부를 <b>분류</b>하는 것을 목표로 한다.\n</blockquote>\n\n<p>다시말해서 수많은 청원 글 중 주목받을 만한 글을 예측하는 것이 목표라 할 수 있겠다. <문구수정> <span style=\"color: #ff8300;\">관심이 필요한 많은 사연들에 사람들의 눈길이 한 번 더 닿도록 하기 위함이다. 국민청원의 몇몇 사연들은 언론이나 SNS등의 도움을 받아 20만 동의 단숨에 달성하곤 한다. 반면 중대하지만 눈에 띄지 않고, 도움이 반드시 필요하지만 관심을 받지 못한 사연들은 많은 동의를 받기 어렵다. 사람들의 관미미이 일부 청원 글에 집중되기보다 사회의 다양한 사연들에 전해지도록 하는 것이 이 프로젝트의 궁극적인 목적이다. </span> <span문구수정></span문구수정></문구수정></p>\n\n<h2 id=\"1-intro\">1. Intro</h2>\n\n<p>프로젝트의 목표는 <span style=\"color: crimson;\">‘주목받을 만한 청원 분류하기’</span>이다. 하지만 ‘주목받을 만한’이라는 기준이 매우 애매하며 이는 사람마다 다를 수 있다. 사연의 경중을 판단하는 것은 입장차이마다 다를 수 있으며 매우 주관적인 영역이기에 읽는 사람마다 다른 판단이 내려진다. 우리는 이러한 주관전 판단을 배제할 수 있는 방법으로 딥러닝을 도입할 것이다. 딥러닝 모델을 통하여 <strong>높은</strong> 청원 참여인원을 기록한 글들의 특징을 학습하여, <strong>새로운 글</strong>이 입력되었을 때 청원 참여인원이 높은 글들과의 <strong>유사성</strong>을 계산하여 주목받을 만한 글인지 아닌지를 판단하도록 한다.</p>\n\n<figure style=\"text-align:center;\"><img width=\"2940\" height=\"512\" src=\"/images/projects/nlp-classification/model_flow.png\" />\n    <figcaption style=\"font-size: 0.8rem; margin-top: 1rem;\">Figure 1. 모델 전체 흐름</figcaption>\n</figure>\n\n<hr />\n<h2 id=\"2-crawling크롤링\">2. crawling(크롤링)</h2>\n\n<p>크롤링이란, 웹 페이지에서 원하는 데이터를 추출하여 수집하는 방법이다. 이 기법을 사용하여 2021년 1월 4일부터 2021년 12월 14일까지의 등록된 국민청원 글을 얻을 수 있다. 하나의 국민청원 글에서 청원 제목, 참여인원, 카테고리, 청원시작일, 청원마감일, 청원 내용 총 6개 항목을 추출한다. 가장 먼저, 데이터를 수집하기 위해 청와대 홈페이지의 국민청원 <a href=\"https://www1.president.go.kr/petitions\">https://www1.president.go.kr/petitions</a> 에 접속해서 보면 청원 글은 마지막 숫자가 1씩 변하는 것을 알 수 있다. 이러한 규칙을 이용하여 for문을 사용해 크롤링 코드를 추가한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n<span class=\"kn\">from</span> <span class=\"nn\">bs4</span> <span class=\"kn\">import</span> <span class=\"n\">BeautifulSoup</span>\n<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">595230</span><span class=\"p\">,</span> <span class=\"mi\">603000</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n    <span class=\"n\">URL</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s\">\"https://www1.president.go.kr/petitions/</span><span class=\"si\">{</span><span class=\"n\">i</span><span class=\"si\">}</span><span class=\"s\">\"</span>\n\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">URL</span><span class=\"p\">)</span>\n    <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">text</span>\n    <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">html</span><span class=\"p\">,</span> <span class=\"s\">'html.parser'</span><span class=\"p\">)</span>\n    <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"s\">\"h3\"</span><span class=\"p\">,</span> <span class=\"n\">class_</span><span class=\"o\">=</span><span class=\"s\">'petitionsView_title'</span><span class=\"p\">)</span>\n    <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"s\">'span'</span><span class=\"p\">,</span> <span class=\"n\">class_</span><span class=\"o\">=</span><span class=\"s\">'counter'</span><span class=\"p\">)</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">content</span> <span class=\"ow\">in</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s\">'div.petitionsView_write &gt; div.View_write'</span><span class=\"p\">):</span>\n        <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">tag</span> <span class=\"ow\">in</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s\">'ul.petitionsView_info_list &gt; li'</span><span class=\"p\">):</span>\n            <span class=\"n\">a</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">tag</span><span class=\"p\">.</span><span class=\"n\">contents</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n\n        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"n\">df1</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span>\n                <span class=\"s\">\"start\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]],</span>\n                <span class=\"s\">\"end\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]],</span>\n                <span class=\"s\">\"category\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]],</span>\n                <span class=\"s\">\"count\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">count</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">],</span>\n                <span class=\"s\">\"title\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">],</span>\n                <span class=\"s\">\"content\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">.</span><span class=\"n\">strip</span><span class=\"p\">()[</span><span class=\"mi\">0</span> <span class=\"p\">:</span> <span class=\"mi\">13000</span><span class=\"p\">]]</span>\n            <span class=\"p\">})</span>\n            <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">concat</span><span class=\"p\">([</span><span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">df1</span><span class=\"p\">])</span>\n            <span class=\"n\">result</span><span class=\"p\">.</span><span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">))</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">60</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Sleep 90seconds. Count:\"</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"s\">\", Local Time:\"</span>\n                  <span class=\"o\">+</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">strftime</span><span class=\"p\">(</span><span class=\"s\">\"%Y-%m-%d\"</span><span class=\"p\">,</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">localtime</span><span class=\"p\">(</span><span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">time</span><span class=\"p\">()))</span>\n                  <span class=\"o\">+</span><span class=\"s\">\", Data Length:\"</span><span class=\"o\">+</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)))</span>\n</code></pre></div></div>\n\n<p>엑셀에 데이터를 저장하기 위해 데이터의 길이를 13,000으로 제한한다. 엑셀에서 한 셀에 넣을 수 있는 글자수가 32,767자이기 때문에 13,000자까지 크롤링한 후 토크나이징 및 청원 제목과 병합하여 32,767자를 초과하지 않도록 하기 위함이다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># 데이터 저장\n</span><span class=\"n\">result</span><span class=\"p\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s\">\"petitions.csv\"</span> <span class=\"p\">,</span><span class=\"n\">index</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<hr />\n<h2 id=\"3-전처리\">3. 전처리</h2>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s\">\"petitions.csv\"</span><span class=\"p\">)</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">re</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">result</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">remove_white_space</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">):</span> <span class=\"c1\"># 공백문자를 제거하는 함수를 정의  \\t =&gt; tap, \\r\\n =&gt; 엔터, \\n =&gt; 줄바꿈, \\f =&gt; 새 페이지, \\v =&gt; 수직 탭\n</span>    \n    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"p\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s\">'[\\t\\r\\n\\f\\v]'</span><span class=\"p\">,</span> <span class=\"s\">''</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">))</span>\n    <span class=\"k\">return</span> <span class=\"n\">text</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">remove_special_char</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">):</span> <span class=\"c1\"># ㄱ-ㅣ(자음 ㄱ-ㅎ, ㅏ~ㅣ) 가-힣, 0-9에 해당하지 않는 문자가 등장하면 공백으로 치환, 영어가 등장해도 공백으로 교체\n</span>    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"p\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"s\">'[^ ㄱ-ㅣ|가-힣 0-9]+'</span><span class=\"p\">,</span> <span class=\"s\">''</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">))</span>\n    <span class=\"k\">return</span> <span class=\"n\">text</span>\n\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_white_space</span><span class=\"p\">)</span>\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_special_char</span><span class=\"p\">)</span>\n\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_white_space</span><span class=\"p\">)</span>\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_special_char</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"31-토크나이징-및-변수-생성\">3.1 토크나이징 및 변수 생성</h3>\n\n<p>토크나이징이란 문장을 의미 있는 부분으로 나누는 과정을 말하며, 그 나누어진 부분을 토큰(Token)이라고 부른다. 간단하게 <strong>형태소</strong>로 이해할 수 있다. 예를 들어, <span style=\"color: #288ba8;\">“나는 치킨을 먹는다”</span> 라는 문장을 형태소 단위로 토크나이징하면 <span style=\"color:#288ba8\">[“나”, “는”, “치킨”, “을”, “먹”, “는”, “다”]</span> 라는 7개의 토큰을 얻을 수 있다. \n분석에 필요한 모든 문장을 토크나이징 해주어야 하는데 그 이유는 컴퓨터는 다른 형태의 단어는 다른 단어라고 인식하기 때문이다. 예를 들어, <span style=\"color: #288ba8\">“먹습니다”, “먹다”, “먹어요”, “먹네요”, “먹었다”</span>는 모두 “먹다”의 의미지만 컴퓨터는 당연하게도 모두 다른 단어라고 인식한다. 이 것을 해결하기 위해 모든 단어를 형태소로 분할한다.\n“먹습니다” -&gt; [“먹”, “습니다”]\n“먹” -&gt; [“먹”, “다”] 등과 같이 전부 나누게 되면 <span style=\"color: #288ba8\">“먹”</span> 의미를 가진 최소 단위인 “먹”이 추출되고, 컴퓨터는 이 토큰을 근거로 위 문장들이 <span style=\"color:crimson;\">모두 유사한 의미</span>를 지녔다고 판단한다.</p>\n\n<p>우리는 청원 제목과 청원 내용을 토크나이징해야 한다. 청원 제목은 형태소 단위로, 청원 내용은 명사 단위로 문장을 나눈다. 청원 내용에서는 명사만 추출하여 학습하는데, 그 이유는 학습효율과 키워드 중심의 분석을 하기 위함이다. 청원 내용은 글이 길어 형태소 단위로 토크나이징해 학습하기에는 비교적 많은 시관과 자원이 요구된다. 따라서 명사만 추출하여 키워드 중심의 학습을 진행한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">konlpy.tag</span> <span class=\"kn\">import</span> <span class=\"n\">Okt</span>\n</code></pre></div></div>\n\n<p>konlpy에서 Okt를 임포트하기 위해서는 2가지가 필요하다.</p>\n<ol>\n  <li>Java가 설치되어 있어야 하며</li>\n  <li>tweepy가 &lt; 4.0.0 이어야 한다.</li>\n</ol>\n\n<p>따라서 <code class=\"language-plaintext highlighter-rouge\">AttributeError: module 'tweepy' has no attribute 'StreamListener'</code> Error가 나타나면</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip <span class=\"nb\">install </span><span class=\"nv\">tweepy</span><span class=\"o\">==</span>3.10.0\n</code></pre></div></div>\n<p>로 tweepy버전을 낮추자.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">okt</span> <span class=\"o\">=</span> <span class=\"n\">Okt</span><span class=\"p\">()</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"title_token\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">okt</span><span class=\"p\">.</span><span class=\"n\">morphs</span><span class=\"p\">)</span>  <span class=\"c1\"># 청원 제목을 형태소 단위로 토크나이징 하여 title_totken에 저장\n</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"content_token\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">okt</span><span class=\"p\">.</span><span class=\"n\">nouns</span><span class=\"p\">)</span> <span class=\"c1\"># 청원 내용을 명사(Nouns)단위로 토크나이징하여 저장\n</span>\n\n<span class=\"c1\"># 파생변수 생성\n</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"token_final\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title_token</span> <span class=\"o\">+</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content_token</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"count\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"count\"</span><span class=\"p\">].</span><span class=\"n\">replace</span><span class=\"p\">({</span><span class=\"s\">\",\"</span> <span class=\"p\">:</span> <span class=\"s\">\"\"</span><span class=\"p\">},</span> <span class=\"n\">regex</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">).</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span> <span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"c1\"># 참여인원은 천 단위마다\",\"가 있어 object형태로 인식함 참여인원에 \",\"를 제거하고 int형으로 변환\n</span>\n<span class=\"c1\"># 분석에 필요한 toekn_final과 label만 추출하여 df_drop에 저장\n</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"label\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"count\"</span><span class=\"p\">].</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"s\">\"yes\"</span> <span class=\"k\">if</span> <span class=\"n\">x</span><span class=\"o\">&gt;</span><span class=\"mi\">1000</span> <span class=\"k\">else</span> <span class=\"s\">\"No\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">df_drop</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[[</span><span class=\"s\">\"token_final\"</span><span class=\"p\">,</span> <span class=\"s\">\"label\"</span><span class=\"p\">]]</span>\n</code></pre></div></div>\n\n<h2 id=\"4-단어-임베딩\">4. 단어 임베딩</h2>\n\n<p>최종적으로 사용할 데이터는 국민청원의 전처리 결과인 “token_final”과 참여인원 1,000명 이상 여부를 나타내는 ‘label’이다.\n딥러닝 모델은 Input으로 숫자데이터를 입력해주어야 한다. 따라서 딥러닝 모델을 학습시키기 위해서는 이러한 문자데이티러르 숫자로 변환하여 컴퓨터가 이해할 수 있도록 해야 한다. 이러한 과정을 <span style=\"color:crimson\">단어 임베딩(word embedding)</span>이라고 한다. 다양한 임베딩 방법이 있지만 널리 사용하는 <span style=\"color:crimson\"><b>Word2Vec</b></span>을 사용하겠다.</p>\n\n<h3 id=\"41-word2vec을-들어가기-전에\">4.1 Word2Vec을 들어가기 전에</h3>\n<ul>\n  <li>Text1. [‘음주운전’, ‘사고’, ‘가해자’, ‘강력’, ‘처벌’] -&gt; [0, 1, 2, 3, 4]</li>\n  <li>Text2. [‘음주운전’, ‘역주행’, ‘사건’, ‘집행유예’, ‘처벌’] -&gt; [0,5, 6, 7, 4]</li>\n  <li>Text3. [‘음주운전’, ‘사고’, ‘면허’, ‘취소’, ‘규정’] -&gt; [0, 1, 8, 9, 10]</li>\n</ul>\n\n<p>위 인덱스는 임의로 토큰이 등장하는 순서대로 숫자를 부여했다. 음주운전 0, 사고는 1의 값을 갖는다. 하지만 이 방법은 단순히 토큰에 숫자로 치환한 것 그 이상의 의미는 갖지 못한다.</p>\n\n<blockquote>\n  <p><strong>Word2VEC</strong></p>\n</blockquote>\n\n<p><strong>Word2Vec</strong>은 단어의 의미와 유사도를 반영하여 단어를 벡터로 표현하는 방식이다. 예를 들어 <em>“왕-남자 = 여왕”</em>을 벡터로 표현하여 연산하는 것이다. Word2Vec을 관통하는 핵심은 <strong><em>‘토큰의 의미는 주변 토큰의 정보로 표현된다고’</em></strong> 가정한다. 즉 특정 토큰 근처에 있는 토큰들은 비슷한 위치의 벡터로 표현된다는 것이다.</p>\n\n<p><strong><em>One-Hot Encoding Vecotr</em></strong> 에 가중치 행렬을 곱하여 <strong><em>Word Embding Vector</em></strong> 를 생성할 수 있다. 가중치 행렬의 차원(Dimension)은 사용자가 지정해주어야 하는 값으로, 이 프로젝트에서는 <strong><em>100차원</em></strong>을 지정한다. 가중치 행렬을 학습하는 과정으로 <strong><em>CBOW</em></strong>와 <strong><em>Skip-Gram</em></strong>이 있으며 두 가지 방법 모두 문장을 <strong><em>윈도우 형태</em></strong>로 일부분만 보는 것을 기본으로 합니다. 중심 토큰의 양옆 토큰을 포함한 윈도우가 이동하면서 중심 토큰과 주변 토큰의 관계를 학습한다. CBOW의 목적은 윈도우 크기만 큼 앞뒤 주변 토큰을 벡터로 변환해 더한 후 중앙토큰을 맞추는 것이고, 반대로 Skip-gram의 목적은 중심 토큰을 벡터로 변환한 후 윈도우 크기만큼 주변 토큰을 맞추는 것이다. 일반적으로 Skip-gram의 성능이 더 좋다고 알려져있다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gensim.models</span> <span class=\"kn\">import</span> <span class=\"n\">Word2Vec</span> <span class=\"c1\"># Word2Vec, Doc2Vec, FastText, LDA Model 등과 같이 자연어 처리에 사용되는 모델을 지원하는데 그중 Word2Vec을 사용한다.\n</span>\n<span class=\"n\">embedding_model</span> <span class=\"o\">=</span> <span class=\"n\">Word2Vec</span><span class=\"p\">(</span><span class=\"n\">df_drop</span><span class=\"p\">[</span><span class=\"s\">\"token_final\"</span><span class=\"p\">],</span> <span class=\"c1\"># 임베딩 벡터를 생성할 대상이 되는 데이터\n</span>                           <span class=\"n\">sg</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\"># Word2Vec의 모델 구조 옵션을 지정(1: Skip-Gram, 0:Cbow)\n</span>                           <span class=\"n\">vector_size</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"c1\"># 임베딩 벡터의 크기(Dimension)을 지정\n</span>                           <span class=\"n\">window</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"c1\"># 임베딩 벡터 생성 시 문맥 파악을 위해 고려해야 할 앞, 뒤 토큰 수를 지정\n</span>                           <span class=\"n\">min_count</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\"># 전체 토큰에서 일정횟수 이상 등장하지 않는 토큰은 임베딩 벡터엣서 제외\n</span>                           <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span> <span class=\"c1\"># 실행할 병령 프로세서의 수\n</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">embedding_model</span><span class=\"p\">)</span>\n\n<span class=\"n\">model_result</span> <span class=\"o\">=</span> <span class=\"n\">embedding_model</span><span class=\"p\">.</span><span class=\"n\">wv</span><span class=\"p\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"s\">\"음주운전\"</span><span class=\"p\">)</span> <span class=\"c1\"># 9\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">model_result</span><span class=\"p\">)</span>\n\n\n<span class=\"c1\">##### 임베딩 모델 저장 및 로드\n</span><span class=\"kn\">from</span> <span class=\"nn\">gensim.models</span> <span class=\"kn\">import</span> <span class=\"n\">KeyedVectors</span> <span class=\"c1\"># 임베딩 모델을 불러오기 위한 클래스르 불러옴\n</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">path</span><span class=\"p\">.</span><span class=\"n\">isdir</span><span class=\"p\">(</span><span class=\"s\">\"data\"</span><span class=\"p\">):</span>\n    <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"s\">\"data\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">embedding_model</span><span class=\"p\">.</span><span class=\"n\">wv</span><span class=\"p\">.</span><span class=\"n\">save_word2vec_format</span><span class=\"p\">(</span><span class=\"s\">\"data/petitions_tokens_w2v\"</span><span class=\"p\">)</span> <span class=\"c1\"># 임베딩 모델을 저장\n</span>\n<span class=\"n\">loaded_model</span> <span class=\"o\">=</span> <span class=\"n\">KeyedVectors</span><span class=\"p\">.</span><span class=\"n\">load_word2vec_format</span><span class=\"p\">(</span><span class=\"s\">\"data/petitions_tokens_w2v\"</span><span class=\"p\">)</span> <span class=\"c1\"># 폴더에 저장되어 있는 임베딩 모델을 불러와 \"loaded_model\"에 저장\n</span>\n<span class=\"n\">model_result</span> <span class=\"o\">=</span> <span class=\"n\">loaded_model</span><span class=\"p\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"s\">\"음주운전\"</span><span class=\"p\">)</span> <span class=\"c1\"># 임베딩 모델이 이상 없이 로드되었는지 확인하기 위해 \"음주운전\" 유사한 단어와 벡터값이 이전 결과와 같은지 확인\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">model_result</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n","url":"/project/nlp-classification","relative_path":"_projects/2021-12-15-nlp-classification.md","permalink":null}],"testimonials":[],"data":{"newsletter":{"newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"},"navigation":{"logo_image":"/uploads/logo-blank.png","menu__settings":{"menu__items":[{"title":"Home","url":"/"},{"title":"Projects","url":"/projects/"},{"title":"Blog","url":"/blog/"},{"title":"Pages","submenu":[{"url":"/about/","title":"About"},{"url":"/elements/","title":"Elements"}]}]}},"social_links":{"social":[{"icon":"Twitter","link":"https://twitter.com"},{"icon":"Github","link":"https://github.com/woohaen88"},{"icon":"Pinterest","link":"https://pinterest.com"},{"icon":"Youtube","link":"https://youtube.com"}]},"general_settings":{"title":"woohyeon","description":"project","social_media_share_image":"/uploads/profile.jpeg","disqus-identifier":null,"google-analytics":null},"footer":{"footer_menu__settings":{"menu__items":[{"title":"Home","url":"/"},{"title":"Projects","url":"/projects/"},{"title":"Elements","url":"/elements/"},{"title":"About","url":"/about/"},{"title":"Blog","url":"/blog/"}]},"copyright_text_html":"<p>2021 &copy; <a href=\"/\">Vonge</a>. Template by <a href=\"https://cloudcannon.com/\">CloudCannon</a>. and Modified ururu</p>"},"author":{"author_name":"Kim WooHyeon","author_image":"/uploads/profile.jpeg"}},"baseurl":null,"title":"Woohyeon"}}