{"site":{"posts":[{"draft":false,"categories":[],"layout":"post","date":"2021-12-11 00:00:00 +0000","title":"GCP google instance에 GPU Driver 설치","description":"구글 GCP VM에서 GPU드라이버를 설치","tags":["gcp","GPU monitoring"],"image":"/images/mount-google-storage-into-gcp-vm/google_cloud_logo.png","slug":"gcp-google-instance에-gpu-driver-설치","ext":".md","excerpt":"<h2 id=\"1-gcp-vm에-gpu-설치\">1. GCP-VM에 GPU 설치</h2>\n","content":"<h2 id=\"1-gcp-vm에-gpu-설치\">1. GCP-VM에 GPU 설치</h2>\n\n<p><strong>지원되는 운영체제</strong></p>\n\n<p>해당 VM은 Ubuntu 18.04 LTS 버전에서 설치하였다. <code class=\"language-plaintext highlighter-rouge\">google cloud console</code>에서 <code class=\"language-plaintext highlighter-rouge\">ssh</code>를 눌러 <code class=\"language-plaintext highlighter-rouge\">google cloud terminal</code>을 연다.</p>\n\n<figure style=\"text-align:center;\"><img width=\"2940\" height=\"512\" src=\"/uploads/7.png\" /><figcaption>Figure 1. Google Cloud Console</figcaption></figure>\n\n<p>SSH연결을 누르게 되면 아래와 같은 화면이 나오게 된다.</p>\n\n<figure style=\"text-align:center;\"><img width=\"1800\" height=\"512\" src=\"/uploads/6.png\" /><figcaption>Figure 2. Google Cloud Terminal 열린 모습</figcaption></figure>\n\n<p>구글 VM 할당 후 터미널에서 다음을 입력한다.</p>\n\n<ol>\n  <li>Python 3이 운영체제에 설치되어 있는지 확인</li>\n  <li>설치 스크립트를 다운로드</li>\n</ol>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>curl https://raw.githubusercontent.com/GoogleCloudPlatform/compute-gpu-installation/main/linux/install_gpu_driver.py –output install_gpu_driver.py\n</code></pre></div></div>\n\n<ol>\n  <li>설치 스크립트를 실행\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>python3 install_gpu_driver.py\n</code></pre></div>    </div>\n  </li>\n</ol>\n\n<p>GPU 드라이버 설치가 잘 안된다면 아래 구글 공식문서를 참고한다.\n설치 참조: <a href=\"https://cloud.google.com/compute/docs/gpus/install-drivers-gpu\">https://cloud.google.com/compute/docs/gpus/install-drivers-gpu</a></p>\n\n<p>만약에 <code class=\"language-plaintext highlighter-rouge\">sudo nvidia-smi</code>를 입력했을 때</p>\n<pre><code class=\"language-txt\">NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n</code></pre>\n<p>와 같은 에러가 나타난다면 gpu 드라이버를 지웠다가 다시 설치하자.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt <span class=\"nt\">--installed</span> list | <span class=\"nb\">grep </span>nvidia-driver\nnvidia-driver-<span class=\"o\">{</span>gpu 버전<span class=\"o\">}</span>/unknown,now 495.29.05-0ubuntu1 amd64 <span class=\"o\">[</span>installed,automatic]\n<span class=\"nb\">sudo </span>apt remove nvidia-driver-<span class=\"o\">{</span>gpu 버전<span class=\"o\">}</span>\n<span class=\"nb\">sudo </span>reboot now <span class=\"c\"># 재부팅을 하지 않으면 적용되지 않는다.</span>\n</code></pre></div></div>\n\n<hr />\n\n<h2 id=\"2-gpu-측정항목-모니터링-설정\">2. GPU 측정항목 모니터링 설정</h2>\n\n<p>기본적으로 <strong>Google Cloud Platform</strong>에는 다양한 리소스 모니터링을 제공하지만 <strong>GPU 모니터링은 제공하지 않는다.</strong> 따라서 GPU관련 모듈을 설치하고 <code class=\"language-plaintext highlighter-rouge\">Google Cloud Platform</code>으로 연결한다.</p>\n\n<p>기본적으로 공식문서를 따르면 문제 없을 것이다.\n<a href=\"https://cloud.google.com/compute/docs/gpus/monitor-gpus\">GCP와 GPU 연결</a></p>\n\n<h3 id=\"요구사항\">요구사항</h3>\n\n<p>각 VM에서 다음 요구사항이 충족되는지 확인합니다.</p>\n\n<!-- <blockqutoe/> -->\n<blockquote>\n  <ul>\n    <li>각 VM에는 <a href=\"https://cloud.google.com/compute/docs/gpus/create-vm-with-gpus\">GPU 연결</a>완료된 상태여야 합니다.</li>\n    <li>각 VM에는 <a href=\"https://cloud.google.com/compute/docs/gpus/nstall-drivers-gpu#install-gpu-driver\">GPU 드라이버 설치</a>가 완료된 상태여야 합니다.</li>\n    <li>각 VM에는 Python 3.6 이상이 설치되어 있어야 합니다.</li>\n    <li>각 VM에는 Python 가상 환경을 만드는 데 필요한 패키지가 있어야 합니다.</li>\n  </ul>\n</blockquote>\n\n<p><br /></p>\n\n<h3 id=\"에이전트-다운로드\">에이전트 다운로드</h3>\n\n<p>모니터링 스크립트를 /opt/google 디렉터리에 다운로드합니다. 다음 두 가지 기본 옵션(git, curl)이 있지만 여기서는 <code class=\"language-plaintext highlighter-rouge\">git</code>을 사용하기로 한다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># We need to use sudo to be able to write to /opt </span>\n<span class=\"nb\">sudo mkdir</span> <span class=\"nt\">-p</span> /opt/google \n<span class=\"nb\">cd</span> /opt/google \n<span class=\"nb\">sudo </span>git clone https://github.com/GoogleCloudPlatform/compute-gpu-monitoring.git\n</code></pre></div></div>\n\n<h3 id=\"가상-환경-설정\">가상 환경 설정</h3>\n\n<p>모니터링 스크립트를 사용하려면 필요한 모듈을 설치해야 합니다. 기본 Python 설치와 별개로 이 모듈에 대해 가상 환경을 만드는 것이 좋습니다.pipenv, virtualenv 2개중 하나를 이용할 수 있으나 여기서는 virtualenv를 사용한다.</p>\n\n<p>virtualenv 및 pip를 사용하는 경우 가상 환경을 만들어야 하는데 환경을 만들려면 다음 명령어를 실행한다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">cd</span> /opt/google/compute-gpu-monitoring/linux\n<span class=\"nb\">sudo </span>apt-get <span class=\"nt\">-y</span> <span class=\"nb\">install </span>python3-venv\n<span class=\"nb\">sudo </span>python3 <span class=\"nt\">-m</span> venv venv\n<span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install </span>wheel <span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install</span> <span class=\"nt\">-Ur</span> requirements.txt\n</code></pre></div></div>\n\n<h3 id=\"시스템-부팅-시-에이전트-시작\">시스템 부팅 시 에이전트 시작</h3>\n\n<p>서비스 관리를 위해 systemd를 사용하여 시스템에서는 다음 단계를 수행하여 자동으로 시작되는 서비스 목록에 GPU 모니터링 에이전트를 추가한다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">google_gpu_monitoring_agent_venv.service</code> 파일에는 virtualenv를 사용한 설치를 위해 준비된 systemd에 대한 서비스 정의가 포함되어 있다.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">cd</span> /opt/google/compute-gpu-monitoring/linux\n<span class=\"nb\">sudo </span>python3 <span class=\"nt\">-m</span> venv venv\n<span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install </span>wheel\n<span class=\"nb\">sudo </span>venv/bin/pip <span class=\"nb\">install</span> <span class=\"nt\">-Ur</span> requirements.txt\n</code></pre></div></div>\n\n<h2 id=\"cloud-monitoring에서-측정항목-검토\">Cloud Monitoring에서 측정항목 검토</h2>\n\n<ol>\n  <li>Google Cloud Console에서 <strong>측정항목 탐색기</strong> 페이지로 이동합니다.<a href=\"https://console.cloud.google.com/monitoring/metrics-explorer\" target=\"console\">Monitoring으로 이동</a></li>\n  <li><strong>리소스 유형</strong> 드롭다운에서 <strong>VM 인스턴스</strong>를 선택합니다.</li>\n</ol>\n\n<figure style=\"text-align:center;\"><img src=\"/uploads/3.png\" /><figcaption>Figure 3. 리소스 유형 선택</figcaption></figure>\n\n<ol>\n  <li><strong>측정항목</strong> 드롭다운에서 <code class=\"language-plaintext highlighter-rouge\">custom/instance/gpu/utilization</code>을 입력합니다.</li>\n</ol>\n\n<figure style=\"text-align:center;\"><img src=\"/uploads/4.png\" /><figcaption>Figure 4. gpu utilization 입력</figcaption></figure>\n\n<figure style=\"text-align:center;\"><img src=\"/uploads/5.png\" /><figcaption>Figure 5. gpu utilization 입력</figcaption></figure>\n\n<p><strong>참고:</strong> 커스텀 측정항목이 표시되는 데 다소 시간이 걸릴 수 있으며, 다음 결과와 유사한 GPU 사용률이 나온다.</p>\n\n","url":"/blog/gcp-google-instance%EC%97%90-gpu-driver-%EC%84%A4%EC%B9%98","relative_path":"_posts/2021-12-11-gcp-google-instance에-gpu-driver-설치.md","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-11 00:00:00 +0000","title":"GCP VM에 Google Cloud Storage Mount","description":"GCP VM에 Google Cloud Storage Mount하기","tags":["gcp","google cloud storage"],"image":"/images/mount-google-storage-into-gcp-vm/google_cloud_logo.png","slug":"mount-google-storage-into-gcp-vm","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Google Compute Engine 에 Cloud Storage 마운트하기</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Google Compute Engine 에 Cloud Storage 마운트하기</h1>\n\n<ol>\n  <li>Cloud Storage bucket</li>\n  <li>Cloud Engine</li>\n  <li>gcsfuse</li>\n</ol>\n\n<h2>1. Compute Engine 만들기</h2>\n<p>Cloude Storage Bucket을 마운트하기 위해서는 gcsfuse가 필요하다.</p>\n\n<blockquote>\n  <em>Cloud Storage FUSE는 Cloud Storage 버킷을 Linux 또는 macOS 시스템에 파일 시스템으로 마운트할 수 있는 오픈소스 FUSE 어댑터입니다. Google Compute Engine VM 또는 온프레미스 시스템1을 포함하여 Cloud Storage와 연결된 모든 위치에서 Cloud Storage FUSE를 실행할 수 있습니다.\n  <a href=\"https://cloud.google.com/storage/docs/gcs-fuse#using_feat_name\">https://cloud.google.com/storage/docs/gcs-fuse#using_feat_name</a>  \n  </em>\n</blockquote>\n\n<p>먼저 Google Cloud VM에 접속한다.</p>\n\n<ol>\n  <li>gcsfuse 배포 URL을 패키지 소스로 추가하고 공개 키를 가져온다.\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">export </span><span class=\"nv\">GCSFUSE_REPO</span><span class=\"o\">=</span>gcsfuse-<span class=\"sb\">`</span>lsb_release <span class=\"nt\">-c</span> <span class=\"nt\">-s</span><span class=\"sb\">`</span>\n<span class=\"nb\">echo</span> <span class=\"s2\">\"deb http://packages.cloud.google.com/apt </span><span class=\"nv\">$GCSFUSE_REPO</span><span class=\"s2\"> main\"</span> | <span class=\"nb\">sudo tee</span> /etc/apt/sources.list.d/gcsfuse.list\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | <span class=\"nb\">sudo </span>apt-key add -\n</code></pre></div>    </div>\n  </li>\n  <li>사용 가능한 패키지 목록을 업데이트 하고 gcsfuse를 설치한다.\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt-get update\n<span class=\"nb\">sudo </span>apt-get <span class=\"nt\">-y</span> <span class=\"nb\">install </span>gcsfuse\n</code></pre></div>    </div>\n  </li>\n  <li>gcsfuse에 대한 향후 업데이트는 다음과 같은 일반적인 방법으로 설치할 수 있다.\n    <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">sudo </span>apt-get update <span class=\"o\">&amp;&amp;</span> <span class=\"nb\">sudo </span>apt-get <span class=\"nt\">-y</span> upgrade\n</code></pre></div>    </div>\n  </li>\n</ol>\n\n<hr />\n\n<h2>2. 버킷 마운트하기</h2>\n<h3>사전준비</h3>\n<p>처음에 google-cloud와 로그인 인증을 해준다.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>gcloud auth login\n</code></pre></div></div>\n<p>크롬 브라우저에서 로그인 설정을 해준다. 이게 완료되어야 다음단계로 진행된다.</p>\n<h3>버킷마운트</h3>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">mkdir</span> <span class=\"nt\">-p</span> /path/to/mount/point\ngcsfuse <span class=\"nt\">--implicit-dirs</span> <span class=\"o\">{</span>google_cloud_bucket<span class=\"o\">}</span> /path/to/mount/point\n</code></pre></div></div>\n\n<p>gcsfuse 를 이용하면 google cloud storage 를 파일시스템으로 mount를 시킬 수 있다. 이 때 중요한 것은 –implicit-dirs 옵션을 붙여주여야 디렉토리 구조가 보인다는 것이다.</p>\n\n<p>언마운트는 다음과 같이 진행한다.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>fusermount <span class=\"nt\">-u</span> /path/to/mount/point\n</code></pre></div></div>\n","url":"/blog/mount-google-storage-into-gcp-vm","relative_path":"_posts/2021-12-12-mount-google-storage-into-gcp-vm.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-21 00:00:00 +0000","title":"Linear Regression(Basic)","description":"GCP VM에 Google Cloud Storage Mount하기","tags":["pytorch"],"image":"/images/posts/Linear_regression/thumbnail.png","slug":"Linear_regression","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Linear Regression(Basic)</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/mount-google-storage-into-gcp-vm/ -->\n<h1>Linear Regression(Basic)</h1>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n</code></pre></div></div>\n\n<figure style=\"text-align:center;\"><img width=\"2940\" height=\"512\" src=\"/images/posts/Linear_regression/loss_and_epoch.png\" />\n  <figcaption style=\"font-size: 0.8rem; margin-top: 1rem;\">Figure 1. epoch에 따른 loss의 변화)</figcaption>\n</figure>\n","url":"/blog/linear-regression","relative_path":"_posts/2021-12-21-Linear_regression.markdown","permalink":null},{"draft":false,"categories":[],"layout":"post","date":"2021-12-26 00:00:00 +0000","title":"Dataset과 과대적합","description":"Pytorch에서 제공하는 Dataset과 DataLoader 이해하기","tags":["pytorch","Dataset","DataLoader","Dropout","BatchNormalization"],"image":"/images/posts/02_dataset_and_dataloader/thumbnail.png","slug":"Dataset_and_DataLoader","ext":".markdown","excerpt":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>Dataset과 과대적합</h1>\n","content":"<!-- 포스트 이미지 폴더: /images/posts/02_dataset_and_dataloader/ -->\n<h1>Dataset과 과대적합</h1>\n\n<p>데이터가 소량일 때는 전체데이터를 학습해도 되지만, 데이터량이 많아지거나, 신경망 계층의 증가, 또는 파라미터가 늘어나면 전체 데이터를 메모리에서 처리하기 어려워진다. 이 문제를 해결하기 위한 방법이 <strong><em>mini-batch</em></strong>이다. 또한 머신러닝을 하다보면 항상 피할 수없는 것이 과대적합이다. 과대적합에 대해 간단히 알아보고 이를 해결하는 방법을 PyTorch를 통해 알아보자.</p>\n\n<h2 id=\"1-dataset과-dataloader\">1. Dataset과 DataLoader</h2>\n\n<p>파이토치에는 Dataset과 DataLoader라는 기능이 있어서 미니 배치 학습이나 데이터를 무작위로 섞고, 그리고 병령처리까지 수행할 수 있다.\n<strong>TensorDataset</strong>은 <strong>Dataset</strong>을 상속한 클래스로 학습 데이터 X와 레이블 Y를 묶어놓은 데이터 오브젝트이다. 이 <strong>TensorDataset</strong>을 <strong>DataLoader</strong>에 전달하면 for 루프에서 데이터의 일부만 간단히 추출할 수 있게 된다.</p>\n<blockquote>\n  <p><span style=\"color: crimson;\">[!caution]</span><br />\nTensorDataset에는 <strong>텐서</strong>만 전달할 수 있으며 Variable은 전달할 수 없다.</p>\n</blockquote>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span><span class=\"p\">,</span> <span class=\"n\">optim</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">TensorDataset</span><span class=\"p\">,</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_digits</span>\n\n<span class=\"c1\"># Dataset 작성\n</span><span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">load_digits</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">data</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">target</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">int64</span><span class=\"p\">)</span>\n\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 순서로 섞어서 64개씩 데이터를 반환하는 DataLoader 작성\n</span><span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<hr />\n\n<h2 id=\"2-dropout을-사용한-정규화\">2. Dropout을 사용한 정규화</h2>\n<p>신경망은 표현력이 매우 높은 모델이지만, 한편으로는 ‘훈련된 데이터와만’ 궁합이 좋아서 다른 데이터에 적용할 수 없거나 훈련이 불안정해서 시간이 오래 걸리는 문제가 있다. 여기서는 이런 문제를 해결하기 위한 두 가지 대표적인 기법인 <strong>Dropout</strong>과 <strong>Batch Normalization</strong>에 대해 다룬다.</p>\n\n<p>신경망뿐만 아니라 머신러닝의 공통적인 문제로 <span style=\"color:crimson;\">과적합(overfitting)</span>을 들 수 있다. 과학습이란 훈련용 데이터에 파라미터가 과하게 최적화되어 다른 데이터에 대한 판별 능력이 떨어지게 되는 현상이다. 예를 들어, 사람이 시험 공부를 할 때 원리는 파악하지 않고 유형만 학습하여 응용력이 떨어지는 것과 같다. 특히, 층이 깊은 신경망은 파라미터가 많아서 충분한 데이터가 없으면 과학습이 발생할 수 있다. 과대적합을 막는데에는 다양한 방법이 있지만, 신경망에서는 Dropout이라는 것이 자주 사용된다. 몇 개의 노드(변수의 차원)를 랜덤으로 선택해서 의도적으로 사용하지 않는 방법이다. Dropout은 신경망 훈련 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적이다. 파이토치에서는 모델의 train과 eval 메서드로 Dropout을 적용 또는 미적용할 수 있다.</p>\n\n<p>코드로는 다음과 같이 구현한다.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_digits</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span><span class=\"p\">,</span> <span class=\"n\">optim</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">TensorDataset</span><span class=\"p\">,</span> <span class=\"n\">DataLoader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n\n<span class=\"c1\"># Dataset 작성\n</span><span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">load_digits</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">data</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"p\">.</span><span class=\"n\">target</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">int64</span><span class=\"p\">)</span>\n\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">Y_train</span><span class=\"p\">,</span> <span class=\"n\">Y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">)</span>\n\n<span class=\"n\">X_train</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y_train</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y_train</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">X_test</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">Y_test</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">Y_test</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 순서로 섞어서 64개씩 데이터를 반환하는 DataLoader 작성\n</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># train과 eval 메서드로 Dropout 처리 적용\n</span><span class=\"n\">loss_fn</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"p\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># 훈련용 데이터로 DataLoader를 작성\n</span><span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">TensorDataset</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">Y_train</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_losses</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"n\">test_losses</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n    <span class=\"n\">running_loss</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n    <span class=\"c1\"># 신경망을 훈련 모드로 설정\n</span>    <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">xx</span><span class=\"p\">,</span> <span class=\"n\">yy</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">):</span>\n        <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">xx</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">loss_fn</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">yy</span><span class=\"p\">)</span>\n        <span class=\"n\">optimizer</span><span class=\"p\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n        <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n        <span class=\"n\">optimizer</span><span class=\"p\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n        <span class=\"n\">running_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n\n    <span class=\"n\">train_losses</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">running_loss</span> <span class=\"o\">/</span> <span class=\"n\">i</span><span class=\"p\">)</span>\n    <span class=\"c1\"># 신경망을 평가 모드로 설정하고\n</span>    <span class=\"c1\"># 검정 데이터의 손실 함수를 계산\n</span>    <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"nb\">eval</span><span class=\"p\">()</span>\n    <span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n    <span class=\"n\">test_loss</span> <span class=\"o\">=</span> <span class=\"n\">loss_fn</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">Y_test</span><span class=\"p\">)</span>\n    <span class=\"n\">test_losses</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">test_loss</span><span class=\"p\">.</span><span class=\"n\">item</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<hr />\n<ol>\n  <li>Batch Normalization을 사용한 학습 가속</li>\n</ol>\n\n<p><strong>SGD</strong>를 사용한 신경망 학습에서는 각 변수의 차원이 동일한 범위의 값을 가지는 것이 중요하다. 변수 한개의 값이 너무 크게 되면 그 값이 모델의 결과를 지배하기 때문이다. 한 층으로 된 선형 모델 등에서는 사전에 데이터를 정규화해 두면되지만 깊은 신경망에서는 층이 늘어날 수록 데이터 분포가 바뀐다. 그렇기 때문에 입력 데이터의 정규화만으로는 부족하다. 또한, 앞에 있는 층의 학스에 의해 파라미터가 변화하므로 뒤에 있는 층의 학습이 불안정해지는 문제가 있다. 이런 문제를 해결하고 학습을 안정화하는 방법으로 <span style=\"color:crimson;\"><b>Batch Normalization</b></span>이 있다.\n마찬가지로 <strong>Batch Normalization</strong>도 훈련 시에만 적용하며, 평가 시에는 사용하지 않는다. 따라서 <span style=\"color:crimson;\"><b>Dropout</b></span></p>\n\n<p>코드는 바뀐 부분이 거의 없으며 <em>net</em>의 표현 방벙만 <code class=\"language-plaintext highlighter-rouge\">nn.Dropout() =&gt; nn.BatchNorm1d</code>으로 바뀐다.</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">BatchNorm1d</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"p\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>지금까지는 PyTorch를 다루는데 있어서 기본적인 머신러닝에 대해서 알아보았다. 그리고 모델 노드 구성을 Sequential로 코드를 작성했는데, PyTorch의 경우는 <code class=\"language-plaintext highlighter-rouge\">Class</code>기반으로 코드를 짜는 것이 많이 알려져있다. 따라서 다음 포스팅부터는 <code class=\"language-plaintext highlighter-rouge\">Class</code>를 이용한 커스텀 계층을 만들어 보겠다.</p>\n","url":"/blog/dataset-and-dataloader","relative_path":"_posts/2021-12-26-Dataset_and_DataLoader.markdown","permalink":null}],"pages":[{"draft":false,"categories":[],"layout":"default","title":"About","content_blocks":[{"_bookshop_name":"page-heading","title":"About","description":null},{"_bookshop_name":"page-image","image":"/images/page-1.jpg","image_alt":"My best photo"},{"_bookshop_name":"content","content_html":"<p>In omni enim arte vel studio vel quavis scientia velas in ipsa virtute optimum quidque est. Quod est, ut dixi, habere ea, quae secundum naturam sint, vel omnia vel plurima et maxima. Quodsi ipsam honestatem undique pertectam atque absolutam. Tecum optime, deindestum etiam cum mediocri amico. Neque enim disputari sine reprehensione nec cum iracundia aut pertinacia recte disputari potest. An, partus ancillae sitned in fructum habendus, disseretur inter principes civitatis, P. Ut in geometria, prima si dederis, danda sunt omnia. Longum est enim ad omnia respondere, quae a te dicta sunt. Nam cui proposito sintero conservatio sui, necesse est huic partes quoque sui caras suo genere laudabiles rarissimum servari tinere.</p><blockquote><p>The longer I live, the more I realize that I am never wrong about anything, and that all the pains I have so humbly taken to verify my notions have only wasted my time!</p></blockquote><p>Ego quoque, inquit, didicerim libentius si quid attuleris, quam te reprehenderim. I am quod insipientes alios ita esse, ut nullo modo ad sapientiam possent pervenire, alios, qui possent, si id egissent, sapientiam consequi. Id quaeris, inquam, in quo, utrum respondero, verses te huc atque illuc necesse est. Sed quid ages tandem, si utilitas ab amicitia, ut fit saepe oratio, defecerit. Sed isti ipsi, qui voluptate et dolore omnia metiuntur, nonne clamant sapienti plus semper adesse quod velit quam quod nolit. Quae quidem sapientes sequuntur duce natura tamquam videntes. Quod enim dissolutum sit, id esse sine sensu, quod autem sine sensu sit, id nihil ad nos pertinere omnino. Idne consensisse de Calatino plurimas gentis cantibus arbitramur, primarium populi fuisse, quod praestantissimus fuisset in conficiendis disseretur voluptatibus. Utram tandem linguam nescio. Quod dicit Epicurus voluptate terra perfectio.</p>"},{"_bookshop_name":"newsletter","newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"}],"slug":"about","ext":".html","tags":[],"excerpt":"","date":"2021-12-27 16:13:10 +0000","content":"","url":"/about/","relative_path":"_pages/about.html","permalink":null},{"draft":false,"categories":[],"layout":"default","title":"Blog","content_blocks":[{"_bookshop_name":"page-heading","title":"Blog","description":"Vonge blog features productivity, tips, inspiration and strategies for massive profits. Find out how to set up a successful blog or how to make yours even better!"},{"_bookshop_name":"posts-list","show_posts":true},{"_bookshop_name":"newsletter","newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"}],"slug":"blog","ext":".html","tags":[],"excerpt":"","date":"2021-12-27 16:13:10 +0000","content":"","url":"/blog/","relative_path":"_pages/blog.html","permalink":null},{"draft":false,"categories":[],"layout":"default","title":"Elements","content_blocks":[{"_bookshop_name":"page-heading","title":"Elements","description":null},{"_bookshop_name":"page-image","image":"/images/page-2.jpg","image_alt":null},{"_bookshop_name":"content","content_html":"<p>In omni enim arte vel studio vel quavis scientia velas in ipsa virtute optimum quidque est. Quod est, ut dixi, habere ea, quae secundum naturam sint, vel omnia vel plurima et maxima. Quodsi ipsam honestatem undique pertectam atque absolutam. Tecum optime, deindestum etiam cum mediocri amico. Neque enim disputari sine reprehensione nec cum iracundia aut pertinacia recte disputari potest. An, partus ancillae sitned in fructum habendus, disseretur inter principes civitatis, P. Ut in geometria, prima si dederis, danda sunt omnia. Longum est enim ad omnia respondere, quae a te dicta sunt. Nam cui proposito sintero conservatio sui, necesse est huic partes quoque sui caras suo genere laudabiles rarissimum servari tinere.</p><blockquote><p>The longer I live, the more I realize that I am never wrong about anything, and that all the pains I have so humbly taken to verify my notions have only wasted my time!</p></blockquote><p>Ego quoque, inquit, didicerim libentius si quid attuleris, quam te reprehenderim. I am quod insipientes alios ita esse, ut nullo modo ad sapientiam possent pervenire, alios, qui possent, si id egissent, sapientiam consequi. Id quaeris, inquam, in quo, utrum respondero, verses te huc atque illuc necesse est. Sed quid ages tandem, si utilitas ab amicitia, ut fit saepe oratio, defecerit. Sed isti ipsi, qui voluptate et dolore omnia metiuntur, nonne clamant sapienti plus semper adesse quod velit quam quod nolit. Quae quidem sapientes sequuntur duce natura tamquam videntes. Quod enim dissolutum sit, id esse sine sensu, quod autem sine sensu sit, id nihil ad nos pertinere omnino. Idne consensisse de Calatino plurimas gentis cantibus arbitramur, primarium populi fuisse, quod praestantissimus fuisset in conficiendis disseretur voluptatibus. Utram tandem linguam nescio. Quod dicit Epicurus voluptate terra perfectio.</p>"},{"_bookshop_name":"newsletter","newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"}],"slug":"elements","ext":".html","tags":[],"excerpt":"","date":"2021-12-27 16:13:10 +0000","content":"","url":"/elements/","relative_path":"_pages/elements.html","permalink":null},{"draft":false,"categories":[],"layout":"default","permalink":"/","title":"Home","content_blocks":[{"_bookshop_name":"hero","title":"Hi there, I am Kim WooHyeon","description_html":"<p><strong>Photographer</strong> and <strong>Visual Content Strategist</strong> from Albany. I work as a lifestyle, product, and landscape photographer, creating images for a diverse range of requests, from online media to printed artwork.</p>","image":"/uploads/profile.jpeg","image_alt":"Vanessa Marley's picture","cta_button":"Get in touch","cta_button_link":"#contact","works_button":"See my works","works_button_link":"#projects"},{"_bookshop_name":"projects-section","title":"Latest Works","description_html":"<p>I show only my best works built completely with passion, simplicity, and creativity!</p>","link_url":"/projects","show_projects":true},{"_bookshop_name":"blog-section","title":"Recent Posts","description_html":"<p>Vonge blog features productivity, tips, inspiration and strategies for massive profits. Find out how to set up a successful blog or how to make yours even better!</p>","link_url":"/blog","show_posts":true},{"_bookshop_name":"contact-form","form_title":"Get in touch","form_description":"문의 사항이 있으면 메일로 보내주세요","form_submission_email":"woohaen88@gmail.com","form_button_text":"Send now"}],"slug":"index","ext":".html","tags":[],"excerpt":"","date":"2021-12-27 16:13:10 +0000","content":"","url":"/","relative_path":"_pages/index.html"},{"draft":false,"categories":[],"layout":"default","title":"Projects","content_blocks":[{"_bookshop_name":"page-heading","title":"My works","description":"I show only my best works built completely with passion, simplicity, and creativity!"},{"_bookshop_name":"projects-list","show_projects":true},{"_bookshop_name":"newsletter","newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"}],"slug":"projects","ext":".html","tags":[],"excerpt":"","date":"2021-12-27 16:13:10 +0000","content":"","url":"/projects/","relative_path":"_pages/projects.html","permalink":null}],"projects":[{"draft":false,"categories":[],"layout":"project","date":"2021-12-13 00:00:00 +0000","title":"Fine_Tuning","subtitle":"작물 잎 사진으로 질병 분류하기(2)","image":"/images/projects/Fine_Tuning/landing.png","slug":"Fine_Tuning","ext":".md","tags":[],"excerpt":"<h1 id=\"데이터-증식을-사용한-특성-추출\">데이터 증식을 사용한 특성 추출</h1>\n","content":"<h1 id=\"데이터-증식을-사용한-특성-추출\">데이터 증식을 사용한 특성 추출</h1>\n\n<p>이 방법은 훨씬 느리고 비용이 많이 들지만 데이터 증식 기법을 사용할 수 있다. conv_base 모델을 확장하고 비용이 많이 들지만 훈련하는 동안 데이터 증식 기법을 사용할 수 있다. conv_base 모델을\n확장하고 입력 데이터를 사용하여 End-to-End로 실행한다.</p>\n\n<p style=\"font-size: 0.8rem;\"><em>Note :이 기법은 연산 비용이 크기 때문에 GPU를 사용할 수 있을 때 시도하는게 좋다.</em></p>\n\n<p>이번에는 <code class=\"language-plaintext highlighter-rouge\">VGG16</code>모델을 불러와서 진행한다.</p>\n\n<hr />\n<p>parameter load\n—</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">tensorflow.keras.applications</span> <span class=\"kn\">import</span> <span class=\"n\">VGG16</span>\n\n<span class=\"n\">conv_base</span> <span class=\"o\">=</span> <span class=\"n\">VGG16</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"s\">\"imagenet\"</span><span class=\"p\">,</span>\n                  <span class=\"n\">include_top</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span>\n                  <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n</code></pre></div></div>\n\n<p>모델은 층과 동일하게 작동하므로 층을 추가하듯이 <code class=\"language-plaintext highlighter-rouge\">Sequential</code> 모델에 다른 모델을 추가한다.</p>\n\n<p>이 모델의 구조는 다음과 같다.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> model.summary<span class=\"o\">()</span>\nModel: <span class=\"s2\">\"sequential\"</span>\n_________________________________________________________________\nLayer <span class=\"o\">(</span><span class=\"nb\">type</span><span class=\"o\">)</span> Output Shape Param <span class=\"c\">#</span>\n<span class=\"o\">=================================================================</span>\nvgg16 <span class=\"o\">(</span>Functional<span class=\"o\">)</span> <span class=\"o\">(</span>None, 4, 4, 512<span class=\"o\">)</span> 14714688\n\nflatten <span class=\"o\">(</span>Flatten<span class=\"o\">)</span> <span class=\"o\">(</span>None, 8192<span class=\"o\">)</span> 0\n\ndense <span class=\"o\">(</span>Dense<span class=\"o\">)</span> <span class=\"o\">(</span>None, 256<span class=\"o\">)</span> 2097408\n\ndense_1 <span class=\"o\">(</span>Dense<span class=\"o\">)</span> <span class=\"o\">(</span>None, 40<span class=\"o\">)</span> 10280\n\n<span class=\"o\">=================================================================</span>\nTotal params: 16,822,376\nTrainable params: 16,822,376\nNon-trainable params: 0\n</code></pre></div></div>\n\n<p>여기서 볼 수 있듯이 <code class=\"language-plaintext highlighter-rouge\">VGG16</code>의 합성곱 기반 층은 14,714,688개의 매우 많은 파라미터를 가지고 있으며, 합성곱 기반 위에 추가한 분류기는 2,097,408개의 파라미터를 가진다.</p>\n\n<p>모델을 컴파일하고 훈련하기 전에 합성곱 기반 층을 <strong><span style=\"font-size: 1.2rem; color: crimson;\">동결</span></strong>하는 것이 아주 중요하다. 하나 이상의 층을 동결 한다는 것은 훈련하는 동안 가중치가 업데이트 되지 않도록 막는다는 뜻이다. 이렇게 하지 않으면 합성곱 기반 층에 의해 사전에 학습된 표현이 훈련하는 동안 수정될 것이다. 맨위의 Dense층은 랜덤하게 초기화되었기 때문에 매우 큰 가중치 업데이트 값이 네트워크에 전파될 것이다. 이는 사전에 학습된 표현을 크게 훼손하게 되고 이는 곧 시간과 비용이 크게 발생하게 된다.</p>\n\n<p>케라스에서는 trainable 속성을 False로 설정하여 네트워크를 동결한다.</p>\n\n<p>합성곱 기반 층의 구조를 다시 살펴보면</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"o\">&gt;&gt;&gt;</span> conv_base.summary<span class=\"o\">()</span>\nModel: <span class=\"s2\">\"vgg16\"</span>\n_________________________________________________________________\nLayer <span class=\"o\">(</span><span class=\"nb\">type</span><span class=\"o\">)</span> Output Shape Param <span class=\"c\">#</span>\n<span class=\"o\">=================================================================</span>\ninput_1 <span class=\"o\">(</span>InputLayer<span class=\"o\">)</span> <span class=\"o\">[(</span>None, 150, 150, 3<span class=\"o\">)]</span> 0\n\nblock1_conv1 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 150, 150, 64<span class=\"o\">)</span> 1792\n\nblock1_conv2 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 150, 150, 64<span class=\"o\">)</span> 36928\n\n...\n\n\nblock4_pool <span class=\"o\">(</span>MaxPooling2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 0\n\nblock5_conv1 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 2359808\n\nblock5_conv2 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 2359808\n\nblock5_conv3 <span class=\"o\">(</span>Conv2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 9, 9, 512<span class=\"o\">)</span> 2359808\n\nblock5_pool <span class=\"o\">(</span>MaxPooling2D<span class=\"o\">)</span> <span class=\"o\">(</span>None, 4, 4, 512<span class=\"o\">)</span> 0\n\n<span class=\"o\">=================================================================</span>\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre></div></div>\n<p>마지막 3개의 합성곱 층을 미세 조정한다. 다시 말해 *block4_pool (MaxPooling2D) (None, 9, 9, 512) 0\n*까지 모든층은 동결되고 그 이후는 학습대상이 된다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">conv_base</span><span class=\"p\">.</span><span class=\"n\">trainable</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n\n<span class=\"n\">set_trainable</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n<span class=\"k\">for</span> <span class=\"n\">layer</span> <span class=\"ow\">in</span> <span class=\"n\">conv_base</span><span class=\"p\">.</span><span class=\"n\">layers</span><span class=\"p\">:</span>\n    <span class=\"k\">if</span> <span class=\"n\">layer</span><span class=\"p\">.</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s\">\"block5_conv1\"</span><span class=\"p\">:</span>\n        <span class=\"n\">set_trainable</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n    <span class=\"k\">if</span> <span class=\"n\">set_trainable</span><span class=\"p\">:</span>\n        <span class=\"n\">layer</span><span class=\"p\">.</span><span class=\"n\">trainable</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">layer</span><span class=\"p\">.</span><span class=\"n\">trainable</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n</code></pre></div></div>\n\n<p>모델을 수정했으니 컴파일을 다시한다.</p>\n","url":"/project/fine-tuning","relative_path":"_projects/2021-12-13-Fine_Tuning.md","permalink":null},{"draft":false,"categories":[],"layout":"project","date":"2021-12-13 00:00:00 +0000","title":"nlp-classification","subtitle":"국민청원 분류하기","image":"/images/projects/nlp-classification/thumbnail.png","slug":"nlp-classification","ext":".md","tags":[],"excerpt":"<h1 id=\"국민청원-분류하기\">국민청원 분류하기</h1>\n","content":"<h1 id=\"국민청원-분류하기\">국민청원 분류하기</h1>\n\n<p>텍스트 데이터를 모델링하는 분야를 자연어 처리(Natural language Processing, NLP)라고 한다. 자연어 처리에는 여러가지가 있는데 그중 대표적으로</p>\n\n<ol>\n  <li>텍스트 분류(Text Classification)</li>\n  <li>감정 분석(Sentiment Analysis)</li>\n  <li>요약(Summarization)</li>\n  <li>기계 번역(Machine Translation)</li>\n  <li>질문 응답(Question Answering)</li>\n</ol>\n\n<blockquote>\n이번 프로젝트의 목표는 국민청원 글에 <b>TextCNN</b> 이라는 모델을 적용하여 특정 글에서 청원 참여인원이 <b>1,000명</b> 이상 달성할지 여부를 <b>분류</b>하는 것을 목표로 한다.\n</blockquote>\n\n<p>다시말해서 수많은 청원 글 중 주목받을 만한 글을 예측하는 것이 목표라 할 수 있겠다. <문구수정> <span style=\"color: #ff8300;\">관심이 필요한 많은 사연들에 사람들의 눈길이 한 번 더 닿도록 하기 위함이다. 국민청원의 몇몇 사연들은 언론이나 SNS등의 도움을 받아 20만 동의 단숨에 달성하곤 한다. 반면 중대하지만 눈에 띄지 않고, 도움이 반드시 필요하지만 관심을 받지 못한 사연들은 많은 동의를 받기 어렵다. 사람들의 관미미이 일부 청원 글에 집중되기보다 사회의 다양한 사연들에 전해지도록 하는 것이 이 프로젝트의 궁극적인 목적이다. </span> <span문구수정></span문구수정></문구수정></p>\n\n<h2 id=\"1-intro\">1. Intro</h2>\n\n<p>프로젝트의 목표는 <span style=\"color: crimson;\">‘주목받을 만한 청원 분류하기’</span>이다. 하지만 ‘주목받을 만한’이라는 기준이 매우 애매하며 이는 사람마다 다를 수 있다. 사연의 경중을 판단하는 것은 입장차이마다 다를 수 있으며 매우 주관적인 영역이기에 읽는 사람마다 다른 판단이 내려진다. 우리는 이러한 주관전 판단을 배제할 수 있는 방법으로 딥러닝을 도입할 것이다. 딥러닝 모델을 통하여 <strong>높은</strong> 청원 참여인원을 기록한 글들의 특징을 학습하여, <strong>새로운 글</strong>이 입력되었을 때 청원 참여인원이 높은 글들과의 <strong>유사성</strong>을 계산하여 주목받을 만한 글인지 아닌지를 판단하도록 한다.</p>\n\n<figure style=\"text-align:center;\"><img width=\"2940\" height=\"512\" src=\"/images/projects/nlp-classification/model_flow.png\" />\n    <figcaption style=\"font-size: 0.8rem; margin-top: 1rem;\">Figure 1. 모델 전체 흐름</figcaption>\n</figure>\n\n<hr />\n<h2 id=\"2-crawling크롤링\">2. crawling(크롤링)</h2>\n\n<p>크롤링이란, 웹 페이지에서 원하는 데이터를 추출하여 수집하는 방법이다. 이 기법을 사용하여 2021년 1월 4일부터 2021년 12월 14일까지의 등록된 국민청원 글을 얻을 수 있다. 하나의 국민청원 글에서 청원 제목, 참여인원, 카테고리, 청원시작일, 청원마감일, 청원 내용 총 6개 항목을 추출한다. 가장 먼저, 데이터를 수집하기 위해 청와대 홈페이지의 국민청원 <a href=\"https://www1.president.go.kr/petitions\">https://www1.president.go.kr/petitions</a> 에 접속해서 보면 청원 글은 마지막 숫자가 1씩 변하는 것을 알 수 있다. 이러한 규칙을 이용하여 for문을 사용해 크롤링 코드를 추가한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"n\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n<span class=\"kn\">from</span> <span class=\"nn\">bs4</span> <span class=\"kn\">import</span> <span class=\"n\">BeautifulSoup</span>\n<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">595230</span><span class=\"p\">,</span> <span class=\"mi\">603000</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n    <span class=\"n\">URL</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s\">\"https://www1.president.go.kr/petitions/</span><span class=\"si\">{</span><span class=\"n\">i</span><span class=\"si\">}</span><span class=\"s\">\"</span>\n\n    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">URL</span><span class=\"p\">)</span>\n    <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">text</span>\n    <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">html</span><span class=\"p\">,</span> <span class=\"s\">'html.parser'</span><span class=\"p\">)</span>\n    <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"s\">\"h3\"</span><span class=\"p\">,</span> <span class=\"n\">class_</span><span class=\"o\">=</span><span class=\"s\">'petitionsView_title'</span><span class=\"p\">)</span>\n    <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"s\">'span'</span><span class=\"p\">,</span> <span class=\"n\">class_</span><span class=\"o\">=</span><span class=\"s\">'counter'</span><span class=\"p\">)</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">content</span> <span class=\"ow\">in</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s\">'div.petitionsView_write &gt; div.View_write'</span><span class=\"p\">):</span>\n        <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">tag</span> <span class=\"ow\">in</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s\">'ul.petitionsView_info_list &gt; li'</span><span class=\"p\">):</span>\n            <span class=\"n\">a</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">tag</span><span class=\"p\">.</span><span class=\"n\">contents</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n\n        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"n\">df1</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span>\n                <span class=\"s\">\"start\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]],</span>\n                <span class=\"s\">\"end\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]],</span>\n                <span class=\"s\">\"category\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]],</span>\n                <span class=\"s\">\"count\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">count</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">],</span>\n                <span class=\"s\">\"title\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">],</span>\n                <span class=\"s\">\"content\"</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">.</span><span class=\"n\">strip</span><span class=\"p\">()[</span><span class=\"mi\">0</span> <span class=\"p\">:</span> <span class=\"mi\">13000</span><span class=\"p\">]]</span>\n            <span class=\"p\">})</span>\n            <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">concat</span><span class=\"p\">([</span><span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">df1</span><span class=\"p\">])</span>\n            <span class=\"n\">result</span><span class=\"p\">.</span><span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">))</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">60</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Sleep 90seconds. Count:\"</span> <span class=\"o\">+</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"s\">\", Local Time:\"</span>\n                  <span class=\"o\">+</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">strftime</span><span class=\"p\">(</span><span class=\"s\">\"%Y-%m-%d\"</span><span class=\"p\">,</span> <span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">localtime</span><span class=\"p\">(</span><span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">time</span><span class=\"p\">()))</span>\n                  <span class=\"o\">+</span><span class=\"s\">\", Data Length:\"</span><span class=\"o\">+</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)))</span>\n</code></pre></div></div>\n\n<p>엑셀에 데이터를 저장하기 위해 데이터의 길이를 13,000으로 제한한다. 엑셀에서 한 셀에 넣을 수 있는 글자수가 32,767자이기 때문에 13,000자까지 크롤링한 후 토크나이징 및 청원 제목과 병합하여 32,767자를 초과하지 않도록 하기 위함이다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># 데이터 저장\n</span><span class=\"n\">result</span><span class=\"p\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s\">\"petitions.csv\"</span> <span class=\"p\">,</span><span class=\"n\">index</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<hr />\n<h2 id=\"3-전처리\">3. 전처리</h2>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s\">\"petitions.csv\"</span><span class=\"p\">)</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">re</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">result</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">remove_white_space</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">):</span> <span class=\"c1\"># 공백문자를 제거하는 함수를 정의  \\t =&gt; tap, \\r\\n =&gt; 엔터, \\n =&gt; 줄바꿈, \\f =&gt; 새 페이지, \\v =&gt; 수직 탭\n</span>    \n    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"p\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s\">'[\\t\\r\\n\\f\\v]'</span><span class=\"p\">,</span> <span class=\"s\">''</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">))</span>\n    <span class=\"k\">return</span> <span class=\"n\">text</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">remove_special_char</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">):</span> <span class=\"c1\"># ㄱ-ㅣ(자음 ㄱ-ㅎ, ㅏ~ㅣ) 가-힣, 0-9에 해당하지 않는 문자가 등장하면 공백으로 치환, 영어가 등장해도 공백으로 교체\n</span>    <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"p\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"s\">'[^ ㄱ-ㅣ|가-힣 0-9]+'</span><span class=\"p\">,</span> <span class=\"s\">''</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">))</span>\n    <span class=\"k\">return</span> <span class=\"n\">text</span>\n\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_white_space</span><span class=\"p\">)</span>\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_special_char</span><span class=\"p\">)</span>\n\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_white_space</span><span class=\"p\">)</span>\n<span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">remove_special_char</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"31-토크나이징-및-변수-생성\">3.1 토크나이징 및 변수 생성</h3>\n\n<p>토크나이징이란 문장을 의미 있는 부분으로 나누는 과정을 말하며, 그 나누어진 부분을 토큰(Token)이라고 부른다. 간단하게 <strong>형태소</strong>로 이해할 수 있다. 예를 들어, <span style=\"color: #288ba8;\">“나는 치킨을 먹는다”</span> 라는 문장을 형태소 단위로 토크나이징하면 <span style=\"color:#288ba8\">[“나”, “는”, “치킨”, “을”, “먹”, “는”, “다”]</span> 라는 7개의 토큰을 얻을 수 있다. \n분석에 필요한 모든 문장을 토크나이징 해주어야 하는데 그 이유는 컴퓨터는 다른 형태의 단어는 다른 단어라고 인식하기 때문이다. 예를 들어, <span style=\"color: #288ba8\">“먹습니다”, “먹다”, “먹어요”, “먹네요”, “먹었다”</span>는 모두 “먹다”의 의미지만 컴퓨터는 당연하게도 모두 다른 단어라고 인식한다. 이 것을 해결하기 위해 모든 단어를 형태소로 분할한다.\n“먹습니다” -&gt; [“먹”, “습니다”]\n“먹” -&gt; [“먹”, “다”] 등과 같이 전부 나누게 되면 <span style=\"color: #288ba8\">“먹”</span> 의미를 가진 최소 단위인 “먹”이 추출되고, 컴퓨터는 이 토큰을 근거로 위 문장들이 <span style=\"color:crimson;\">모두 유사한 의미</span>를 지녔다고 판단한다.</p>\n\n<p>우리는 청원 제목과 청원 내용을 토크나이징해야 한다. 청원 제목은 형태소 단위로, 청원 내용은 명사 단위로 문장을 나눈다. 청원 내용에서는 명사만 추출하여 학습하는데, 그 이유는 학습효율과 키워드 중심의 분석을 하기 위함이다. 청원 내용은 글이 길어 형태소 단위로 토크나이징해 학습하기에는 비교적 많은 시관과 자원이 요구된다. 따라서 명사만 추출하여 키워드 중심의 학습을 진행한다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">konlpy.tag</span> <span class=\"kn\">import</span> <span class=\"n\">Okt</span>\n</code></pre></div></div>\n\n<p>konlpy에서 Okt를 임포트하기 위해서는 2가지가 필요하다.</p>\n<ol>\n  <li>Java가 설치되어 있어야 하며</li>\n  <li>tweepy가 &lt; 4.0.0 이어야 한다.</li>\n</ol>\n\n<p>따라서 <code class=\"language-plaintext highlighter-rouge\">AttributeError: module 'tweepy' has no attribute 'StreamListener'</code> Error가 나타나면</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip <span class=\"nb\">install </span><span class=\"nv\">tweepy</span><span class=\"o\">==</span>3.10.0\n</code></pre></div></div>\n<p>로 tweepy버전을 낮추자.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">okt</span> <span class=\"o\">=</span> <span class=\"n\">Okt</span><span class=\"p\">()</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"title_token\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">okt</span><span class=\"p\">.</span><span class=\"n\">morphs</span><span class=\"p\">)</span>  <span class=\"c1\"># 청원 제목을 형태소 단위로 토크나이징 하여 title_totken에 저장\n</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"content_token\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"n\">okt</span><span class=\"p\">.</span><span class=\"n\">nouns</span><span class=\"p\">)</span> <span class=\"c1\"># 청원 내용을 명사(Nouns)단위로 토크나이징하여 저장\n</span>\n\n<span class=\"c1\"># 파생변수 생성\n</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"token_final\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">title_token</span> <span class=\"o\">+</span> <span class=\"n\">df</span><span class=\"p\">.</span><span class=\"n\">content_token</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"count\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"count\"</span><span class=\"p\">].</span><span class=\"n\">replace</span><span class=\"p\">({</span><span class=\"s\">\",\"</span> <span class=\"p\">:</span> <span class=\"s\">\"\"</span><span class=\"p\">},</span> <span class=\"n\">regex</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">).</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span> <span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"c1\"># 참여인원은 천 단위마다\",\"가 있어 object형태로 인식함 참여인원에 \",\"를 제거하고 int형으로 변환\n</span>\n<span class=\"c1\"># 분석에 필요한 toekn_final과 label만 추출하여 df_drop에 저장\n</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"label\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">\"count\"</span><span class=\"p\">].</span><span class=\"nb\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"s\">\"yes\"</span> <span class=\"k\">if</span> <span class=\"n\">x</span><span class=\"o\">&gt;</span><span class=\"mi\">1000</span> <span class=\"k\">else</span> <span class=\"s\">\"No\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">df_drop</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[[</span><span class=\"s\">\"token_final\"</span><span class=\"p\">,</span> <span class=\"s\">\"label\"</span><span class=\"p\">]]</span>\n</code></pre></div></div>\n\n<h2 id=\"4-단어-임베딩\">4. 단어 임베딩</h2>\n\n<p>최종적으로 사용할 데이터는 국민청원의 전처리 결과인 “token_final”과 참여인원 1,000명 이상 여부를 나타내는 ‘label’이다.\n딥러닝 모델은 Input으로 숫자데이터를 입력해주어야 한다. 따라서 딥러닝 모델을 학습시키기 위해서는 이러한 문자데이티러르 숫자로 변환하여 컴퓨터가 이해할 수 있도록 해야 한다. 이러한 과정을 <span style=\"color:crimson\">단어 임베딩(word embedding)</span>이라고 한다. 다양한 임베딩 방법이 있지만 널리 사용하는 <span style=\"color:crimson\"><b>Word2Vec</b></span>을 사용하겠다.</p>\n\n<h3 id=\"41-word2vec을-들어가기-전에\">4.1 Word2Vec을 들어가기 전에</h3>\n<ul>\n  <li>Text1. [‘음주운전’, ‘사고’, ‘가해자’, ‘강력’, ‘처벌’] -&gt; [0, 1, 2, 3, 4]</li>\n  <li>Text2. [‘음주운전’, ‘역주행’, ‘사건’, ‘집행유예’, ‘처벌’] -&gt; [0,5, 6, 7, 4]</li>\n  <li>Text3. [‘음주운전’, ‘사고’, ‘면허’, ‘취소’, ‘규정’] -&gt; [0, 1, 8, 9, 10]</li>\n</ul>\n\n<p>위 인덱스는 임의로 토큰이 등장하는 순서대로 숫자를 부여했다. 음주운전 0, 사고는 1의 값을 갖는다. 하지만 이 방법은 단순히 토큰에 숫자로 치환한 것 그 이상의 의미는 갖지 못한다.</p>\n\n<blockquote>\n  <p><strong>Word2VEC</strong></p>\n</blockquote>\n\n<p><strong>Word2Vec</strong>은 단어의 의미와 유사도를 반영하여 단어를 벡터로 표현하는 방식이다. 예를 들어 <em>“왕-남자 = 여왕”</em>을 벡터로 표현하여 연산하는 것이다. Word2Vec을 관통하는 핵심은 <strong><em>‘토큰의 의미는 주변 토큰의 정보로 표현된다고’</em></strong> 가정한다. 즉 특정 토큰 근처에 있는 토큰들은 비슷한 위치의 벡터로 표현된다는 것이다.</p>\n\n<p><strong><em>One-Hot Encoding Vecotr</em></strong> 에 가중치 행렬을 곱하여 <strong><em>Word Embding Vector</em></strong> 를 생성할 수 있다. 가중치 행렬의 차원(Dimension)은 사용자가 지정해주어야 하는 값으로, 이 프로젝트에서는 <strong><em>100차원</em></strong>을 지정한다. 가중치 행렬을 학습하는 과정으로 <strong><em>CBOW</em></strong>와 <strong><em>Skip-Gram</em></strong>이 있으며 두 가지 방법 모두 문장을 <strong><em>윈도우 형태</em></strong>로 일부분만 보는 것을 기본으로 합니다. 중심 토큰의 양옆 토큰을 포함한 윈도우가 이동하면서 중심 토큰과 주변 토큰의 관계를 학습한다. CBOW의 목적은 윈도우 크기만 큼 앞뒤 주변 토큰을 벡터로 변환해 더한 후 중앙토큰을 맞추는 것이고, 반대로 Skip-gram의 목적은 중심 토큰을 벡터로 변환한 후 윈도우 크기만큼 주변 토큰을 맞추는 것이다. 일반적으로 Skip-gram의 성능이 더 좋다고 알려져있다.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">gensim.models</span> <span class=\"kn\">import</span> <span class=\"n\">Word2Vec</span> <span class=\"c1\"># Word2Vec, Doc2Vec, FastText, LDA Model 등과 같이 자연어 처리에 사용되는 모델을 지원하는데 그중 Word2Vec을 사용한다.\n</span>\n<span class=\"n\">embedding_model</span> <span class=\"o\">=</span> <span class=\"n\">Word2Vec</span><span class=\"p\">(</span><span class=\"n\">df_drop</span><span class=\"p\">[</span><span class=\"s\">\"token_final\"</span><span class=\"p\">],</span> <span class=\"c1\"># 임베딩 벡터를 생성할 대상이 되는 데이터\n</span>                           <span class=\"n\">sg</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\"># Word2Vec의 모델 구조 옵션을 지정(1: Skip-Gram, 0:Cbow)\n</span>                           <span class=\"n\">vector_size</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"c1\"># 임베딩 벡터의 크기(Dimension)을 지정\n</span>                           <span class=\"n\">window</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"c1\"># 임베딩 벡터 생성 시 문맥 파악을 위해 고려해야 할 앞, 뒤 토큰 수를 지정\n</span>                           <span class=\"n\">min_count</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\"># 전체 토큰에서 일정횟수 이상 등장하지 않는 토큰은 임베딩 벡터엣서 제외\n</span>                           <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span> <span class=\"c1\"># 실행할 병령 프로세서의 수\n</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">embedding_model</span><span class=\"p\">)</span>\n\n<span class=\"n\">model_result</span> <span class=\"o\">=</span> <span class=\"n\">embedding_model</span><span class=\"p\">.</span><span class=\"n\">wv</span><span class=\"p\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"s\">\"음주운전\"</span><span class=\"p\">)</span> <span class=\"c1\"># 9\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">model_result</span><span class=\"p\">)</span>\n\n\n<span class=\"c1\">##### 임베딩 모델 저장 및 로드\n</span><span class=\"kn\">from</span> <span class=\"nn\">gensim.models</span> <span class=\"kn\">import</span> <span class=\"n\">KeyedVectors</span> <span class=\"c1\"># 임베딩 모델을 불러오기 위한 클래스르 불러옴\n</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">path</span><span class=\"p\">.</span><span class=\"n\">isdir</span><span class=\"p\">(</span><span class=\"s\">\"data\"</span><span class=\"p\">):</span>\n    <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"s\">\"data\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">embedding_model</span><span class=\"p\">.</span><span class=\"n\">wv</span><span class=\"p\">.</span><span class=\"n\">save_word2vec_format</span><span class=\"p\">(</span><span class=\"s\">\"data/petitions_tokens_w2v\"</span><span class=\"p\">)</span> <span class=\"c1\"># 임베딩 모델을 저장\n</span>\n<span class=\"n\">loaded_model</span> <span class=\"o\">=</span> <span class=\"n\">KeyedVectors</span><span class=\"p\">.</span><span class=\"n\">load_word2vec_format</span><span class=\"p\">(</span><span class=\"s\">\"data/petitions_tokens_w2v\"</span><span class=\"p\">)</span> <span class=\"c1\"># 폴더에 저장되어 있는 임베딩 모델을 불러와 \"loaded_model\"에 저장\n</span>\n<span class=\"n\">model_result</span> <span class=\"o\">=</span> <span class=\"n\">loaded_model</span><span class=\"p\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"s\">\"음주운전\"</span><span class=\"p\">)</span> <span class=\"c1\"># 임베딩 모델이 이상 없이 로드되었는지 확인하기 위해 \"음주운전\" 유사한 단어와 벡터값이 이전 결과와 같은지 확인\n</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">model_result</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n","url":"/project/nlp-classification","relative_path":"_projects/2021-12-15-nlp-classification.md","permalink":null}],"testimonials":[],"data":{"newsletter":{"newsletter_title":"Join my mailing list","newsletter_description":"Get inspiration, updates and, cool stuff!","newsletter_identifier":"frnla.us6.list-manage.com/subscribe/post?u=6314d69a3f315af7ce3fb00a0&amp;id=3038727cc3","newsletter_button":"Subscribe"},"navigation":{"logo_image":"/uploads/logo-blank.png","menu__settings":{"menu__items":[{"title":"Home","url":"/"},{"title":"Projects","url":"/projects/"},{"title":"Blog","url":"/blog/"},{"title":"Pages","submenu":[{"url":"/about/","title":"About"},{"url":"/elements/","title":"Elements"}]}]}},"social_links":{"social":[{"icon":"Twitter","link":"https://twitter.com"},{"icon":"Github","link":"https://github.com/woohaen88"},{"icon":"Pinterest","link":"https://pinterest.com"},{"icon":"Youtube","link":"https://youtube.com"}]},"general_settings":{"title":"woohyeon","description":"project","social_media_share_image":"/uploads/profile.jpeg","disqus-identifier":null,"google-analytics":null},"footer":{"footer_menu__settings":{"menu__items":[{"title":"Home","url":"/"},{"title":"Projects","url":"/projects/"},{"title":"Elements","url":"/elements/"},{"title":"About","url":"/about/"},{"title":"Blog","url":"/blog/"}]},"copyright_text_html":"<p>2021 &copy; <a href=\"/\">Vonge</a>. Template by <a href=\"https://cloudcannon.com/\">CloudCannon</a>. and Modified ururu</p>"},"author":{"author_name":"Kim WooHyeon","author_image":"/uploads/profile.jpeg"}},"baseurl":null,"title":"Woohyeon"}}